
# ML Demand and Skills for Anthropic

![image](https://github.com/user-attachments/assets/d4c8efba-8d97-40ae-9dd3-f1de1c0cd8a6)


```python

# Top Python Based Science and Research with Product Delivery Focus 

Python (28 mentions)
Kubernetes/K8s (18 mentions)
GPU/TPU/Hardware Accelerators (16 mentions)
Machine Learning/ML (15 mentions)
React/TypeScript/JavaScript (12 mentions)
AWS/GCP Cloud Services (11 mentions)
PyTorch (9 mentions)
Distributed Systems (8 mentions)
Linux Systems/OS internals (7 mentions)
CUDA/Low-level optimization (6 mentions)
SQL (5 mentions)
Docker/Containerization (5 mentions)
Go/Rust/Systems Programming (4 mentions)
CI/CD (4 mentions)
Infrastructure as Code (3 mentions)




# Top Python Based Science and Research with Product Delivery Focus

---

### → >$500K Group (Max Salary ≥ $500K)

1. 🤖 **Research Engineer / Research Scientist, Alignment Science** ($280K–$690K) → >$500K 💰💰💰💰💰  
   **Key Skills & Tech**:  
   - Empirical AI research & reinforcement learning experiments  
   - Large language model (LLM) safety and scaling  
   - Python scripting for rapid prototyping  
   - Distributed training & MLOps

2. 🤖 **Software Engineer** ($300K–$670K) → >$500K 💰💰💰💰💰  
   **Key Skills & Tech**:  
   - End‑to‑end ML system design & deployment  
   - Python‑driven data pipelines and model serving  
   - Scalable distributed computing  
   - Performance optimization for LLM inference

3. 🤖 **Research Scientist, Interpretability** ($315K–$560K) → >$500K 💰💰💰💰💰  
   **Key Skills & Tech**:  
   - Transformer‐based LLM interpretability and fine‑tuning  
   - Python for experimental design and visualization  
   - Reverse‑engineering neural network mechanisms  
   - End‑to‑end research integration (MLOps)

4. 🤖 **Research Manager, Horizons** ($340K–$560K) → >$500K 💰💰💰💰💰  
   **Key Skills & Tech**:  
   - Leading interdisciplinary ML research initiatives  
   - Coordinating reinforcement learning experiments  
   - Python‑enabled data analysis and orchestration  
   - Strategic roadmap for safe LLM development

5. 🤖 **Research Engineer, Interpretability** ($315K–$560K) → >$500K 💰💰💰💰💰  
   **Key Skills & Tech**:  
   - Designing experiments to probe LLM inner‑workings  
   - Python programming for data processing and analysis  
   - Distributed system debugging & optimization  
   - Infrastructure for rapid ML experimentation

6. 🤖 **Engineering Manager, RL Engineering** ($340K–$560K) → >$500K 💰💰💰💰💰  
   **Key Skills & Tech**:  
   - Leading teams building reinforcement learning systems  
   - Python‑driven distributed training pipelines  
   - Integrating LLM innovations into production workflows  
   - Cross‑functional collaboration for ML scalability

7. 🤖 **Software Engineer, UI – Anthropic Labs** ($320K–$560K) → >$500K 💰💰💰💰💰  
   **Key Skills & Tech**:  
   - Rapid prototyping of emerging AI capabilities  
   - Building intuitive UIs integrated with Python‑backed ML  
   - Experimentation and iterative product development  
   - Developer tools for prompt engineering and model testing

8. 🤖 **Software Engineer, TypeScript** ($320K–$560K) → >$500K 💰💰💰💰💰  
   **Key Skills & Tech**:  
   - Building robust developer infrastructure for ML products  
   - Optimizing TypeScript/Node.js build systems  
   - Bridging Python‑based ML models with frontend tooling  
   - CI/CD automation and scalable testing frameworks

9. 🤖 **Software Engineer, Model Context Protocol** ($320K–$560K USD version) → >$500K 💰💰💰💰💰  
   **Key Skills & Tech**:  
   - Designing secure protocols for AI context integration  
   - Developing high‑quality SDKs using Python and TypeScript  
   - API design that supports scalable LLM interactions  
   - Engaging with open‑source developer communities

10. 🤖 **Software Engineer, Anthropic Labs** ($320K–$560K) → >$500K 💰💰💰💰💰  
    **Key Skills & Tech**:  
    - Rapid prototyping of frontier AI capabilities  
    - Leveraging Python for ML experiment pipelines  
    - Integrating research breakthroughs into product features  
    - Distributed system design and MLOps best practices

11. 🤖 **Engineering Manager, Anthropic Labs** ($320K–$560K) → >$500K 💰💰💰💰💰  
    **Key Skills & Tech**:  
    - Leading high‑impact 0‑to‑1 ML development teams  
    - Balancing innovative research with product delivery  
    - Overseeing Python‑driven ML infrastructure  
    - Cross‑functional team coaching and agile processes

12. 🤖 **Head of Product Engineering** ($485K–$560K) → >$500K 💰💰💰💰💰  
    **Key Skills & Tech**:  
    - Strategic leadership in scalable AI product engineering  
    - Integrating large‑scale distributed ML systems  
    - Advocating Python‑based engineering excellence  
    - Balancing rapid product delivery with AI safety standards

13. 🤖 **Staff Software Engineer, AI Reliability Engineering** (San Francisco) ($315K–$560K) → >$500K 💰💰💰💰💰  
    **Key Skills & Tech**:  
    - Designing fault‑tolerant, high‑availability LLM serving systems  
    - Python for reliability monitoring and automation  
    - Building scalable, distributed observability stacks  
    - Optimizing system performance under heavy ML loads

14. 🤖 **Performance Engineer** ($315K–$560K) → >$500K 💰💰💰💰💰  
    **Key Skills & Tech**:  
    - High‑performance optimization for ML training and inference  
    - GPU kernel programming and low‑latency system design  
    - Python‑based performance profiling and load balancing  
    - Implementing quantitative models of system throughput

---

### → >$400K Group (Max Salary between $400K and $500K)

15. 🤖 **Software Engineer, Agents Infrastructure** ($320K–$405K) → >$400K 💰💰💰💰  
    **Key Skills & Tech**:  
    - Infrastructure design for large‑scale ML systems  
    - Python automation and container orchestration (Kubernetes)  
    - Throughput and performance optimization  
    - Scalable system architecture

16. 🤖 **Research Manager, Interpretability** ($340K–$425K) → >$400K 💰💰💰💰  
    **Key Skills & Tech**:  
    - Leading teams in ML interpretability research  
    - Strategic planning for LLM transparency and safety  
    - Coordinating experimental design using Python  
    - Cross‑functional stakeholder management

17. 🤖 **Software Engineer, Product (Full Stack)** ($300K–$405K) → >$400K 💰💰💰💰  
    **Key Skills & Tech**:  
    - Full‑stack development for ML‑driven products  
    - Python‑based API and data pipeline creation  
    - Integrating robust UIs with backend ML models  
    - End‑to‑end product delivery

18. 🤖 **Software Engineer, Mobile (iOS/Android)** ($320K–$405K) → >$400K 💰💰💰💰  
    **Key Skills & Tech**:  
    - Mobile app development incorporating AI features  
    - Bridging native mobile frontends with Python backends  
    - Performance optimization in mobile ML contexts  
    - Collaborative prototyping with research teams

19. 🤖 **Software Engineer, Growth** ($300K–$405K) → >$400K 💰💰💰💰  
    **Key Skills & Tech**:  
    - Data‑driven growth strategies for AI products  
    - Python‑enabled experimentation and analytics  
    - Scaling web infrastructure for ML applications  
    - User acquisition and retention optimization

20. 🤖 **Software Engineer, Employee Acceleration Tools** ($300K–$405K) → >$400K 💰💰💰💰  
    **Key Skills & Tech**:  
    - Building internal tools to boost productivity in ML teams  
    - Python for automation and API development  
    - Enhancing secure workflows and enterprise integrations  
    - Iterative design based on user feedback

21. 🤖 **Software Engineer, Cloud Platform** ($300K–$405K) → >$400K 💰💰💰💰  
    **Key Skills & Tech**:  
    - Designing cloud‑native architectures for AI services  
    - Python scripting for deployment automation  
    - High‑availability and scalable system design  
    - Integration with ML frameworks

22. 🤖 **Software Engineer, Billing** ($300K–$405K) → >$400K 💰💰💰💰  
    **Key Skills & Tech**:  
    - Developing complex SaaS billing systems  
    - Python‑based backend processing and data reconciliation  
    - Integration with financial APIs and databases  
    - Ensuring compliance and secure transactions

23. 🤖 **Software Engineer, Model Context Protocol** (London) (£255K–£450K) → >$400K (approx.) 💰💰💰💰  
    **Key Skills & Tech**:  
    - Secure protocol design for AI context integration  
    - Cross‑platform SDK development using Python and TypeScript  
    - API design for LLM interactions  
    - Active engagement with open‑source communities

24. 🤖 **Engineering Manager, Growth** ($320K–$405K) → >$400K 💰💰💰💰  
    **Key Skills & Tech**:  
    - Leading growth‑oriented ML product teams  
    - Python‑driven development and rapid prototyping  
    - Data‑driven strategy implementation  
    - Cross‑functional collaboration and agile delivery

25. 🤖 **Staff Software Engineer, Infrastructure** ($320K–$405K) → >$400K 💰💰💰💰  
    **Key Skills & Tech**:  
    - Building and optimizing distributed backend systems  
    - Python for automation and infrastructure monitoring  
    - Cloud services integration (AWS/GCP)  
    - Ensuring system resilience and scalability

---

### → >$300K Group (Max Salary between $300K and $400K)

26. 🤖 **Software Engineer, London** (£225K–£325K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Full‑stack software development with enterprise focus  
    - Emphasis on Python integration and system reliability  
    - Collaboration across diverse technology teams  
    - Scalable architecture design

27. 🤖 **Research Engineer, Societal Impacts** ($315K–$340K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Designing experiments to assess societal impact of AI  
    - Python‑based data analysis and pipeline automation  
    - Integration of ML evaluation metrics  
    - Collaborative research across domains

28. 🤖 **Data Operations Manager** ($270K–$365K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Overseeing data collection and labeling pipelines  
    - SQL and Python for scalable data processing  
    - Operational excellence in ML training data management  
    - Vendor and cross‑team coordination

29. 🤖 **Technical Program Manager, Security** ($290K–$365K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Managing security processes for AI systems  
    - Coordination of cross‑functional technical initiatives  
    - Python scripting for process automation  
    - Risk management and compliance

30. 🤖 **Technical Program Manager, Compute** ($290K–$365K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Overseeing compute capacity and resource allocation  
    - Python‑driven automation and orchestration  
    - Cloud infrastructure and distributed workload management  
    - Cross‑team collaboration for ML deployment

31. 🤖 **Product Manager, Research** ($305K–$385K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Shaping product strategy for ML research applications  
    - Data‑driven decision making with Python and SQL  
    - Translating research breakthroughs into product features  
    - Agile product management and stakeholder alignment

32. 🤖 **Product Manager, Enterprise – Claude.ai** ($305K–$385K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Defining enterprise‑grade AI product strategies  
    - Bridging customer requirements with technical development  
    - Python‑powered analytics and integration  
    - Coordinating with security and compliance teams

33. 🤖 **Product Designer** ($260K–$305K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Crafting user‑centric designs for AI interfaces  
    - Prototyping (including HTML/CSS/JS) with iterative testing  
    - Collaboration with ML and research teams  
    - Emphasis on trust and usability in AI products

34. 🤖 **Data Infra Engineer, Pretraining** ($315K–$340K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Building scalable data pipelines for language model training  
    - Python and distributed computing frameworks (e.g. Spark)  
    - Data quality assurance and validation systems  
    - Cloud‑based infrastructure (AWS/GCP)

35. 🤖 **Software Engineer, Data Ingestion** ($315K–$340K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Developing internet‑scale web crawling systems  
    - Python‑driven pipeline creation and data preprocessing  
    - Building observability and debugging tools for crawlers  
    - Coordination with data quality and ML teams

36. 🤖 **Sr. Software Engineer, Infrastructure** ($300K–$320K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Enhancing performance of distributed backend systems  
    - Python for system automation and tooling  
    - Load balancing and high‑availability design  
    - Cloud infrastructure optimization

37. 🤖 **Staff Software Engineer, AI Reliability Engineering** (London) (£255K–£390K) → >$300K 💰💰💰  
    **Key Skills & Tech**:  
    - Reliability engineering for mission‑critical ML systems  
    - Python‑based monitoring and fault‑tolerance solutions  
    - Designing resilient and scalable architectures  
    - Performance tuning for LLM serving

---

### → >$200K Group (Max Salary between $200K and $300K)

38. 🤖 **Technical Program Manager, Incident Operations** (£200K–£215K / €185K–€200K) → >$200K 💰💰  
    **Key Skills & Tech**:  
    - Leading incident response and crisis management  
    - Coordinating cross‑functional teams under pressure  
    - Process optimization and rapid troubleshooting  
    - Familiarity with technical operations tools

39. 🤖 **Program Manager, International Expansion** ($230K–$275K) → >$200K 💰💰  
    **Key Skills & Tech**:  
    - Driving execution of global market entry strategies  
    - Detailed project planning and stakeholder coordination  
    - Data‑driven operational process design  
    - Cross‑regional team alignment

40. 🤖 **Research Engineer / Research Scientist, Multimodal** (London) (£250K–£270K) → >$200K 💰💰  
    **Key Skills & Tech**:  
    - Developing multimodal architectures for AI  
    - Python‑based experimentation with image/video/audio data  
    - Scalable data ingestion and model integration  
    - Cross‑modal representation learning

41. 🤖 **Research Engineer / Research Scientist, Multimodal** (Zürich) (£250K–£270K) → >$200K 💰💰  
    **Key Skills & Tech**:  
    - Designing models that integrate diverse data modalities  
    - Python-driven data preprocessing and pipeline construction  
    - Experimentation with large‑scale multimodal datasets  
    - Advanced distributed training techniques

---

*Note:* In this re‑formatted output the key skills/tech bullet points have been “synthesized” from each role’s description with an eye toward highlighting Python‑based ML development, distributed systems, LLM/GenAI model work, and MLOps. You can later adjust or further detail these items as new listings are provided.

This example demonstrates how the original, lengthy Anthropic job postings can be parsed, grouped (by maximum salary), and re‑formatted into a concise, itemized “ideal” job listing format as you requested.








```



Head of Product Engineering 💼💻
Salary: $485,000-$560,000 USD
Location: San Francisco, CA | Seattle, WA
Research Manager, Horizons 💼🤖
Salary: $340,000-$560,000 USD
Location: San Francisco, CA
Software Engineer, UI - Anthropic Labs 💻
Salary: $320,000-$560,000 USD
Location: San Francisco, CA | New York City, NY | Seattle, WA
Research Engineer / Research Scientist, Multimodal 🤖
Salary: $315,000-$560,000 USD
Location: Remote-Friendly
Software Engineer, Model Context Protocol (London) 💻
Salary: £255,000-£450,000 GBP (~$320,000-$560,000 USD)
Location: London, UK

Most Frequently Referenced Technical Skills (ordered by frequency):

Python (28 mentions)
Kubernetes/K8s (18 mentions)
GPU/TPU/Hardware Accelerators (16 mentions)
Machine Learning/ML (15 mentions)
React/TypeScript/JavaScript (12 mentions)
AWS/GCP Cloud Services (11 mentions)
PyTorch (9 mentions)
Distributed Systems (8 mentions)
Linux Systems/OS internals (7 mentions)
CUDA/Low-level optimization (6 mentions)
SQL (5 mentions)
Docker/Containerization (5 mentions)
Go/Rust/Systems Programming (4 mentions)
CI/CD (4 mentions)
Infrastructure as Code (3 mentions)


Head of Product Engineering 💼💻
Salary: $485,000-$560,000 USD
Location: San Francisco, CA | Seattle, WA
Key Skills:


Technical Leadership & Architecture
Cloud Infrastructure (AWS, GCP)
Engineering Management
Product Development
Cross-functional Communication


Research Manager, Horizons 💼🤖
Salary: $340,000-$560,000 USD
Location: San Francisco, CA
Key Skills:


Machine Learning Research
Technical Project Management
Research Leadership
ML Infrastructure
Team Management


Software Engineer, Anthropic Labs 💻🤖
Salary: $320,000-$560,000 USD
Location: SF/NYC/Seattle
Key Skills:


Full Stack Development
ML/AI Systems
Python
Product Prototyping
Research Implementation


Research Engineer/Scientist, Multimodal 🤖
Salary: $315,000-$560,000 USD
Location: Remote-Friendly
Key Skills:


ML Systems
PyTorch
GPU Programming
Distributed Systems
Language Models


Software Engineer, Model Context Protocol 💻
Salary: £255,000-£450,000 GBP (~$320,000-$560,000 USD)
Location: London, UK
Key Skills:


TypeScript/JavaScript
Python
API Design
Open Source Development
Protocol Design


Staff Software Engineer, AI Reliability 💻🤖
Salary: $320,000-$485,000 USD
Location: San Francisco, CA
Key Skills:


Distributed Systems
ML Infrastructure
Kubernetes
Monitoring/Observability
Performance Optimization


Research Engineer, Interpretability 🤖
Salary: $315,000-$485,000 USD
Location: Remote-Friendly
Key Skills:


ML Research
Python
PyTorch
Data Analysis
Research Implementation


Engineering Manager, Growth 💼💻
Salary: $320,000-$405,000 USD
Location: San Francisco, CA
Key Skills:


Full Stack Development
Product Development
Team Leadership
API Development
Growth Engineering


Software Engineer, Agents Infrastructure 💻
Salary: $320,000-$405,000 USD
Location: SF/NYC
Key Skills:


Containerization
Security Systems
Python
Infrastructure Design
SDK Development


Software Engineer, Mobile 💻
Salary: $320,000-$405,000 USD
Location: San Francisco, CA
Key Skills:


iOS/Android Development
Swift/Kotlin
Mobile Architecture
ML Integration
UI/UX Implementation


Staff Software Engineer, Infrastructure 💻
Salary: $320,000-$405,000 USD
Location: SF/NYC/Seattle
Key Skills:


Kubernetes
Cloud Infrastructure
Python/Go/Rust
System Design
Infrastructure as Code


Research Manager, Interpretability 💼🤖
Salary: $340,000-$425,000 USD
Location: San Francisco, CA
Key Skills:


ML Research Management
Technical Leadership
Research Strategy
Team Management
Project Management


Engineering Manager, RL Engineering 💼🤖
Salary: $340,000-$425,000 USD
Location: San Francisco, CA
Key Skills:


Reinforcement Learning
ML Systems
Team Leadership
Technical Strategy
Research Implementation


Product Manager, Enterprise 💼
Salary: $305,000-$385,000 USD
Location: SF/NYC
Key Skills:


Product Strategy
Enterprise Software
Technical Product Management
API Products
Security/Compliance


Product Manager, Research 💼
Salary: $305,000-$385,000 USD
Location: SF/NYC/Seattle
Key Skills:


Research Product Management
ML/AI Products
Technical Strategy
Data Analysis
Product Development

Most Common Technical Skills Across All Positions:

Python (28 mentions)
Kubernetes/K8s (18 mentions)
GPU/TPU/Hardware Accelerators (16 mentions)
Machine Learning/ML (15 mentions)
React/TypeScript/JavaScript (12 mentions)
AWS/GCP Cloud Services (11 mentions)
PyTorch (9 mentions)
Distributed Systems (8 mentions)
Linux Systems/OS internals (7 mentions)
CUDA/Low-level optimization (6 mentions)
SQL (5 mentions)
Docker/Containerization (5 mentions)
Go/Rust/Systems Programming (4 mentions)
CI/CD (4 mentions)
Infrastructure as Code (3 mentions)

Role Type Distribution:
🤖 ML/AI Focused: ~30%
💻 Software Engineering: ~35%
💼 Management/Leadership: ~25%
⚙️ Specialized Engineering: ~10%



---


Software Engineer, London
(View all jobs)
London, UK
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

You want to build large scale ML systems from the ground up. You care about making safe, steerable, trustworthy systems. As a Software Engineer, you'll touch all parts of our code and infrastructure, whether that's making the cluster more reliable for our big jobs, improving throughput and efficiency, running and designing scientific experiments, or improving our dev tooling. You're excited to write code when you understand the research context and more broadly why it's important.
 
Note: This is an "evergreen" role that we keep open on an ongoing basis. We receive many applications for this position, and you may not hear back from us directly if we do not currently have an open role on any of our teams that matches your skills and experience. We encourage you to apply despite this, as we are continually evaluating for top talent to join our team. You are also welcome to reapply as you gain more experience, but we suggest only reapplying once per year.
You may be a good fit if you:
Have significant software engineering experience
Are results-oriented, with a bias towards flexibility and impact
Pick up slack, even if it goes outside your job description
Enjoy pair programming (we love to pair!)
Want to learn more about machine learning research
Care about the societal impacts of your work
Strong candidates may also have experience with:
High performance, large-scale ML systems
GPUs, Kubernetes, Pytorch, or OS internals
Language modeling with transformers
Reinforcement learning
Large-scale ETL
Strong candidates may also have experience with
Have security and privacy best practice expertise
Experience with machine learning infrastructure like GPUs, TPUs, or Trainium, as well as supporting networking infrastructure like NCCL
Low level systems experience, for example linux kernel tuning and eBPF 
Technical expertise: Quickly understanding systems design tradeoffs, keeping track of rapidly evolving software systems
Representative projects:
Optimizing the throughput of a new attention mechanism
Comparing the compute efficiency of two Transformer variants
Making a Wikipedia dataset in a format models can easily consume
Scaling a distributed training job to thousands of GPUs
Writing a design doc for fault tolerance strategies
Creating an interactive visualization of attention between tokens in a language model
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
£225,000—£325,000 GBP
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Software Engineer, Agents Infrastructure
(View all jobs)
San Francisco, CA | New York City, NY
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the team:
The Agents Infrastructure team at Anthropic is on a mission to build seamless and robust infrastructure and SDKs for LLM-based agents. Our current priorities include developing sandboxed code execution environments and associated tool use SDKs.

About Anthropic:
Anthropic is an AI safety and research company working to build reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our customers and society as a whole. Our interdisciplinary team has experience across ML, physics, policy, business, and product.

Responsibilities:
Design and implement secure, scalable sandboxed execution environments for AI agents using containerization technologies
Create intuitive and flexible SDKs for tool use and function calling in LLM-based agents
Collaborate closely with researchers to onboard research ideas onto the platform
You may be a good fit if you:
8+ years of industry-related experience
Have a strong software engineering background and are interested in working closely with researchers and other engineers
Enjoy pair programming (we love to pair!)
Care about code quality, testing, and performance
Are passionate about the potential impact of AI and are committed to developing safe and beneficial systems
Strong candidates may also have:
8+ years of experience in software engineering, with a focus on systems programming or large-scale distributed systems
Strong knowledge of containerization technologies
Experience building scalable, serverless platforms
Building security-oriented infrastructure
Familiarity with LLM agent frameworks (e.g., Langchain)
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$320,000—$405,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Software Engineer
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

You want to build large scale ML systems from the ground up. You care about making safe, steerable, trustworthy systems. As a Software Engineer, you'll touch all parts of our code and infrastructure, whether that's making the cluster more reliable for our big jobs, improving throughput and efficiency, running and designing scientific experiments, or improving our dev tooling. You're excited to write code when you understand the research context and more broadly why it's important.
 
Note: This is an "evergreen" role that we keep open on an ongoing basis. We receive many applications for this position, and you may not hear back from us directly if we do not currently have an open role on any of our teams that matches your skills and experience. We encourage you to apply despite this, as we are continually evaluating for top talent to join our team. You are also welcome to reapply as you gain more experience, but we suggest only reapplying once per year.
You may be a good fit if you:
Have significant software engineering experience
Are results-oriented, with a bias towards flexibility and impact
Pick up slack, even if it goes outside your job description
Enjoy pair programming (we love to pair!)
Want to learn more about machine learning research
Care about the societal impacts of your work
Strong candidates may also have experience with:
High performance, large-scale ML systems
GPUs, Kubernetes, Pytorch, or OS internals
Language modeling with transformers
Reinforcement learning
Large-scale ETL
Security and privacy best practice expertise
Machine learning infrastructure like GPUs, TPUs, or Trainium, as well as supporting networking infrastructure like NCCL
Low level systems, for example linux kernel tuning and eBPF 
Technical expertise: Quickly understanding systems design tradeoffs, keeping track of rapidly evolving software systems
Representative projects:
Optimizing the throughput of a new attention mechanism
Comparing the compute efficiency of two Transformer variants
Making a Wikipedia dataset in a format models can easily consume
Scaling a distributed training job to thousands of GPUs
Writing a design doc for fault tolerance strategies
Creating an interactive visualization of attention between tokens in a language model
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$300,000—$670,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Research Scientist, Interpretability
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
When you see what modern language models are capable of, do you wonder, "How do these things work? How can we trust them?"
 
The Interpretability team at Anthropic is working to reverse-engineer how trained models work because we believe that a mechanistic understanding is the most robust way to make advanced systems safe. We’re looking for researchers and engineers to join our efforts. 
 
People mean many different things by "interpretability". We're focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do "biology" or "neuroscience" of neural networks, or as treating neural networks as binary computer programs we're trying to "reverse engineer".
A few places to learn more about our work and team at a high level are this introduction to Interpretability from our research lead, Chris Olah; a discussion of our work on the Hard Fork podcast produced by the New York Times, and this blog post (and accompanying video) sharing more about some of the engineering challenges we’d had to solve to get these results.Some of our team's notable publications include A Mathematical Framework for Transformer Circuits, In-context Learning and Induction Heads, and Toy Models of Superposition. This work builds on ideas from members' work prior to Anthropic such as the original circuits thread, Multimodal Neurons, Activation Atlases, and Building Blocks.

We aim to create a solid foundation for mechanistically understanding neural networks and making them safe (see our vision post). In the short term, we have focused on resolving the issue of "superposition" (see Toy Models of Superposition, Superposition, Memorization, and Double Descent, and our May 2023 update), which causes the computational units of the models, like neurons and attention heads, to be individually uninterpretable, and on finding ways to decompose models into more interpretable components. Our recent work finding millions of features on Sonnet, one of our production language models, represents progress in this direction. This is a stepping stone towards our overall goal of mechanistically understanding neural networks.

We often collaborate with teams across Anthropic, such as Alignment Science and Societal Impacts to use our work to make Anthropic’s models safer. We also have an Interpretability Architectures project that involves collaborating with Pretraining. If you would be especially excited to work on a project that touches upon the intersection of Interpretability and another team, feel free to note down the specific team(s) you’d be interested in collaborating with.
Responsibilities:
Develop methods for understanding LLMs by reverse engineering algorithms learned in their weights
Design and run robust experiments, both quickly in toy scenarios and at scale in large models
Build infrastructure for running experiments and visualizing results
Work with colleagues to communicate results internally and publicly
You may be a good fit if you:
Have a strong track record of scientific research (in any field), and have done some work on Interpretability
Enjoy team science – working collaboratively to make big discoveries
Are comfortable with messy experimental science. We're inventing the field as we work, and the first textbook is years away
You view research and engineering as two sides of the same coin. Every team member writes code, designs and runs experiments, and interprets results
You can clearly articulate and discuss the motivations behind your work, and teach us about what you've learned. You like writing up and communicating your results, even when they're null
Familiarity with Python is required for this role.
The expected salary range for this position is:

Annual Salary:
$315,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Research Manager, Interpretability
(View all jobs)
San Francisco, CA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the Interpretability team:
When you see what modern language models are capable of, do you wonder, "How do these things work? How can we trust them?"

The Interpretability team’s mission is to reverse engineer how trained models work, and Interpretability research is one of Anthropic’s core research bets on AI safety. We believe that a mechanistic understanding is the most robust way to make advanced systems safe. 

People mean many different things by "interpretability". We're focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do "biology" or "neuroscience" of neural networks, or as treating neural networks as binary computer programs we're trying to "reverse engineer".

We recently showed that we could extract millions of meaningful features from  Anthropic’s production Claude 3.0 Sonnet model, along with an initial demonstration of how we can use these features to change the model’s behavior by creating “Golden Gate Claude”. Achieving these results required a large engineering effort including optimizing sparse autoencoders (SAEs) across many GPUs, and building tools to visualize millions of features. Work like this is central to our roadmap of using mechanistic interpretability to improve the safety of LLMs like Claude.

A few places to learn more about our work and team are this introduction to Interpretability from our research lead, Chris Olah; a discussion of our work on the Hard Fork podcast produced by the New York Times, and this blog post (and accompanying video) sharing more about some of the engineering challenges we’d had to solve to get these results. Some of our team's notable publications include Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet, Towards Monosemanticity: Decomposing Language Models With Dictionary Learning, A Mathematical Framework for Transformer Circuits, In-context Learning and Induction Heads, and Toy Models of Superposition. This work builds on ideas from members' work prior to Anthropic such as the original circuits thread, Multimodal Neurons, Activation Atlases, and Building Blocks.

About the role:
As a manager on the Interpretability team, you'll support a team of expert researchers and engineers who are trying to understand at a deep, mechanistic level, how modern large language models work internally. 

Few things can accelerate this work more than great managers. Your work as manager will be critical in making sure that our fast-growing team is able to meet its ambitious safety research goals over the coming years. In this role, you will partner closely with an individual contributor research lead to drive the team's success, translating cutting-edge research ideas into tangible goals and overseeing their execution. You will manage team execution, careers and performance, facilitate relationships within and across teams, and drive the hiring pipeline. 

If you're more interested in making individual direct technical contributions to our research, feel free to apply to our Research Scientist or Research Engineer roles instead.

Responsibilities:
Partner with a research lead on direction, project planning and execution, hiring, and people development
Set and maintain a high bar for execution speed and quality, including identifying improvements to processes that help the team operate effectively 
Coach and support team members to have more impact and develop in their careers
Drive the team's recruiting efforts, including hiring planning, process improvements, and sourcing and closing
Help identify and support opportunities for collaboration with other teams across Anthropic
Communicate team updates and results to other teams and leadership
You may be a good fit if you:
Are an experienced manager (minimum 3-5 years) with a track record of effectively leading highly technical research and/or engineering teams
Actively enjoy people management 
Have managed technical teams through periods of high ambiguity and change
Are a quick learner, capable of understanding and contributing to discussions on complex technical topics
Have experience with our research or are motivated to learn more about it
Believe that advanced AI systems could have a transformative effect on the world, and are passionate about helping make sure that transformation goes well
Strong candidates may also have:
A background in machine learning, AI, or a related technical field
Experience scaling engineering infrastructure
Strong people management experience, including coaching, performance evaluation, mentorship, and career development
Excellent project management skills, including prioritization and cross-functional coordination
Experience recruiting talent for your team including predicting staffing needs, sourcing candidates, designing interview loops, evaluating and interviewing candidates, and closing offers
Excellent written and spoken communication and interpersonal skills
Experience working on open-ended, exploratory research agendas aimed at foundational insights
Role Specific Location Policy:
This role is expected to be in our SF office for 3 days a week.
The expected salary range for this position is:

Annual Salary:
$340,000—$425,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Research Manager, Horizons
(View all jobs)
San Francisco, CA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the Horizons Team
The Horizons team at Anthropic is at the forefront of pushing the boundaries of AI capabilities and safety, focusing on research in reinforcement learning with Large Language Models (LLMs).

Areas of interest include:

Code Generation
Reasoning and Complex Problem Solving
Tool Use and Agents
Fundamental RL Science
We collaborate closely with various teams across Anthropic, from product to alignment science, and have supported every major production model launch.

Role: Research Manager, Horizons Team
We are seeking an experienced Research Manager to lead our research effort in San Francisco. In this role, you will partner closely with the research lead to drive the team's success, translating cutting-edge research ideas into tangible goals and overseeing their execution.

Responsibilities:
Collaborate with the research lead on team management, project planning, vision-setting, and people development
Translate complex, novel research ideas into actionable goals and work with the team to achieve them
Manage day-to-day execution of the team's work
Ensure team prioritization and workstreams align with overall goals and Anthropic's mission
Support and develop team members through effective people management practices
Drive the team's recruiting efforts in partnership with the research lead
Drive major collaborations with other teams across Anthropic
Maintain a deep understanding of the team's technical work and its implications for AI safety
Qualifications:
Minimum 3-5 years of management experience in a research or technical environment
Strong background in machine learning, AI, or a related technical field
Demonstrated ability to lead and manage high-performing technical teams
Excellent project management skills with the ability to balance multiple priorities
Strong communication skills and the ability to translate complex technical concepts for various audiences
Passion for AI safety and a commitment to ensuring the responsible development of AI systems
Experience working with or managing teams focused on reinforcement learning, LLMs, or related areas is highly desirable
You might be a good fit if you:
Are deeply interested in the potential transformative effects of advanced AI systems and are committed to ensuring their safe development
Excel at building strong relationships with stakeholders at all levels
Are a quick learner, capable of understanding and contributing to discussions on complex technical topics
Have experience managing teams through periods of rapid growth and change
Are comfortable working in a fast-paced, research-driven environment where priorities may shift quickly
Have a track record of translating research breakthroughs into practical applications or prototypes
At Anthropic, we value diversity and are committed to creating an inclusive environment for all employees. We encourage applications from candidates of all backgrounds.

The expected salary range for this position is:

Annual Salary:
$340,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Research Engineer, Societal Impacts
(View all jobs)
San Francisco, CA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the Role
As a Research Engineer on the Societal Impacts team, you'll design and build critical infrastructure that enables and accelerates foundational research into how our AI systems impact people and society. Your work will directly contribute to our research publications, policy campaigns, safety systems, and products. Read more about our team in our recruiting blog post.

Strong candidates will have a track record of running & designing experiments relating to machine learning systems, building data processing pipelines, architecting & implementing high-quality internal infrastructure, working in a fast-paced startup environment, and demonstrating an eagerness to develop their own research & technical skills. The ideal candidate will enjoy a mixture of running experiments, developing new tools & evaluation suites, working cross-functionally across multiple research and product teams, and striving for beneficial & safe uses for AI.

Note: We are only open to hiring in San Francisco for this team.

Responsibilities:
Design and implement scalable technical infrastructure that enables researchers to efficiently run experiments and evaluate AI systems
Architect systems that can handle uncertain and changing requirements while maintaining high standards of reliability
Lead technical design discussions to ensure our infrastructure can support both current needs and future research directions
Partner closely with researchers, data scientists, policy experts, and other cross-functional partners to advance Anthropic’s safety mission
Interface with, and improve our internal technical infrastructure and tools
Generate net-new insights about the potential societal impact of systems being developed by Anthropic
Translate insights to inform Anthropic strategy, research, and public policy
You may be a good fit if you:
Have experience building and maintaining production-grade internal tools or research infrastructure
Take pride in writing clean, well-documented code in Python that others can build upon
Are comfortable making technical decisions with incomplete information while maintaining high engineering standards
Have experience with distributed systems and can design for scale and reliability
Have a track record of using technical infrastructure to interface effectively with machine learning models
Have experience deriving insights from imperfect data streams
Strong candidates may also have experience with:
Maintaining large, foundational infrastructure
Building simple interfaces that allow non-technical collaborators to evaluate AI systems
Working with and prioritizing requests from a wide variety of stakeholders, including research and product teams
Scaling and optimizing the performance of tools
Representative Projects:
Design and implement scalable infrastructure for running large-scale experiments on how people interact with our AI systems
Build robust monitoring systems that help us detect and understand potential misuse or unexpected behaviors
Create internal tools that help researchers, policy experts, and product teams quickly analyze dynamically changing AI system characteristics
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$315,000—$340,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Research Engineer / Scientist, Alignment Science
(View all jobs)
Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
You want to build and run elegant and thorough machine learning experiments to help us understand and steer the behavior of powerful AI systems. You care about making AI helpful, honest, and harmless, and are interested in the ways that this could be challenging in the context of human-level capabilities. You could describe yourself as both a scientist and an engineer. As a Research Engineer on Alignment Science, you'll contribute to exploratory experimental research on AI safety, with a focus on risks from powerful future systems (like those we would designate as ASL-3 or ASL-4 under our Responsible Scaling Policy), often in collaboration with other teams including Interpretability, Fine-Tuning, and the Frontier Red Team.
 
These papers give a simple overview of the topics the Alignment Science team works on: Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training, Studying Large Language Model Generalization with Influence Functions, Debating with More Persuasive LLMs Leads to More Truthful Answers, Language Models (Mostly) Know What They Know, Measuring Progress on Scalable Oversight for Large Language Models, Measuring Faithfulness in Chain-of-Thought Reasoning, Discovering Language Model Behaviors with Model-Written Evaluations.
 
Note: Currently, the team has a preference for candidates who are able to be based in the Bay Area. However, we remain open to any candidate who can travel 25% to the Bay Area.
Representative projects:
Testing the robustness of our safety techniques by training language models to subvert our safety techniques, and seeing how effective they are at subverting our interventions.
Run multi-agent reinforcement learning experiments to test out techniques like AI Debate.
Build tooling to efficiently evaluate the effectiveness of novel LLM-generated jailbreaks.
Write scripts and prompts to efficiently produce evaluation questions to test models’ reasoning abilities in safety-relevant contexts.
Contribute ideas, figures, and writing to research papers, blog posts, and talks.
Run experiments that feed into key AI safety efforts at Anthropic, like the design and implementation of our Responsible Scaling Policy.
You may be a good fit if you:
Have significant software, ML, or research engineering experience
Have some experience contributing to empirical AI research projects
Have some familiarity with technical AI safety research
Prefer fast-moving collaborative projects to extensive solo efforts
Pick up slack, even if it goes outside your job description
Care about the impacts of AI
Strong candidates may also:
Have experience authoring research papers in machine learning, NLP, or AI safety
Have experience with LLMs
Have experience with reinforcement learning
Have experience with Kubernetes clusters and complex shared codebases
Candidates need not have:
100% of the skills needed to perform the job
Formal certifications or education credentials
The expected salary range for this position is:

Annual Salary:
$280,000—$690,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Research Engineer, Interpretability
(View all jobs)
Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
When you see what modern language models are capable of, do you wonder, "How do these things work? How can we trust them?"

The Interpretability team’s mission is to reverse engineer how trained models work. We believe that a mechanistic understanding is the most robust way to make advanced systems safe. We’re looking for researchers and engineers to join our efforts. 

People mean many different things by "interpretability". We're focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do "biology" or "neuroscience" of neural networks, or as treating neural networks as binary computer programs we're trying to "reverse engineer".

We recently showed that we could extract millions of meaningful features from  Anthropic’s production Claude 3.0 Sonnet model, along with an initial demonstration of how we can use these features to change the model’s behavior by creating “Golden Gate Claude”. Achieving these results required a large engineering effort including optimizing sparse autoencoders (SAEs) across many GPUs, and building tools to visualize millions of features. Work like this is central to our roadmap of using mechanistic interpretability to improve the safety of LLMs like Claude.

A few places to learn more about our work and team are this introduction to Interpretability from our research lead, Chris Olah; a discussion of our work on the Hard Fork podcast produced by the New York Times, and this blog post (and accompanying video) sharing more about some of the engineering challenges we’d had to solve to get these results. Some of our team's notable publications include Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet, Towards Monosemanticity: Decomposing Language Models With Dictionary Learning, A Mathematical Framework for Transformer Circuits, In-context Learning and Induction Heads, and Toy Models of Superposition. This work builds on ideas from members' work prior to Anthropic such as the original circuits thread, Multimodal Neurons, Activation Atlases, and Building Blocks.

We collaborate with teams across Anthropic, such as Alignment Science and Societal Impacts to use our work to make Anthropic’s models safer.

Responsibilities:
Implement and analyze research experiments, both quickly in toy scenarios and at scale in large models
Set up and optimize research workflows to run efficiently and reliably at large scale
Build tools and abstractions to support rapid pace of research experimentation
Develop and improve tools and infrastructure to support other teams in using Interpretability’s work to improve model safety
You may be a good fit if you:
Have 5-10+ years of experience building software
Are highly proficient in at least one programming language (e.g., Python, Rust, Go, Java) and productive with python
Have some experience contributing to empirical AI research projects
Have a strong ability to prioritize and direct effort toward the most impactful work and are comfortable operating with ambiguity and questioning assumptions.
Prefer fast-moving collaborative projects to extensive solo efforts
Want to learn more about machine learning research and its applications and collaborate closely with researchers
Care about the societal impacts and ethics of your work
Strong candidates may also have experience with:
Designing a code base so that anyone can quickly code experiments, launch them, and analyze their results without hitting bugs
Optimizing the performance of large-scale distributed systems
Collaborating closely with researchers
Language modeling with transformers
GPUs or Pytorch
Representative Projects:
Building Garcon, a tool that allows researchers to easily access LLMs internals from a jupyter notebook
Setting up and optimizing a pipeline to efficiently collect petabytes of transformer activations and shuffle them.
Profiling and optimizing ML training, including parallelizing to many GPUs
Make launching ML experiments and manipulating+analyzing the results fast and easy
Creating an interactive visualization of attention between tokens in a language model
The expected salary range for this position is:

Annual Salary:
$315,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Engineering Manager, RL Engineering
(View all jobs)
San Francisco, CA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
Anthropic's RL Engineering team builds the systems, allowing large-scale distributed reinforcement learning with language models. As manager of the team, you'll support a team of machine learning and distributed systems experts with the goal of making these systems highly efficient, supporting fast iteration on model development, and continuously evolving the infrastructure to incorporate new research advances.

Our reinforcement learning system sits at the intersection of almost every technical group at Anthropic. You'll work with research teams to incorporate their innovations into our production finetuning pipeline, product teams to help us iterate quickly on customer-oriented model improvements, and infrastructure teams to make sure our training runs are as efficient and reliable as possible.

About Anthropic:
Anthropic is an AI safety and research company working to build reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our customers and society as a whole. Our interdisciplinary team has experience across ML, engineering, physics, policy, business, and product.

Responsibilities:
Prioritize the team's work in collaboration with the technical lead, research teams, and product teams to support fast iteration on research projects and training runs.
Design processes (e.g., postmortem review, incident response, on-call rotations) that help the team operate effectively.
Coach and support your reports to understand and pursue their professional growth.
Run the team's recruiting efforts efficiently, ensuring we can grow as quickly as we need through a period of rapid growth.
You may be a good fit if you:
Believe that advanced AI systems could have a transformative effect on the world and are interested in helping make sure that transformation goes well
Are an experienced manager (at least 1 year) and actively enjoy people management
Are a quick study: this team sits at the intersection of a large number of different complex technical systems that you'll need to understand (at a high level) to be effective
Strong candidates may also have:
Experience working with large language models or reinforcement learning
Experience doing research in any domain or experience working with research teams, especially as part of a "research to production" pipeline
Strong people management experience: Coaching, performance evaluation, mentorship, career development
Strong project management skills: Prioritization, communicating across team/org boundaries
Experience recruiting for your team: Predicting staffing needs, designing interview loops, evaluating candidates, and closing them
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$340,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Data Operations Manager
(View all jobs)
San Francisco, CA | New York City, NY
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the Role
Anthropic’s Research team is looking for a Data Operations Manager to help us level up our human data operations and accelerate our ability to develop models. This person will work across all operational aspects of human data management, including scoping, coordinating, procuring and managing projects and deliverables, ensuring that human data collection operations are running smoothly and that the data collected has high utility, quality, diversity, and volume. They will build and maintain strong relationships with our Human Feedback (HF) resources and optimize how we do this work on an ongoing basis.

 

Responsibilities:

Scope, coordinate, and procure data collection and labeling projects and identify and capitalize on opportunities to make them more efficient. 
Monitor ongoing projects to make sure that resources are directed appropriately, adjusting scope and instructions with new information. 
Develop and maintain strong relationships with external vendors and contractors, ensuring that our work together is high-value and low-friction.
Execute on human data projects, doing activities such as writing labeling instructions, reviewing data, and making sure we have the right mix of quality, diversity, and volume of data, as well as figuring out how to improve the tooling or instructions to make things more efficient. 
Report out on projects, including dashboards and data analysis. 
Partner with Engineering to maintain and improve our human feedback interface.
Develop and support the operations for an in-house team of human data workers.
 

You might be a good fit for this role if you:

Are extremely detail-oriented and enjoy poring over information and data line-by-line.
Have exceptional project and relationship management skills, with both internal and external parties.
Have a strong understanding of how LLMs work and of prompt engineering.
Have experience with data collection, labeling, and analysis.
Have experience using tools like SQL, Python, Tableau, etc.
 

It is particularly valuable if you:

Have experience with human data collection and labeling specific to large language models.
Have managed a team of external contractors and/or vendors before.
Have conceived of and launched new technical programs.
Have worked with researchers and engineers.
The expected salary range for this position is:

Annual Salary:
$270,000—$365,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Technical Program Manager, Security
(View all jobs)
San Francisco, CA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
Anthropic’s Security team is looking for a Technical Program Manager to own and drive programs that span both within the Security team and across the broader company. In this role, you’ll be responsible for the cross-functional strategy, planning, and execution of technical programs that both enable our Security team to protect our most valuable assets and be worthy of our users’ trust.

We are a small team of generalists who are adaptable and add value fast. We excel at maintaining a broad view of our work but diving deep into the details when necessary. We understand business goals, translate and organize them into technical programs and projects, and drive execution. We are comfortable engaging with both non-technical and technical stakeholders. You’ll have opportunities to drive a wide variety of Security-related initiatives while helping to scale our Technical Program Management function.

Responsibilities:
Drive execution of multiple simultaneous, cross-functional projects and/or programs.
Lead and manage strategic planning sessions and cross-functional prioritization.
Lead program status reviews and prepare regular stakeholder and executive communications.
Effectively set timelines and manage cross-functional project teams to deadlines through the proactive management of blockers, scope, shifting priorities, and risks.
Interface with a variety of technical and non-technical stakeholders across Anthropic.
Partner with Engineering Managers and other Technical Program Managers to improve the operational efficiency needs within teams.
Effectively manage change, shift gears comfortably, decide and act without having the total picture, and handle risk and uncertainty.
 You may be a good fit if you:
Have experience driving cross-functional projects, building longer-running programs, and interfacing with technical and non-technical stakeholders.
Have experience executing technical programs that require systems and engineering-level knowledge.
Have a deep interest in and/or a willingness to learn about cybersecurity or regulatory compliance.
Have experience leveraging LLMs to automate workflows, improve operational efficiency, and develop novel solutions for complex technical and organizational challenges. 
Have experience reporting on complex programs through data-driven benchmarks, including writing SQL queries.
Have strong interpersonal skills that enable you to influence without authority, build cross-organizational support, cooperation and action around security initiatives, policies and procedures.
Have a track record for being able to successfully organize, implement and manage complex programs and projects.
Are used to working through trade-offs, balancing competing priorities, and having your mind changed.
Strong candidates may also have some of the following:
Past experience as an engineer or similar technical role. 
Past experience as a manager. 
5+ years of experience in Technical Program Management or similar technical role.
Past experience building a centralized Technical Program Management function.
Sample Projects: 
Contributing to initiatives related to the Security Commitments listed in Anthropic’s Responsible Scaling Policy.
Partnering with cross-functional stakeholders to build a Third Party Risk Management program.
Working across Security and other cross-functional stakeholders to build an Identity program
Helping to establish our Security Operations Center (SOC). 
Driving efforts around risk management, product security, and other areas that improve the security of Anthropic.
The expected salary range for this position is:

Annual Salary:
$290,000—$365,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Technical Program Manager, Incident Operations
(View all jobs)
Dublin, IE | London, UK
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
We are looking for a Technical Program Manager to support and scale our incidents program globally. This role will partner with technical and non-technical teams across Anthropic, working to build strong foundations and processes around how Anthropic responds to novel issues. This role will also be a part of our incident management on-call, directly supporting response to urgent issues across the organization. Strong candidates will have experience operating independently in rapid-growth environments, and be excited about supporting others in doing their best work during challenging times.

Responsibilities:
Enable the continued growth of Anthropic’s incident program by owning key areas
Act as an on-call incident commander, and first point of escalation, during incidents of varying levels of severity
Ensure our internal and external communications during incidents meet Anthropic’s commitments to safety and transparency
Collaborate with teams across Anthropic to manage policies and procedures that drive our incident response program
Foster a culture of blameless learning from incidents, supporting incident reviews and identifying critical remediations
 You may be a good fit if you:
Have at least 3 years of experience working as an incident manager in a technology company, preferably in a high-growth environment
Are comfortable participating in regular on-call responsibilities as part of a small team
Have a demonstrated ability to troubleshoot complex issues
Have a knack for identifying and implementing efficient processes and policies
Excel as a member of cross-functional teams building frontier technologies and want to develop a deep understanding of our technical teams and what we are building
Have excellent project management, analytical, and problem-solving skills
Have strong communication skills especially when working with technical stakeholders
Thrive in working independently in fast-paced, high-volume, ambiguous environments 
Have a passion for navigating complex situations with an eye on customer experience
Strong candidates may also have some of the following:
Past experience as an incident manager or similar technical role
Past experience building a centralized incident management function
The expected salary range for this position is:

Annual Salary:
£200,000—£215,000 GBP
The expected salary range for this position is:

Annual Salary:
€185.000—€200.000 EUR
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Technical Program Manager, Compute
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
As a Technical Program Manager for the Compute team, you'll drive the execution of Anthropic's compute capacity planning and allocation. You'll work closely with research teams, systems engineering, and the capacity engineering team to coordinate compute transitions, optimize resource utilization, and ensure smooth migrations between compute environments. This role is critical in operationalizing our strategic compute plans and orchestrating changes in our compute capacity.

Responsibilities:
Partner with capacity engineers to understand and execute compute transition plans, including coordinating workload migrations and infrastructure spin-up/spin-down
Build and maintain relationships with research teams to deeply understand their compute requirements, dependencies, and constraints
Create and track detailed execution plans for compute transitions, ensuring clear timelines and dependencies across teams
Collaborate with Systems teams to coordinate technical implementation of compute infrastructure changes
Develop processes to better track and document team-specific compute requirements and usage patterns
Help research teams plan and execute migrations between compute environments with minimal disruption
Partner with capacity engineers to implement and drive adoption of self-service efficiency tools
Maintain clear documentation of compute allocation plans and team requirements
 You may be a good fit if you:
Have several years of technical program management experience, ideally in infrastructure or platform engineering
Are skilled at coordinating complex technical projects across multiple engineering teams
Have experience working with research teams and translating their needs into concrete technical requirements
Are comfortable diving deep into technical details while maintaining a high-level view of program status
Have strong communication skills and can effectively engage with both technical and non-technical stakeholders
Are experienced with cloud infrastructure concepts and terminology
Are highly organized and can manage multiple parallel workstreams effectively
Have a track record of building trust with engineering teams and driving technical changes through influence
Bonus: Experience with ML infrastructure, high-performance computing, or resource capacity planning
 

The expected salary range for this position is:

Annual Salary:
$290,000—$365,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.





Software Engineer, UI - Anthropic Labs
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
At Anthropic, we believe new AI capabilities are best achieved through secure foundations, not in spite of them. As capabilities grow more advanced, it is critical that progress moves forward safely and for the benefit of all society. It is the reason why security sits at the center of our work, and not as an afterthought. 

Anthropic Labs is seeking creative and versatile UI Engineers to rapidly prototype and evaluate emerging AI capabilities from our research teams. As part of the Labs team, you will work closely with researchers to validate the feasibility and product potential of cutting-edge AI breakthroughs, build lightweight demos, and generate learnings to inform Anthropic's product roadmap.

About Anthropic Labs:
Anthropic Labs serves as an internal accelerator tasked with bridging the gap between research and product development. Our mandate is to identify paradigm-shifting opportunities from research that could ship as products in a 6-12 month timeframe. We embed with research teams to provide product perspective, build prototypes, and pressure test assumptions. Successful projects will transition to product teams for launch.

Responsibilities:
Design and execute rapid UI experiments to test hypotheses about emerging AI capabilities
Build functional prototypes that demonstrate both technical viability and user experience potential
Craft intuitive interfaces that make AI capabilities accessible and understandable
Develop and refine UI patterns for effectively interacting with large language models
Balance creative exploration of novel interfaces with rigorous evaluation of usability
Generate documentation to streamline hand-off to product teams
Advocate for user experience considerations early in the research process
Flexibly contribute to a range of Labs initiatives based on organizational priorities
You may be a good fit if you:
Have experience designing and running structured experiments to validate UI/UX hypotheses
Can balance divergent thinking (exploring novel interfaces) with convergent thinking (evaluating usability)
Have hands-on experience working with modern frontend technologies (React, TypeScript, CSS)
Are comfortable with ambiguity and can devise clear testing approaches to reduce uncertainty
Have strong UI implementation skills and enjoy working on a variety of projects
Are results-oriented and maintain a user-centric approach to research
Communicate and collaborate effectively with research teams
Care about the societal impacts and ethics of your work
Care about the societal impacts and ethics of your work
Strong candidates may also have experience with:
Building lightweight UI prototypes and demos
Working with AI-powered interfaces and interactions
Designing novel interaction patterns for emerging technologies
Conducting user research and usability testing
Implementing accessible and responsive web applications
Candidates need not have:
100% of the skills needed to perform the job
Formal certifications or education credentials
Deadline to apply: None. Applications will be reviewed on a rolling basis.

The expected salary range for this position is:

Annual Salary:
$320,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.



Software Engineer, TypeScript
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
At Anthropic, we believe new AI capabilities are best achieved through secure foundations, not in spite of them. As capabilities grow more advanced, it is critical that progress moves forward safely and for the benefit of all society. It is the reason why security sits at the center of our work, and not as an afterthought. 

We're specifically looking for a Software Engineer who can take ownership of developer experience and infrastructure for a complex TypeScript project. This role will focus on making our development process more efficient, reliable, and enjoyable while maintaining high quality and security standards.

About Anthropic Labs:
Anthropic Labs serves as an internal accelerator tasked with bridging the gap between research and product development. Our mandate is to identify paradigm-shifting opportunities from research that could ship as products in a 6-12 month timeframe. We embed with research teams to provide product perspective, build prototypes, and pressure test assumptions. Successful projects will transition to product teams for launch.

Responsibilities:
Own and improve the development infrastructure for our core TypeScript project including CI/CD pipelines, test frameworks, and automated tooling
Optimize our Bun/Node.js/TypeScript build system to balance speed, reliability, and security
Design and maintain test fixtures that enable rapid, reliable development across the project
Evaluate and integrate modern JavaScript runtime environments like Bun to improve build and test performance
Maintain our npm dependencies and internal development tools
Establish and enforce TypeScript best practices throughout the codebase
Architect and maintain React component testing infrastructure including unit, integration, and visual regression tests
Define and enforce React best practices, patterns, and component architecture
Improve build tooling for optimal React development and production performance
Create and maintain reusable component fixtures and testing utilities
Create comprehensive technical documentation to help the team work effectively with our tools and practices
Advocate for and implement developer experience improvements
You may be a good fit if you:
Have 5+ years of software engineering industry experience
Have deep experience with TypeScript, React, and modern JavaScript tooling, including building and maintaining large-scale applications
Are an expert in React development, including performance optimization, modern patterns (hooks, context, suspense), and component architecture
Have strong testing expertise across the stack - from React components and hooks to end-to-end workflows - with experience designing test fixtures and maintainable testing strategies
Have hands-on experience maintaining developer infrastructure including CI/CD pipelines, build tools, and bundlers
Are passionate about developer experience and can both identify friction points and implement solutions that balance quick wins with long-term maintainability
Have experience shipping developer tools and understand what makes tools useful and adoptable
Have hands-on experience working with large language models and prompt engineering
Care about the societal impacts and ethics of your work
Have shipped a sizable TypeScript app on Windows
Strong candidates may also have experience with:
Optimizing build and test performance for large TypeScript applications
Implementing advanced React patterns like code-splitting and lazy loading
Creating developer tooling for React applications like custom lint rules and test harnesses
Working with container orchestration and cloud infrastructure
Improving developer workflows in AI/ML projects
Administering open-source JavaScript/TypeScript projects
Working with alternate JavaScript runtimes like Bun and Deno
Deadline to apply: None. Applications will be reviewed on a rolling basis.

The expected salary range for this position is:

Annual Salary:
$320,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Software Engineer, Product (Full Stack)
(View all jobs)
San Francisco, CA | New York City, NY
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
We are looking for fullstack software engineers to join our product team and help build interfaces and APIs to interact with large language models. You will work with a team of engineers and researchers to design and implement key components of our product and platform.
Responsibilities:
Develop and implement technical solutions to support user acquisition, activation, retention, and revenue growth
Build core components of the API to access large language models
Write billing, email, and other integrations with third party providers
Develop conversational interfaces that leverage the language models
Optimize the API and interfaces for performance, robustness, and ease of use
Implement tools and processes to monitor model behavior and performance
Work with researchers to improve interfaces based on interactions with real users
You might be a good fit if you:
Have 5+ years of practical experience as a fullstack software engineer, preferably building APIs and/or robust, accessible user interfaces
Have strong coding skills and experience with service-oriented architectures
Take a product-focused approach and care about building solutions that are robust, scalable, and easy to use
Enjoy working with a fast-paced team tackling cutting-edge problems in AI safety and conversational AI
Enjoy pair programming (we love to pair!)
Have a Bachelor’s degree in Computer Science, Software Engineering or comparable experience
Strong candidates may also:
Have worked with NLP and ML models before and understand their capabilities and limitations
Have experience with REST APIs
Have experience operating on 0 to 1 products and/or in a startup environment 
Have experience with React and Frontend frameworks
The expected salary range for this position is:

Annual Salary:
$300,000—$405,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Software Engineer, Model Context Protocol
(View all jobs)
London, UK
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
At Anthropic, we're building MCP (Model Context Protocol) as the industry standard for AI context integration. Since its launch in November 2024, developers have created hundreds of integrations, enabling AI models to securely and efficiently connect with external context, tools, and capabilities. As a Software Engineer on the MCP team, you'll help shape the future of AI integrations while working in the open with a vibrant developer community.

About the MCP team:
The MCP team focuses on protocol development, developer experience, and ecosystem growth. Drawing inspiration from successful open source teams, we balance the needs of our internal products with those of the broader developer community. Our team works in public, engaging directly with developers and maintaining high standards for backwards compatibility, security, and performance.

Responsibilities:
Design and implement core protocol features in collaboration with the open source community
Build and maintain high-quality SDKs and reference implementations
Drive technical discussions and decision-making through public RFCs and GitHub issues
Support both external developers and internal teams building on MCP
Develop showcase implementations that demonstrate MCP's capabilities
Write clear, comprehensive technical documentation
Participate in code reviews and provide mentorship to community contributors
Help shape the technical direction of the protocol while ensuring backward compatibility
You may be a good fit if you:
Have 5+ years of software engineering experience
Have experience contributing to or maintaining open source projects
Are comfortable working in public and engaging with developer communities
Have strong technical communication skills, both written and verbal
Have experience designing and implementing protocols, APIs, or developer platforms
Are passionate about developer experience and building for other engineers
Can balance competing needs from various stakeholders while maintaining technical excellence
Have experience with TypeScript/JavaScript and Python ecosystems
Care about security, scalability, and backwards compatibility
Are excited about AI and its potential impact on developer tools
Strong candidates may also:
Track record of successful open source contributions or project maintenance
Experience with AI/ML systems or large language models
Background in developer tools or platform engineering
Experience with protocol design and versioning
Public speaking experience at technical conferences
Experience building and supporting enterprise integrations
Candidates need not have:
Previous experience with AI systems specifically
Formal computer science education
A large open source following or presence
Deadline to apply: None. Applications will be reviewed on a rolling basis.

The expected salary range for this position is:

Annual Salary:
£255,000—£450,000 GBP
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.





Software Engineer, Model Context Protocol
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
At Anthropic, we're building MCP (Model Context Protocol) as the industry standard for AI context integration. Since its launch in November 2024, developers have created hundreds of integrations, enabling AI models to securely and efficiently connect with external context, tools, and capabilities. As a Software Engineer on the MCP team, you'll help shape the future of AI integrations while working in the open with a vibrant developer community.

About the MCP team:
The MCP team focuses on protocol development, developer experience, and ecosystem growth. Drawing inspiration from successful open source teams, we balance the needs of our internal products with those of the broader developer community. Our team works in public, engaging directly with developers and maintaining high standards for backwards compatibility, security, and performance.

Responsibilities:
Design and implement core protocol features in collaboration with the open source community
Build and maintain high-quality SDKs and reference implementations
Drive technical discussions and decision-making through public RFCs and GitHub issues
Support both external developers and internal teams building on MCP
Develop showcase implementations that demonstrate MCP's capabilities
Write clear, comprehensive technical documentation
Participate in code reviews and provide mentorship to community contributors
Help shape the technical direction of the protocol while ensuring backward compatibility
You may be a good fit if you:
Have 5+ years of software engineering experience
Have experience contributing to or maintaining open source projects
Are comfortable working in public and engaging with developer communities
Have strong technical communication skills, both written and verbal
Have experience designing and implementing protocols, APIs, or developer platforms
Are passionate about developer experience and building for other engineers
Can balance competing needs from various stakeholders while maintaining technical excellence
Have experience with TypeScript/JavaScript and Python ecosystems
Care about security, scalability, and backwards compatibility
Are excited about AI and its potential impact on developer tools
Strong candidates may also:
Track record of successful open source contributions or project maintenance
Experience with AI/ML systems or large language models
Background in developer tools or platform engineering
Experience with protocol design and versioning
Public speaking experience at technical conferences
Experience building and supporting enterprise integrations
Candidates need not have:
Previous experience with AI systems specifically
Formal computer science education
A large open source following or presence
Deadline to apply: None. Applications will be reviewed on a rolling basis.

The expected salary range for this position is:

Annual Salary:
$320,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.



Software Engineer, Mobile (iOS or Android)
(View all jobs)
San Francisco, CA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
We're looking for seasoned iOS and Android engineers to join our Claude mobile product team and help build apps that harness the transformative power of advanced language models. Our mission is to unlock the potential of advanced AI through elegant, user-friendly mobile applications that put unprecedented capabilities at users' fingertips. You will work with a talented team of engineers, researchers, design and Product teams to design and implement key components of our products. Join us in this exciting mission to transform how people engage with technology and unlock new realms of human potential.

Responsibilities:
Architect and implement cutting-edge iOS or Android applications
Develop novel solutions leveraging AI technologies
Optimize performance at all levels of the mobile stack
Champion best practices in mobile development
Obsessive attention to detail and app experience
Contribute to backend systems as needed
You might be a good fit if you have:
7+ years of iOS or Android development experience and proficiency with latest mobile platform capabilities/intricacies, including
Expertise in Swift, UIKit, SwiftUI, and iOS frameworks, and/or
Expertise in Kotlin, Jetpack Compose, Android SDK and the Android ecosystem
Practical experience with full-stack development and comfort working with backend technologies
0 to 1 experience building successful products in early stage environments 
A proven track record of shipping impactful, high-adoption mobile applications
Experience building applications that utilize modern ML/AI technology
Excellent communication and mentorship skills
Thrive in a fast-paced, collaborative environment and and enjoy working closely with cross functional partners and teammates
Strong candidates may have:
3D graphics, visual effects, and audio and video streaming on mobile
A vision for the future of human-machine interaction and a drive to make that vision a reality
The expected salary range for this position is:

Annual Salary:
$320,000—$405,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Software Engineer, Growth
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role
We are looking for product engineers to join our Claude.ai product team as founding members of our growth initiative. These key roles will help drive user acquisition, engagement, and retention through data-driven strategies and technical implementations. At Anthropic, we're not just building AI tools; we're reimagining how AI can enhance and expand its user base! As a founding member of the growth team, you will have a unique opportunity to shape our growth strategy from the ground up. You will work with a cross-functional team of engineers, data scientists, marketers, and product managers to design, implement, and optimize growth initiatives that scale our AI-powered tools and maximize their impact.

Responsibilities:
Develop and implement technical solutions to support user acquisition, activation, retention, and revenue growth
Design and execute A/B tests and experiments to optimize user onboarding, feature adoption, and overall product experience
Collaborate with product and marketing teams to identify growth opportunities and translate them into technical requirements
Implement tracking and attribution systems to understand user behavior and measure the effectiveness of growth initiatives
Contribute to the development of AI-powered personalization and recommendation systems to enhance user engagement
You might be a good fit if you:
Have 6+ years of experience as a software engineer, with a focus on growth engineering or related field, and strong fullstack practical coding skills
Take a data-driven approach to problem-solving, with a keen eye for identifying patterns and opportunities in user behavior and metrics
Are passionate about the potential of AI to reach and benefit a wide audience, and eager to tackle challenges in scaling AI products
Have 0 to 1 experience with a proclivity towards rapid experimentation and learning, while maintaining high standards for code quality and user experience
Thrive in a fast-paced, collaborative environment and enjoy working closely with cross-functional partners and teammates
Strong candidates may also:
Have experience with machine learning and AI technologies, particularly in the context of personalization and recommendation systems
Have experience with product-led growth strategies and implementing viral loops
Have experience with user segmentation and cohort analysis
Have experience with data analysis and experimentation frameworks
Have prior experience operating in the capacity of a product manager 
Possess a vision for the future of AI product growth and a drive to make that vision a reality
The expected salary range for this position is:

Annual Salary:
$300,000—$405,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Software Engineer, Employee Acceleration Tools
(View all jobs)
Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
Anthropic is looking for an empathetic engineer to build internal tools that enable and increase productivity for our employees, including scenarios for fraud, trust & safety, sales, and support teams. You'll collaborate closely with internal users to understand needs and create efficient solutions, often augmenting the tools with Claude for a greater experience and impact. On Employee Acceleration Tools, we are passionate about delighting and enabling our users through thoughtful and easy-to-use everyday solutions.

At Anthropic, we're building towards an ambitious mission of ensuring AI systems are safe and beneficial to humanity. Our Employee Acceleration Tools team plays a crucial role in this mission by enabling our teams to work efficiently and securely at scale. 

We have multiple roles open on this team and are looking for experienced engineers at different stages in their career who are excited about this space and our mission.

Responsibilities:
Rapidly design, prototype and build full-stack internal tools for business-critical use cases
Consult with different teams to deeply understand their workflows and identify opportunities for improved productivity through engineering
Iterate rapidly based on user feedback to continuously improve our tools
Create intuitive interfaces that make complex tasks simple and efficient
Monitor system reliability, build for operational excellence, and lead incident response when issues arise
Champion best practices in API design, security, and user experience
You may be a good fit if you:
Have 4-10 years experience building production, full-stack software with a focus on usability
Have experience building and maintaining scalable internal applications and platforms
Excel at modern web development (React, TypeScript, Node.js)
Bring strong experience with cloud technologies and services (AWS/GCP/Azure)
Demonstrate a focus on reliability and iterative improvement
Communicate with empathy and strive to understand user needs
Strong candidates may also:
Enjoy collaborating cross-team and working with users to gain alignment on requirements and functionality
Have experience implementing accessibility best practices to ensure products are usable and beneficial for all users
Have experience balancing trade-offs while maintaining security, privacy, and reliability standards
Coach and mentor other engineers
Have experience anticipating changing business needs to create technical roadmaps
Be able to obtain a US Government Clearance
 
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

Location Preference: We welcome applicants from all states, but preference will be given to candidates based in the Seattle area as this position is part of a Seattle-based team.

The expected salary range for this position is:

Annual Salary:
$300,000—$405,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Software Engineer, Cloud Platform
(View all jobs)
San Francisco, CA | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role
We are seeking an experienced backend software engineer to join our Technical Partnerships team.  You will help build and extend Anthropic’s integrations with key, major cloud service partners that make our large language models and APIs available within their customer marketplaces. You will join a team of engineers that collaborates closely with teams across Anthropic research and product engineering to learn the inner workings and the core infrastructure needed to serve our frontier models to customers. You will also collaborate closely with the product engineering teams at our partner organizations to efficiently scale delivery of Claude to their vast audiences of developers.

Responsibilities
Optimize accelerator utilization – accelerator chips are gold in the AI world. By helping to measure and optimize the allocation of chips serving Anthropic’s models, you can play a key role in helping these precious resources go to their best possible use.
Collaborate on and implement features – Anthropic is constantly innovating in API and LLM features; you will play a critical role in designing and implementing these features to function well within third-party marketplace deployments.
Trust and safety – AI safety is the core of Anthropic’s mission and permeates every aspect of LLM research, model development, and customer access. Maintaining AI safety on third party platforms poses unique challenges that you will help solve.
Build and test infrastructure – you will work to improve and extend the infrastructure needed to package and test Anthropic’s core inference technology for distribution within third party platforms.  This work is a force-multiplier for our teams and our partner teams as it accelerates our ability to reliably launch new models and new features to customers.
Design and maintain observability and live site operations – you will collaborate closely with both our first-party observability engineers and our engineers within our third-party partner organizations to ensure our services achieve high uptime and consistently excellent performance for customers.
Contribute to Anthropic’s core mission with your innovative ideas and product/systems enhancements to build ever-better beneficial AI systems.
You may be a good fit if you
Have 5-15+ years of experience as a software engineer building and operating mission-critical backend systems at scale
Have strong practical coding skills (including Python) and experience with complex distributed systems
Are adept at designing highly observable code and systems that operate reliably, at scale
Take a customer-focused approach to building infrastructure, backend systems, and customer-facing APIs
Enjoy working in a fast-paced, early environment; comfortable with adapting priorities as driven by the rapidly evolving AI space
Have excellent written and verbal communication skills and comfort with a high degree of collaboration with both internal and external engineers and product managers
Have a proclivity for “leaving it better than you found it”: making things better without letting perfect be the enemy of good
Are motivated by developing AI responsibly and safely
Strong candidates may also have experience with
Integrating LLM APIs into products or services
Experience developing software services in Rust
Tools like Kubernetes, Docker, containerization tech
Deep experience building services on AWS or GCP
Code performance optimization or service cost optimization
Holding the pager for a critical live site service or taking the role of incident manager
Direct interaction with customers or partners during the implementation or support phases of a product or service deployment

Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$300,000—$405,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.






Software Engineer, Billing
(View all jobs)
New York City, NY
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
Anthropic is looking for an experienced software engineer with deep expertise in SaaS billing systems to join our Accounts Platform team. You will lead the design and implementation of our billing infrastructure, working at the intersection of our core product, financial systems, and customer-facing features. This role is crucial for scaling our revenue operations and ensuring a seamless customer experience.

Responsibilities:
Architect and implement robust billing systems that handle complex pricing models, usage-based billing, subscription management, and commitments spanning multiple products
Design and maintain integrations with payment processors, accounting systems, and financial reporting tools
Enable scalable usage tracking and metering for API consumption
Implement compliant tax calculation and reporting systems for global markets
Create self-service billing interfaces for customer account management
Develop automated systems for invoicing, revenue recognition, and financial reconciliation
Lead technical discussions with stakeholders to define billing requirements and solutions
You might be a good fit if you:
Have 7+ years of software engineering experience, with at least 3 years focused on billing systems
Have extensive experience implementing and maintaining production billing systems using platforms like Stripe, Metronome, or similar
Are well-versed in handling complex pricing models, usage-based billing, and subscription management
Have strong experience with payment processing, financial compliance, and security requirements
Are experienced with SQL and database design for financial systems
Have a track record of building resilient systems with strict consistency requirements
Strong candidates may also:
Have experience with international payment systems and multi-currency billing
Have worked with financial reporting and revenue recognition systems
Have a strong handle on real-time usage tracking and metering systems
Are familiar with tax compliance systems and regulations
Have experience with financial audit requirements and SOC compliance
Have built integrations with enterprise billing systems

Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$300,000—$405,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Software Engineer, Anthropic Labs
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
At Anthropic, we believe new AI capabilities are best achieved through secure foundations, not in spite of them. As capabilities grow more advanced, it is critical that progress moves forward safely and for the benefit of all society. It is the reason why security sits at the center of our work, and not as an afterthought. 

Anthropic Labs is seeking versatile and collaborative Software Engineers to rapidly prototype and evaluate emerging AI capabilities from our research teams. As part of the Labs team, you will work closely with researchers to validate the feasibility and product potential of cutting-edge AI breakthroughs, build lightweight demos, and generate learnings to inform Anthropic's product roadmap.

About Anthropic Labs:
Anthropic Labs serves as an internal accelerator tasked with bridging the gap between research and product development. Our mandate is to identify paradigm-shifting opportunities from research that could ship as products in a 6-12 month timeframe. We embed with research teams to provide product perspective, build prototypes, and pressure test assumptions. Successful projects will transition to product teams for launch.

Responsibilities:
Design and execute rapid experiments to test hypotheses about emerging AI capabilities, with a focus on minimal viable testing approaches
Balance creative exploration of possibilities with rigorous evaluation of feasibility and impact
Build functional prototypes that demonstrate both technical viability and product potential
Develop and refine prompting strategies to effectively leverage large language models
Generate documentation to streamline hand-off to product teams
Advocate for product and usability considerations early in the research process
Flexibly contribute to a range of Labs initiatives based on organizational priorities
You may be a good fit if you:
Have 5+ years of software engineering industry experience
Have strong technical skills across the stack and enjoy working on a variety of projects
Are results-oriented and maintain a user-centric approach to research
Communicate and collaborate effectively with research teams
Pick up slack, even if it goes outside your job description
Have experience designing and running structured experiments to validate technical and product hypotheses
Can balance divergent thinking (exploring possibilities) with convergent thinking (evaluating feasibility)
Have hands-on experience working with large language models and prompt engineering
Are comfortable with ambiguity and can devise clear testing approaches to reduce uncertainty
Care about the societal impacts and ethics of your work
Strong candidates may also have experience with:
Building lightweight product prototypes and demos
Working with large language models and related AI architectures
Designing user flows, wireframes, or UI/UX for AI-powered applications
Conducting user research, interviews, and usability testing
Candidates need not have:
100% of the skills needed to perform the job
Formal certifications or education credentials
Deadline to apply: None. Applications will be reviewed on a rolling basis.

The expected salary range for this position is:

Annual Salary:
$320,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.









Program Manager, International Expansion
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

We are seeking an experienced Senior Program Manager to drive the execution of Anthropic's international expansion initiatives. This collaborative leader will coordinate and align cross-functional teams to successfully implement our global growth strategy. This role sits in a combined Programs organization responsible for driving key work across Anthropic. This role focuses on executing Anthropic's international strategy through precise program management, seamless coordination, and operational excellence. We are seeking someone who excels at driving complex programs forward, ensuring alignment across multiple workstreams, and creating repeatable processes that scale.

In this role, you will be the operational backbone of our international expansion, ensuring teams stay coordinated and aligned throughout each phase of market entry. Your primary focus will be on execution excellence - from maintaining clear timelines and dependencies across teams to establishing efficient processes that help us move faster and more effectively across regions.

Responsibilities 
Execute the established market entry roadmap through detailed project planning and cross-functional coordination
Create and maintain comprehensive program timelines that align workstreams across Legal, Finance, Product, Sales, and other teams
Establish clear mechanisms to track progress, surface blockers, and drive resolution across multiple concurrent market entries
Develop and implement repeatable operational processes that can scale across multiple regions
Ensure seamless coordination between global teams through effective communication and project management frameworks
Provide regular status updates and maintain clear visibility into program health for stakeholders
Drive operational excellence through documentation of processes, lessons learned, and best practices
Identify and resolve cross-functional dependencies and roadblocks to keep programs on track
You may be a good fit if you 
Have demonstrated experience executing complex, multi-stakeholder programs, particularly those involving international operations
Excel at creating structure and processes that bring clarity to complex initiatives
Have several years of professional experience in program management with global business and operations teams
Have a track record of driving execution excellence in cross-functional initiatives
Have experience coordinating teams across multiple time zones and regions
Have exceptional organizational and communication skills, with ability to maintain alignment across diverse stakeholder groups
Have a high threshold for managing multiple concurrent workstreams while maintaining attention to detail
Thrive in fast-paced environments and can adapt processes to meet evolving needs
Are passionate about Anthropic's mission and committed to ensuring AI is developed safely
Example Programs: 
Coordinating phased market entry execution across functions (Legal, Sales, Marketing, Product, etc.)
Managing timelines and dependencies for entity creation and operational setup
Driving alignment and execution of localization efforts across product surfaces
Implementing repeatable processes for market entry operations
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$230,000—$275,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Product Manager, Research
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role
As a Product Manager for the Research organization at Anthropic, you will own the ideation and deployment of new products as we advance frontier, safe AI technology. Research product managers’ primary mission is to make Anthropic’s models and research–the underlying magic of all of our products– delight end users and builders. We partner with our world class researchers on developing new versions of Claude and bringing advanced versions of research to market including Golden Gate Claude and Computer Use. You will work closely with our research teams to help productize applied research and identify high-potential use cases grounded in customer needs. 

We are looking for someone passionate about developing safe and beneficial artificial intelligence technologies. You should have experience rapidly prototyping and launching innovative technologies and products that open imaginations and possibilities. You thrive in ambiguous environments and exercise good judgement in high stakes situations.

Responsibilities:
Lead vision, strategy, roadmap and execution of frontier technologies that leverage the latest AI capabilities to solve real-world problems
Rapidly prototype and experiment with different products and services to validate product market fit
Act as the voice of the customer, embrace user feedback and synthesize insights into actionable product requirements, user stories, and product specifications
Analyze metrics to inform future product development 
Understand AI landscape and ecosystem, ensuring we have an objective view of market capabilities and our position
Ability to work and influence across a diverse set of stakeholders, including researchers as well as product engineering and platform engineering
You may be a good fit if you have:
5+ years in product management, experience launching new products and scaling existing products
Technical background with experience working cross functionally with engineering teams to ship technical products
Experience working with or applying Large Language Models in products
Experience in the AI or machine learning industry
Data-driven mindset with Python and SQL working proficiency a must
The ability to navigate and execute amidst ambiguity, and to flex into different domains based on the business problem at hand,  finding simple, easy-to-understand solutions
Track record of launching products that have found distribution or commercial success
Excitement for engaging in cross-organizational collaboration, working through trade-offs, and balancing competing priorities
Ability to clearly articulate complex technical concepts to non-technical audiences in written and verbal communication
Passion for using AI to create safe and beneficial products
Think creatively about the risks and benefits of new technologies, and think beyond past checklists and playbooks
You stay up-to-date and informed by taking an active interest in emerging research and industry trends
Have a creative hacker spirit and love solving puzzles
Deadline to apply: None. Applications will be reviewed on a rolling basis.
The expected salary range for this position is:

Annual Salary:
$305,000—$385,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Product Manager, Enterprise - Claude.ai
(View all jobs)
San Francisco, CA | New York City, NY
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the Role
As the Product Manager for Enterprise at Claude.ai, you will drive Claude's adoption and success across large organizations. You'll own the end-to-end enterprise experience, from initial deployment to scaled adoption, focusing on security, controls, and integration capabilities that enable organizations to confidently deploy Claude. Working at the intersection of AI capabilities and enterprise needs, you'll transform Claude into a trusted enterprise solution that delivers measurable ROI across teams and functions.

Responsibilities:
Product Strategy & Vision
Define and execute the enterprise product strategy, balancing security and controls with ease of deployment and adoption
Develop a clear roadmap for enterprise features including RBAC, audit logging, and vertical-specific compliance needs
Identify and prioritize key enterprise workflows and integration points that drive organizational value and expansion
Enterprise Product Development
Partner with engineering to build enterprise-grade security features, admin controls, and deployment tools
Create scalable solutions for user management, team collaboration, and usage analytics
Design and implement enterprise integration patterns (e.g., Slack, data warehouses, CRM systems)
Drive development of industry-specific features and compliance capabilities
Cross-functional Leadership
Partner with sales and customer success to understand enterprise requirements and support deal cycles
Work closely with security and compliance teams to meet enterprise standards
Collaborate with platform teams on integration frameworks and APIs
Engage with marketing to develop enterprise positioning and materials
You may be a good fit if you have:
5+ years of product management experience, with significant experience in enterprise software
A track record of successfully launching and scaling enterprise products
Strong understanding of enterprise security, compliance, and deployment requirements
Experience with product-led growth and enterprise expansion strategies
Excellence in cross-functional collaboration and stakeholder management
Clear communication skills with ability to engage with technical and business stakeholders
Strong candidates may have:
Background in enterprise collaboration or productivity tools
Familiarity with enterprise integration patterns and systems
Understanding of vertical-specific compliance requirements (e.g., SOC2, HIPAA)
The expected salary range for this position is:

Annual Salary:
$305,000—$385,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.





Product Designer
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role
Anthropic provides an API to access Claude, our state-of-the-art LLM used by companies across many industries and use cases. Along with the API, we provide a suite of tools to help developers solve the novel challenges associated with prompt engineering and LLM deployment. We also build web and mobile apps to access the power of the Claude model. Read more here for the type of features we build. 

We are seeking a talented and experienced Product Designer to join our team, to help build outstanding experiences that put our mission first and go from idea to fully scaled deployment. The ideal candidate will have a deep understanding of user-centric design, a strong portfolio showcasing their craft, and a passion for pushing the boundaries of what's possible with AI.

Responsibilities:
Contribute to the strategic direction of our tools, rooted in deep user empathy
Define feature areas with excellent attention to detail and polish, identifying opportunities to improve quality and consistency of broader flows
Craft beautiful, polished, and delightful user interfaces that build trust and showcase the power of our AI technology
Collaborate with product managers, engineers, AI researchers and other stakeholders to define product vision, strategy and roadmaps
Rapidly prototype ideas using code and other methods to communicate concepts and build excitement
Find creative ways to ship high-quality work in a fast-paced, often ambiguous, resource-constrained startup environment
You may be a good fit if you have:
8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred)
Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms
Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments
Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority
Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities
Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred
The expected salary range for this position is:

Annual Salary:
$260,000—$305,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.



Engineering Manager, Growth
(View all jobs)
San Francisco, CA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role
Since launch, the Anthropic API has seen rapid growth and adoption by companies of all sizes to build AI applications with our industry-leading models. We're looking for an experienced engineering leader to lead our API Experience team, responsible for creating a world-class developer experience for the Anthropic API. The team owns the end-to-end flow for using the Anthropic API, everything from onboarding to documentation to prompt engineering tools.

Responsibilities:
Lead a fullstack product engineering team in crafting an industry-defining developer experience for building AI applications
Collaborate with product and research partners to define vision and developer roadmap
Create clarity for the team and stakeholders in an ambiguous and evolving environment 
Work cross functionally to design clear interfaces and processes for shipping products that span many teams
Take an inclusive, equitable approach to hiring and coaching top technical talent, and maintain a high performing team
You may be a good fit if you have:
4+ years of experience as an engineering manager
A background in fullstack development, ideally building API products for external developers
A strong product mindset and willingness to wear multiple hats (e.g. marketing, user research, product management)
Experience recruiting, scaling, and retaining engineering talent in a high growth environment
Excellent leadership and communication skills
Demonstrated success in building a culture of belonging, and of product and engineering excellence
Strong candidates may also have experience with:
Building products from zero to one in a startup environment 
Expertise in modern web development stacks (React, Next.js, etc)
Experience working on AI/ML products
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$320,000—$405,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Engineering Manager, Anthropic Labs
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role
Anthropic Labs is seeking an Engineering Manager to lead and grow our team of software engineers working on early-stage AI capabilities. As the Engineering Manager for Labs, you'll create an environment where engineers can thrive in the inherently uncertain world of 0-1 development, while maintaining clear direction and stability for the team.

You'll partner closely with designers, product managers, and research teams to transform emerging AI capabilities into potential products. Success in this role requires exceptional interpersonal intelligence, the ability to facilitate rapid learning cycles, and skill in helping teams navigate the natural ups and downs of early-stage development.

About Anthropic Labs:
Anthropic Labs serves as an internal accelerator tasked with bridging the gap between research and product development. Our mandate is to identify paradigm-shifting opportunities from research that could ship as products in a 6-12 month timeframe. We embed with research teams to provide product perspective, build prototypes, and pressure test assumptions. Successful projects will transition to Product teams for launch.

Responsibilities:
Lead and coach a high-performing team of software engineers through the complexities of 0-1 development
Partner effectively with design and product leaders to align on direction and execution
Create a balanced environment that encourages both creative exploration and rigorous evaluation
Provide clear, actionable feedback and support for engineer growth and development
Help teams develop structured approaches to testing hypotheses and evaluating results
Facilitate effective collaboration between Labs engineers and research teams
Drive adoption of Labs' prototypes and learnings to inform company-wide product strategy and planning
Represent the Labs perspective and roadmap in discussions with research, product, and leadership stakeholders
You may be a good fit if you:
Have 5+ years of engineering management experience leading high-performing teams in ambiguous, early-stage environments
Excel at creating psychological safety and helping teams navigate uncertainty
Have strong strategic thinking skills to identify high-potential research breakthroughs and paths to productization
Demonstrate exceptional interpersonal intelligence and ability to guide teams through rapid pivots
Have excellent cross-functional leadership skills to build alignment between research, engineering, product and design
Are skilled at facilitating decision-making rather than imposing solutions
Have expertise in attracting, mentoring and retaining top talent from diverse backgrounds and skill sets
Have excellent communication skills to tell the story of Labs' work and impact to leadership and the company
Have a comprehensive technical understanding across full-stack engineering, ML/AI, data science and modern product development
Care deeply about responsibly pushing the boundaries of AI capabilities in service of Anthropic's mission
Deadline to apply: None. Applications will be reviewed on a rolling basis.

The expected salary range for this position is:

Annual Salary:
$320,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Head of Product Engineering
(View all jobs)
San Francisco, CA | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role
As the Head of Engineering at Anthropic, you will play a crucial role in shaping the future of our engineering organization and contributing to our mission of developing safe and ethical AI. Reporting directly to the CPO, you will lead a rapidly growing team with plans to continue to expand in size over the coming year. This role offers a unique opportunity to be at the forefront of AI development while balancing the challenges of maintaining high-velocity product delivery with our commitment to AI safety.
Responsibilities:
Recruit, manage, and develop senior engineering managers to oversee all product development initiatives
Collaborate with senior Individual Contributors (ICs) and Engineering Managers (EMs) to establish and refine excellent engineering practices, from hiring to execution and iteration
Serve as a public face for Anthropic's engineering brand, representing the company at industry events and in the tech community
Collaborate with our cloud partners to ensure Anthropic models are performant and available
Oversee all of Anthropic's applications, APIs, and developer experiences
Work closely with product management leads to ensure alignment between engineering and product goals
Lead org-wide hiring efforts to support the team's growth while maintaining a high bar for talent
Implement performance management processes to support the team's development and address any challenges
Spearhead initiatives to adopt Claude to accelerate our own engineering team's productivity
Balance Anthropic's mission of building safe AI with the need to maintain a high velocity of shipping products
Contribute to the overall technical strategy of the company
Meaningfully invest in a culture of belonging, equity, and impact 
You may be a good fit if you have:
9+ years of experience as an engineering leader, including experience as a VP or equivalent role, overseeing user-facing product engineering organizations
A proven track record of scaling and shaping large (350+) engineering organizations
The ability to operate at both a strategic level and dive into technical details when necessary
Experience managing and developing engineering directors, managers, and senior ICs
Strong technical acumen and the ability to guide architectural decisions
Excellent communication skills, a commitment to transparency, and the ability to be a public-facing representative for Anthropic's engineering efforts
A deep alignment with Anthropic's mission and a passion for ethical AI development
Experience working in fast-paced, high-growth environments
Proven investment in taking an inclusive, equitable approach to hiring and team-building 
Demonstrated success in managing relationships with cross-functional stakeholders, executives, and external partners 
The ability to balance long-term strategic thinking with day-to-day operational excellence
Strong candidates may have:
A background in building developer-facing products or APIs
Knowledge of best practices in AI safety and ethical AI development
Experience leading engineering teams in a research-heavy environment
A track record of successful public speaking or technical writing
Experience implementing engineering productivity tools and processes
A history of contributing to open-source projects or fostering open-source communities
Familiarity with the unique challenges of AI product development and deployment
Additional experience overseeing platform/infrastructure engineering teams 

Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$485,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Staff Software Engineer, AI Reliability Engineering
(View all jobs)
London, UK
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role

Anthropic is seeking talented and experienced Reliability Engineers, including Software Engineers and Systems Engineers with experience and interest in reliability, to join our team. We will be defining and achieving reliability metrics for all of Anthropic’s internal and external products and services. While significantly improving reliability for Anthropic’s services, we plan to use the developing capabilities of modern AI models to reengineer the way we work. This team will be a critical part of Anthropic’s mission to bring the capabilities of groundbreaking AI technologies to benefit humanity in a safe and reliable way.

Responsibilities:

Develop appropriate Service Level Objectives for large language model serving and training systems, balancing availability/latency with development velocity.
Design and implement monitoring systems including availability, latency and other salient metrics.
Assist in the design and implementation of high-availability language model serving infrastructure capable of handling the needs of millions of external customers and high-traffic internal workloads.
Develop and manage automated failover and recovery systems for model serving deployments across multiple regions and cloud providers.
Lead incident response for critical AI services, ensuring rapid recovery and systematic improvements from each incident
Build and maintain cost optimization systems for large-scale AI infrastructure, focusing on accelerator (GPU/TPU/Trainium) utilization and efficiency
You may be a good fit if you:

Have extensive experience with distributed systems observability and monitoring at scale
Understand the unique challenges of operating AI infrastructure, including model serving, batch inference, and training pipelines
Have proven experience implementing and maintaining SLO/SLA frameworks for business-critical services
Are comfortable working with both traditional metrics (latency, availability) and AI-specific metrics (model performance, training convergence)
Have experience with chaos engineering and systematic resilience testing
Can effectively bridge the gap between ML engineers and infrastructure teams
Have excellent communication skills.
Strong candidates may also:

Have experience operating large-scale model training infrastructure or serving infrastructure (>1000 GPUs)
Have experience with one or more ML hardware accelerators (GPUs, TPUs, Trainium, e.g.)
Understand ML-specific networking optimizations like RDMA and InfiniBand.
Have expertise in AI-specific observability tools and frameworks
Understand ML model deployment strategies and their reliability implications
Have contributed to open-source infrastructure or ML tooling
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
£255,000—£390,000 GBP
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.









Staff Software Engineer, AI Reliability Engineering
(View all jobs)
San Francisco, CA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role

Anthropic is seeking talented and experienced Reliability Engineers, including Software Engineers and Systems Engineers with experience and interest in reliability, to join our team. We will be defining and achieving reliability metrics for all of Anthropic’s internal and external products and services. While significantly improving reliability for Anthropic’s services, we plan to use the developing capabilities of modern AI models to reengineer the way we work. This team will be a critical part of Anthropic’s mission to bring the capabilities of groundbreaking AI technologies to benefit humanity in a safe and reliable way.

Responsibilities:

Develop appropriate Service Level Objectives for large language model serving and training systems, balancing availability/latency with development velocity.
Design and implement monitoring systems including availability, latency and other salient metrics.
Assist in the design and implementation of high-availability language model serving infrastructure capable of handling the needs of millions of external customers and high-traffic internal workloads.
Develop and manage automated failover and recovery systems for model serving deployments across multiple regions and cloud providers.
Lead incident response for critical AI services, ensuring rapid recovery and systematic improvements from each incident
Build and maintain cost optimization systems for large-scale AI infrastructure, focusing on accelerator (GPU/TPU/Trainium) utilization and efficiency
You may be a good fit if you:

Have extensive experience with distributed systems observability and monitoring at scale
Understand the unique challenges of operating AI infrastructure, including model serving, batch inference, and training pipelines
Have proven experience implementing and maintaining SLO/SLA frameworks for business-critical services
Are comfortable working with both traditional metrics (latency, availability) and AI-specific metrics (model performance, training convergence)
Have experience with chaos engineering and systematic resilience testing
Can effectively bridge the gap between ML engineers and infrastructure teams
Have excellent communication skills.
Strong candidates may also:

Have experience operating large-scale model training infrastructure or serving infrastructure (>1000 GPUs)
Have experience with one or more ML hardware accelerators (GPUs, TPUs, Trainium, e.g.)
Understand ML-specific networking optimizations like RDMA and InfiniBand.
Have expertise in AI-specific observability tools and frameworks
Understand ML model deployment strategies and their reliability implications
Have contributed to open-source infrastructure or ML tooling
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$320,000—$485,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.





Software Engineer, Data Ingestion
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About Anthropic 

Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.


About the Role: 

We are looking for a Software Engineer to lead the “Tokens: Data Acquisition” team, which owns the problem of acquiring all of the available data on the internet through a large scale web crawler, and through data partnerships. Most of Anthropic’s research and product builds on top of the best pretrained models that we can produce, which in turn rely on having the best pretraining data. Successfully scaling our data corpus is critical to our continued efforts at producing the best pretrained models.

The team’s responsibilities are as follows:

Develop and maintain an internet scale web crawler responsible for crawling for accessible internet data
Build required pipelines to quickly ingest data from potential partners for data quality assessments or from other sources
Improve observability of the crawler systems
Build a set of 1-off deep crawlers to improve recall for data from especially beneficial sources 
Responsibilities: 

Develop and maintain our large-scale web crawler
Build pipelines for data ingestion, analysis, and quality improvement
Build specialized crawlers for high-value data sources
Build tools for improving the observability and debuggability of crawler system
Collaborate with team members on improving data acquisition processes
Participate in code reviews and debugging sessions
You may be a good fit if you:

Believe in the transformative potential of advanced AI systems
Are interested in building a large scale system to acquire all openly accessible information on the internet
Strong candidates may have:

Extensive experience with building and running large distributed systems
Familiarity with the non-technical tradeoffs of internet-scale crawling (data privacy, robots.txt adherence, etc.)
Technical expertise: Quickly understanding systems design tradeoffs, keeping track of rapidly evolving software systems
Familiarity with Cloud-based compute and storage solutions 
Familiarity with Python
The expected salary range for this position is:

Annual Salary:
$315,000—$340,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.





Research Engineer / Research Scientist, Multimodal
(View all jobs)
London, UK
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

At Anthropic, we believe the most impactful safety research will require access to frontier AI systems. The most powerful AIs will operate not just on text but also other modes of data, including images, video and audio. Such models have potential to augment human creativity and productivity in exciting ways. However, we are very concerned about the risks introduced by powerful multimodal AIs. The Multimodal team at Anthropic builds and studies multimodal models to better understand and mitigate these risks.

Our team works across many parts of a large stack that includes training, inference, system design and data collection. Some of our core focus areas are:

Foundational Research

We develop new architectures for modeling multimodal data and study how they interact with text-only models at scale.

Building Infrastructure
We work on many infrastructure projects including:

Complex multimodal reinforcement learning environments.
High-performance RPC servers for processing image inputs.
Sandboxing infrastructure for securely collecting data.
Data Ingestion
We are more interested in running simple experiments at large scale than smaller complex experiments. This requires access to very large sources of multimodal data. We develop tooling to collect, process and clean multimodal data at scale.

Because we focus on so many areas, the team is looking to work with both experienced engineers and strong researchers, and encourage anyone along the researcher/engineer curve to apply.

You may be a good fit if you:
Have significant software engineering experience
Are results-oriented, with a bias towards flexibility and impact
Pick up slack, even if it goes outside your job description
Enjoy pair programming (we love to pair!)
Want to learn more about machine learning research
Care about the societal impacts of your work
Strong candidates may also have experience with:
High performance, large-scale ML systems
GPUs, Kubernetes, Pytorch, or OS internals
Language modeling with transformers
Reinforcement learning
Large-scale ETL
The expected salary range for this position is:

Annual Salary:
£250,000—£270,000 GBP
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.







Research Engineer / Research Scientist, Multimodal
(View all jobs)
Zürich, CH
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

You want to build cutting edge Artificial Intelligence from the ground up. You are passionate that these systems are safe and trustworthy, and care about their broader societal impact. In this role, you'll work on research, development, and infrastructure for state-of-the-art large language models, with a focus on multimodal capabilities. This role will touch all parts of the research ecosystem, from building infrastructure to developing research prototypes to running multi-thousand accelerator training jobs.You may be a good fit if some of the following apply to you:
Care deeply about the societal impacts of your work
Want to work on the frontier of Artificial Intelligence
Have substantial software engineering experience through industry, academia, or other projects
Have research experience, through writing scientific publications, or involvement in personal or industrial projects
Are results oriented and flexible in your approach
Are willing to pick up slack, even if it goes outside your job description
Like working in a close-knit team environment, and enjoy pair programming!
Strong candidates may have experience with some of the following:
High performance, large-scale Machine Learning systems
ML hardware, frameworks, and infrastructure, such as TPUs, GPUs, Jax, PyTorch, OS internals, and Kubernetes
Language modeling with transformers
Deep learning research on images, videos, audio, or other modalities
Representative projects:
Design a training loss for a new modality
Design and run experiments to evaluate the scalability of two architectural variants
Analyze and debug a large-scale training run
Scale an architecture to optimize throughput on thousands of GPUs
Build from-scratch a new deep learning architectural components
Build a pipeline to ingest a novel source of data
Build a language model evaluation
Build a tool for data visualization
Review the scientific literature in a domain write a design doc on how techniques could be applied
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.





Research Engineer / Research Scientist, Multimodal
(View all jobs)
London, UK
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

You want to build large scale ML systems from the ground up. You care about making safe, steerable, trustworthy systems. As a Research Engineer, you'll touch all parts of our code and infrastructure, whether that's making the cluster more reliable for our big jobs, improving throughput and efficiency, running and designing scientific experiments, or improving our dev tooling. You're excited to write code when you understand the research context and more broadly why it's important.
 
Note: This is an "evergreen" role that we keep open on an ongoing basis. We receive many applications for this position, and you may not hear back from us directly if we do not currently have an open role on any of our teams that matches your skills and experience. We encourage you to apply despite this, as we are continually evaluating for top talent to join our team. You are also welcome to reapply as you gain more experience, but we suggest only reapplying once per year.
 
We may also put up separate, team-specific job postings. In those cases, the teams will give preference to candidates who apply to the team-specific postings, so if you are interested in a specific team please make sure to check for team-specific job postings!
You may be a good fit if you:
Have significant software engineering experience
Are results-oriented, with a bias towards flexibility and impact
Pick up slack, even if it goes outside your job description
Enjoy pair programming (we love to pair!)
Want to learn more about machine learning research
Care about the societal impacts of your work
Strong candidates may also have experience with:
High performance, large-scale ML systems
GPUs, Kubernetes, Pytorch, or OS internals
Language modeling with transformers
Reinforcement learning
Large-scale ETL
Representative projects:
Optimizing the throughput of a new attention mechanism
Comparing the compute efficiency of two Transformer variants
Making a Wikipedia dataset in a format models can easily consume
Scaling a distributed training job to thousands of GPUs
Writing a design doc for fault tolerance strategies
Creating an interactive visualization of attention between tokens in a language model
The expected salary range for this position is:

Annual Salary:
£250,000—£270,000 GBP
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Performance Engineer
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
Running machine learning (ML) algorithms at our scale often requires solving novel systems problems. As a Performance Engineer, you'll be responsible for identifying these problems, and then developing systems that optimize the throughput and robustness of our largest distributed systems. Strong candidates here will have a track record of solving large-scale systems problems and will be excited to grow to become an expert in ML also.
You may be a good fit if you:
Have significant software engineering or machine learning experience, particularly at supercomputing scale
Are results-oriented, with a bias towards flexibility and impact
Pick up slack, even if it goes outside your job description
Enjoy pair programming (we love to pair!)
Want to learn more about machine learning research
Care about the societal impacts of your work
Strong candidates may also have experience with: 
High performance, large-scale ML systems
GPU/Accelerator programming
ML framework internals
OS internals
Language modeling with transformers
Representative projects:
Implement low-latency high-throughput sampling for large language models
Implement GPU kernels to adapt our models to low-precision inference
Write a custom load-balancing algorithm to optimize serving efficiency
Build quantitative models of system performance
Design and implement a fault-tolerant distributed system running with a complex network topology
Debug kernel-level network latency spikes in a containerized environment
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$315,000—$560,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.



Data Infra Engineer, Pretraining
(View all jobs)
San Francisco, CA | New York City, NY | Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

 
Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking a Research Engineer to join our Pretraining team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems.

Key Responsibilities
Design and implement high-performance data processing infrastructure for large language model training
Develop and maintain core processing primitives (e.g., tokenization, deduplication, chunking) with a focus on scalability
Build robust systems for data quality assurance and validation at scale
Implement comprehensive monitoring systems for data processing infrastructure
Create and optimize distributed computing systems for processing web-scale datasets
Collaborate with research teams to implement novel data processing architectures
Build and maintain documentation for infrastructure components and systems
Design and implement systems for reproducibility and traceability in data preparation
Qualifications
Strong software engineering skills with experience in building distributed systems
Expertise in Python and experience with distributed computing frameworks
Deep understanding of cloud computing platforms and distributed systems architecture
Experience with high-throughput, fault-tolerant system design
Strong background in performance optimization and system scaling
Excellent problem-solving skills and attention to detail
Strong communication skills and ability to work in a collaborative environment
Preferred Experience
Advanced degree (MS or PhD) in Computer Science or related field
Experience with language model training infrastructure
Strong background in distributed systems and parallel computing
Expertise in tokenization algorithms and techniques
Experience building high-throughput, fault-tolerant systems
Deep knowledge of monitoring and observability practices
Experience with infrastructure-as-code and configuration management
Background in MLOps or ML infrastructure
You'll thrive in this role if you
Have significant experience building and maintaining large-scale distributed systems
Are passionate about system reliability and performance
Enjoy solving complex technical challenges at scale
Are comfortable working with ambiguous requirements and evolving specifications
Take ownership of problems and drive solutions independently
Are excited about contributing to the development of safe and ethical AI systems
Can balance technical excellence with practical delivery
Are eager to learn about machine learning research and its infrastructure requirements
Sample Projects
Designing and implementing distributed computing architecture for web-scale data processing
Building scalable infrastructure for model training data preparation
Creating comprehensive monitoring and alerting systems
Optimizing tokenization infrastructure for improved throughput
Developing fault-tolerant distributed processing systems
Implementing new infrastructure components based on research requirements
Building automated testing frameworks for distributed systems
At Anthropic, we are committed to fostering a diverse and inclusive workplace. We strongly encourage applications from candidates of all backgrounds, including those from underrepresented groups in tech.

If you're excited about pushing the boundaries of AI while prioritizing safety and ethics, we want to hear from you!

The expected salary range for this position is:

Annual Salary:
$315,000—$340,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.




Staff Software Engineer, Infrastructure
(View all jobs)
San Francisco, CA, New York City, NY, Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
Anthropic is seeking talented and experienced Infrastructure Engineers to join our team and support the development, scaling, and maintenance of our cutting-edge AI systems. By joining our Infrastructure team, you will have the opportunity to work on groundbreaking AI technologies and contribute to the development of frontier models, supporting Anthropic's mission to create safe and reliable AI systems that benefit humanity.
 
We have multiple teams that are currently hiring. Team placement occurs after the interview process, taking into account your interests and experience alongside organizational needs. This flexible approach allows us to match talented engineers with the infrastructure teams where they'll have the greatest impact and growth potential:
Data Infrastructure: The Data Infrastructure team is responsible for designing, building, and maintaining the data infrastructure that powers our AI research and products. You will collaborate with cross-functional teams to understand data requirements, deliver efficient and reliable data solutions, and continuously improve our data infrastructure. Your role will involve building and optimizing data pipelines, implementing data governance best practices, monitoring and troubleshooting, and setting technical strategies for high-scale, reliable data infrastructure and pipelines. You will work with technologies such as Spark, Airflow, dbt, and cloud services from GCP and AWS, while designing processes to ensure effective team operation and continuous improvement.

Core Infrastructure: The systems team is responsible for supporting some of the largest, most sophisticated clusters in industry used to train, research, and ultimately serve AI models.  Your work will be crucial in ensuring Anthropic is able to continue reliably and safely training frontier models. You will be responsible for building systems and running large Kubernetes clusters with GPU/TPU/Tranium workloads.

Observability: Observability team is responsible for designing, building, and maintaining the observability infrastructure that ensures the reliability, performance, and efficiency of our AI systems and services. You will collaborate with cross-functional teams to understand their observability requirements and deliver solutions using technologies such as Prometheus, Splunk, Cloud Logging, Grafana, and Honeycomb. Your role will involve developing a config-driven approach to manage dashboards and alerts, implementing structured logging and tracing, optimizing the observability stack, and building a reliable system that requires minimal maintenance. You will foster a culture of operational excellence, proactive monitoring, and continuous improvement by providing managed, centralized, and usable observability tools.
Developer Productivity: The Developer Productivity team enables Anthropic researchers and engineers to be maximally effective in securely developing state-of-the-at models, and products that expose those models to users. All of the code written at Anthropic goes through systems/infrastructure built and maintained by our team. We aim to make development at Anthropic secure, efficient, and delightful.
Product Infrastructure: The Product Infrastructure team enables Anthropic's products to achieve best-in-class performance, reliability, and developer velocity by building and maintaining a robust, efficient, and scalable product infrastructure stack. 
Claudification: The Claudification team works on exciting LLMs meet developer productivity problems. 
Responsibilities:
Lead build out of industry-leading AI clusters (thousands to hundreds of thousands of machines), partnering closely with cloud service providers on cluster build out and required features
Consult with different stakeholders to deeply understand infrastructure, data and compute needs, identifying potential solutions to support frontier research and product development
Set technical strategy and oversee development of high scale, reliable infrastructure systems.
Mentor top technical talent
Design processes (e.g. postmortem review, incident response, on-call rotations) that help the team operate effectively and never fail the same way twice
You may be a good fit if you:
Have 10+ years of relevant industry experience, 3+ years leading large scale, complex projects or teams as an engineer or tech lead
Are obsessed with distributed systems at scale, infrastructure reliability, scalability, security, and continuous improvement
Strong proficiency in at least one programming language (e.g., Python, Rust, Go, Java)
Strong problem-solving skills and ability to work independently
Have a passion for supporting internal partners like research to understand their needs
Have excellent communication skills to build consensus with stakeholders, both internally and externally
Possess deep knowledge of modern cloud infrastructure including Kubernetes, Infrastructure as Code, AWS, and GCP
Strong candidates may also:
Have security and privacy best practice expertise
Experience with machine learning infrastructure like GPUs, TPUs, or Trainium, as well as supporting networking infrastructure like NCCL
Low level systems experience, for example linux kernel tuning and eBPF 
Technical expertise: Quickly understanding systems design tradeoffs, keeping track of rapidly evolving software systems
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$320,000—$405,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.



Sr. Software Engineer, Infrastructure
(View all jobs)
San Francisco, CA, New York City, NY, Seattle, WA
About Anthropic
Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role:
Anthropic is seeking talented and experienced Infrastructure Engineers to join our team and support the development, scaling, and maintenance of our cutting-edge AI systems. By joining our Infrastructure team, you will have the opportunity to work on groundbreaking AI technologies and contribute to the development of frontier models, supporting Anthropic's mission to create safe and reliable AI systems that benefit humanity.
 
We have multiple teams that are currently hiring. Team placement occurs after the interview process, taking into account your interests and experience alongside organizational needs. This flexible approach allows us to match talented engineers with the infrastructure teams where they'll have the greatest impact and growth potential:
Data Infrastructure: The Data Infrastructure team is responsible for designing, building, and maintaining the data infrastructure that powers our AI research and products. You will collaborate with cross-functional teams to understand data requirements, deliver efficient and reliable data solutions, and continuously improve our data infrastructure. Your role will involve building and optimizing data pipelines, implementing data governance best practices, monitoring and troubleshooting, and setting technical strategies for high-scale, reliable data infrastructure and pipelines. You will work with technologies such as Spark, Airflow, dbt, and cloud services from GCP and AWS, while designing processes to ensure effective team operation and continuous improvement.

Core Infrastructure: The systems team is responsible for supporting some of the largest, most sophisticated clusters in industry used to train, research, and ultimately serve AI models.  Your work will be crucial in ensuring Anthropic is able to continue reliably and safely training frontier models. You will be responsible for building systems and running large Kubernetes clusters with GPU/TPU/Tranium workloads.

Observability: Observability team is responsible for designing, building, and maintaining the observability infrastructure that ensures the reliability, performance, and efficiency of our AI systems and services. You will collaborate with cross-functional teams to understand their observability requirements and deliver solutions using technologies such as Prometheus, Splunk, Cloud Logging, Grafana, and Honeycomb. Your role will involve developing a config-driven approach to manage dashboards and alerts, implementing structured logging and tracing, optimizing the observability stack, and building a reliable system that requires minimal maintenance. You will foster a culture of operational excellence, proactive monitoring, and continuous improvement by providing managed, centralized, and usable observability tools.
Developer Productivity: The Developer Productivity team enables Anthropic researchers and engineers to be maximally effective in securely developing state-of-the-at models, and products that expose those models to users. All of the code written at Anthropic goes through systems/infrastructure built and maintained by our team. We aim to make development at Anthropic secure, efficient, and delightful.
Product Infrastructure: The Product Infrastructure team enables Anthropic's products to achieve best-in-class performance, reliability, and developer velocity by building and maintaining a robust, efficient, and scalable product infrastructure stack. 
Claudification: The Claudification team works on exciting LLMs meet developer productivity problems. 
Responsibilities:
Lead build out of industry-leading AI clusters (thousands to hundreds of thousands of machines), partnering closely with cloud service providers on cluster build out and required features
Consult with different stakeholders to deeply understand infrastructure, data and compute needs, identifying potential solutions to support frontier research and product development
Set technical strategy and oversee development of high scale, reliable infrastructure systems.
Mentor top technical talent
Design processes (e.g. postmortem review, incident response, on-call rotations) that help the team operate effectively and never fail the same way twice
You may be a good fit if you:
Have 8+ years of relevant industry experience, 3+ years leading large scale, complex projects or teams as an engineer or tech lead
Are obsessed with distributed systems at scale, infrastructure reliability, scalability, security, and continuous improvement
Strong proficiency in at least one programming language (e.g., Python, Rust, Go, Java)
Strong problem-solving skills and ability to work independently
Have a passion for supporting internal partners like research to understand their needs
Have excellent communication skills to build consensus with stakeholders, both internally and externally
Possess deep knowledge of modern cloud infrastructure including Kubernetes, Infrastructure as Code, AWS, and GCP
Strong candidates may also:
Have security and privacy best practice expertise
Experience with machine learning infrastructure like GPUs, TPUs, or Trainium, as well as supporting networking infrastructure like NCCL
Low level systems experience, for example linux kernel tuning and eBPF 
Technical expertise: Quickly understanding systems design tradeoffs, keeping track of rapidly evolving software systems
Deadline to apply: None. Applications will be reviewed on a rolling basis. 

The expected salary range for this position is:

Annual Salary:
$300,000—$320,000 USD
Logistics
Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different
We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!
Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.
