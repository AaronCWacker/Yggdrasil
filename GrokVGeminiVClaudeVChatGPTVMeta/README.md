# Grok Versus Gemini Versus Claude Versus ChatGPT Versus Meta
![image](https://github.com/user-attachments/assets/98564209-a482-4983-bcc5-0b7f700e9101)

## Study
This is a comparative results study between the five best AI systems as of:
6/27/2025 6:42 PM Central Time.

## Samples

# Q Gemini
Expand this into a filmography scene builders prompt which provides a detail outlined and numbered instruction set for building a scene and showing the most amazing real movie scene ever with: Samurai holding a sword upside down. The sword is about a half foot wide blade two hand hilt and three captured samurai with their hands tied




Show thinking
Crafting the Ultimate Samurai Standoff: A Filmography Scene Builder's Prompt
Logline: In a desolate, snow-swept courtyard, a lone, enigmatic samurai, wielding a monstrous, impossibly wide blade, holds the fate of three captured rivals in his hands. The tension hangs heavier than the winter air as his unorthodox stance with an inverted sword signals a confrontation that will defy tradition and spill legendary blood.

Here is a detailed, outlined, and numbered instruction set for building the most amazing real movie scene ever, featuring a samurai holding an unconventional sword upside down over three captured samurai:

1. Establishing the Scene: The Frozen Courtyard

Shot: Extreme wide shot, slowly pushing in.

Visuals: A vast, desolate courtyard of a ruined temple or castle. A recent, heavy snowfall blankets everything, creating a pristine, yet somber, white landscape. The architecture is that of the Sengoku or early Edo period, with weathered, dark wood and broken shoji screens. A single, gnarled cherry blossom tree, barren and black against the snow, stands defiantly in the center. The air is thick with falling snow, each flake distinct and cinematic.

Sound: The oppressive silence of a snow-filled landscape. The only sounds are the gentle hiss of the falling snow and the faint, rhythmic creak of leather armor.

2. The Captor: The Silent Guardian

Shot: Medium shot, focusing on the central figure.

The Samurai: A lone samurai stands with his back partially to the camera. He is clad in dark, practical armor, perhaps a dou-maru style, that is worn and battle-scarred, suggesting a life of constant conflict. His helmet, or kabuto, is simple, functional, and bears a subtle, yet menacing, crest‚Äîperhaps a stylized oni or a coiled serpent. He is perfectly still, a statue of deadly potential amidst the falling snow.

Instruction: His posture should be relaxed, yet coiled with immense power. He is not just waiting; he is presiding over this scene with an unshakable and intimidating calm.

3. The Unthinkable Blade: The "Daitetsu"

Shot: Slow, deliberate pan down from the samurai's gauntleted hands to the sword's tip.

The Sword: This is the centerpiece of the scene's initial awe. It is a blade of impossible proportions, inspired by the legendary zanbat≈ç or "horse-slaying sword."

The Blade: Approximately a half-foot wide, its surface is a tapestry of folded steel, with a visible, undulating hamon (temper line) that seems to drink the ambient light. The sheer width makes it appear more like a sharpened slab of iron than a traditional katana.

The Hilt: A two-handed tsuka (hilt), wrapped in dark, worn leather over black rayskin, providing the necessary leverage to wield such a massive weapon.

The Stance: Crucially, he holds the sword upside down. The razor-sharp edge is facing him, a gesture that is both a profound insult to the samurai code and a display of supreme, almost arrogant, confidence. The broad, dull spine of the blade is what faces the prisoners, held just above their heads. The tip of this colossal blade rests lightly on the pristine snow.

Instruction: The camera should linger on the sheer, brutalist design of the sword, emphasizing its weight and otherworldly nature. This is not a weapon of honor; it is an instrument of absolute authority.

4. The Captured: The Defeated Trio

Shot: A low-angle shot from behind the captured samurai, looking up at their captor.

The Samurai: Three samurai are kneeling in the snow, their hands bound behind them. They are from a rival clan, their armor more ornate, perhaps with flashes of crimson and gold, now sullied by dirt and defeat.

Their Restraints: They are bound using the historically accurate art of hojojutsu. The ropes are thick, rough hemp (honnawa), tied with a deliberate lack of knots to signify their status as samurai, preserving a sliver of their honor even in capture. The intricate wrappings are both beautiful and brutally effective, immobilizing them completely.

Their Demeanor: Each of the three should display a different emotion: one defiant, staring daggers at his captor; another with his head bowed in shame and despair; the third, a younger warrior, shows a mixture of fear and awe.

Instruction: The contrast between their once-proud appearance and their current, helpless state should be stark and poignant. The specific and detailed rope work will add a layer of authenticity and visual interest.

5. The Unspoken Challenge: The Climax of Stillness

Shot: A series of rapid, intercutting close-ups: the captor's unseen face behind his mask, the defiant prisoner's eyes, the hand of the shamed samurai clenching into a fist in the snow, the upside-down blade, and the taut ropes.

The Action (or Lack Thereof): The "amazing" part of this scene is not a flurry of action, but the unbearable, protracted tension. The captor makes no move to execute them. The upside-down sword is a question hanging in the air. Is it a prelude to a disgraceful execution? A test of their resolve? Or is he waiting for something... or someone?

Sound: Introduce a subtle, low-frequency hum that grows almost imperceptibly, representing the simmering power of the scene. The sound of the captor's slow, deliberate breathing becomes audible.

Instruction: The scene should build to an almost unbearable crescendo of anticipation. The audience should be asking a dozen questions, their eyes darting around the frame, trying to decipher the captor's intent. The power of the scene lies in its potential energy, not its kinetic release.

6. The Inevitable Turn: The Catalyst

Shot: A sharp, sudden focus pull.

The Action: The defiant prisoner, unable to bear the psychological torment any longer, lets out a guttural roar and attempts to lunge forward, a futile gesture against his bonds.

The Reaction: In a single, fluid motion that defies the massive sword's weight, the captor does not bring the edge down. Instead, he flips the sword right-side up with an almost casual flick of his wrists. The sound of a half-foot of steel slicing through the air is a deafening whoosh. The movement is so fast, it's a blur. He now holds it in a conventional, terrifyingly ready stance. The sharp edge now gleams in the cold light, poised to strike.

Sound: The prisoner's roar is cut short by the shocking sound of the blade's movement. A sharp intake of breath from the other two prisoners.

Instruction: This final action redefines the captor's power. His control over this unwieldy weapon is absolute. The "upside-down" stance was not a sign of disrespect for the blade, but a demonstration that he dictates the terms of life and death, and that the sword does his bidding, no matter how he holds it. The scene ends here, on this precipice of violence, leaving the audience breathless and desperate for what comes next.







# Claude
Expand this into a filmography scene builders prompt which provides a detail outlined and numbered instruction set for building a scene and showing the most amazing real movie scene ever with: Samurai holding a sword upside down. The sword is about a half foot wide blade two hand hilt and three captured samurai with their hands tied




Show thinking
# Epic Samurai Scene Builder: The Judgment
## Master Filmography Instructions for Creating Cinema's Most Powerful Samurai Scene

---

## **SCENE CONCEPT**
*A legendary samurai executioner stands over three captured warriors in a moment that will define honor, betrayal, and justice. The inverted sword position signals an ancient ritual of judgment.*

---

## **PRE-PRODUCTION SETUP**

### 1. **Location Scouting & Set Design**
- **Primary Location**: Ancient temple courtyard or bamboo grove clearing
- **Ground Surface**: Weathered stone or packed earth with subtle texture
- **Background Elements**: Weathered wooden posts, ancient stone lanterns, or bamboo stalks
- **Weather Conditions**: Overcast sky or golden hour lighting for dramatic shadows
- **Props Needed**: Authentic katana (half-foot wide blade, traditional two-handed hilt), hemp rope, period-accurate costumes

### 2. **Character Positioning & Blocking**
- **Standing Samurai**: Center frame, elevated position (on small platform or natural rise)
- **Three Captured Samurai**: Kneeling in traditional seiza position, forming triangle formation
- **Distance**: 6-8 feet between standing samurai and captives
- **Angles**: Captives positioned at 45-degree angles to create depth and visual interest

---

## **CAMERA WORK & CINEMATOGRAPHY**

### 3. **Master Shot Establishment**
- **Camera Height**: Slightly below eye level of standing samurai
- **Lens**: 35mm or 50mm for natural perspective
- **Framing**: Wide shot capturing all four characters with breathing room
- **Movement**: Slow, imperceptible push-in over 30 seconds to build tension

### 4. **Dynamic Camera Sequence**
- **Shot 1**: Extreme close-up of inverted sword tip touching ground
- **Shot 2**: Low angle tracking shot following sword blade upward to warrior's face
- **Shot 3**: Medium shot of captives' faces showing resignation and honor
- **Shot 4**: Over-shoulder shot from behind standing samurai looking down
- **Shot 5**: High angle bird's eye view showing the ritual formation

### 5. **Signature Cinematic Moments**
- **The Reveal**: Slow tilt from sword tip to samurai's eyes (10-second duration)
- **The Decision**: Extreme close-up on standing samurai's eyes, followed by quick cuts to each captive's face
- **The Moment**: Ultra-slow motion (120fps) capture of single droplet falling from sword tip

---

## **LIGHTING DESIGN**

### 6. **Three-Point Lighting Setup**
- **Key Light**: Soft, directional light from 45-degree angle (simulating late afternoon sun)
- **Fill Light**: Subtle bounce card or reflector to prevent harsh shadows
- **Rim Light**: Strong backlight creating silhouette effect on standing samurai

### 7. **Atmospheric Lighting**
- **Mood**: Amber/golden tones with deep shadows
- **Special Effects**: Light smoke or mist to add atmosphere
- **Practical Lights**: Flickering torch or lantern light for warmth and movement
- **Shadow Play**: Use wooden slats or bamboo to create dramatic shadow patterns

---

## **AUDIO DESIGN**

### 8. **Soundscape Creation**
- **Ambient**: Subtle wind through bamboo or distant temple bells
- **Foley**: Leather creaking, rope tension, fabric rustling
- **Breath**: Amplified breathing sounds from all characters
- **Silence**: Strategic use of complete silence before key moments

### 9. **Musical Score Direction**
- **Instrumentation**: Traditional Japanese instruments (shakuhachi flute, taiko drums)
- **Tempo**: Slow, building tension with sudden stops
- **Emotional Arc**: Honor ‚Üí Tension ‚Üí Resolution ‚Üí Reflection

---

## **PERFORMANCE DIRECTION**

### 10. **Standing Samurai Character**
- **Posture**: Absolutely still, perfect vertical alignment
- **Grip**: Both hands on hilt, sword point touching ground
- **Expression**: Stoic resolve with subtle internal conflict
- **Eye Line**: Looking down at captives with measured contemplation
- **Breathing**: Controlled, visible chest movement

### 11. **Captured Samurai Trio**
- **Position**: Traditional seiza (kneeling) with perfect posture despite bonds
- **Hands**: Tied behind backs with thick hemp rope
- **Expressions**: Each showing different aspect of honor (acceptance, defiance, peace)
- **Movement**: Minimal, only slight head movements and breathing

---

## **PROP & COSTUME DETAILS**

### 12. **The Ceremonial Sword**
- **Blade**: Half-foot (6-inch) width, mirror polish reflecting faces
- **Hilt**: Traditional two-handed grip with authentic wrapping
- **Position**: Point down, perfectly vertical, blade catching light
- **Weight**: Actor must convey authentic heaviness and balance

### 13. **Costume Design**
- **Standing Samurai**: Dark, formal hakama and haori with clan mon (family crest)
- **Captured Warriors**: Battle-worn kimono, showing signs of conflict
- **Details**: Authentic knots in rope bindings, weathered fabric textures
- **Color Palette**: Earth tones with strategic color accents for visual hierarchy

---

## **SPECIAL TECHNIQUES**

### 14. **Advanced Cinematography**
- **Rack Focus**: Sharp focus pulls between sword and faces
- **Split Diopter**: Keep foreground and background in simultaneous focus
- **Dutch Angle**: Slight camera tilt during emotional peaks
- **Match Cuts**: Cut between similar compositions to maintain visual flow

### 15. **Practical Effects**
- **Wind Machine**: Subtle movement in clothing and hair
- **Water Effects**: Single droplet on sword for dramatic effect
- **Dust Particles**: Backlit particles in air for depth and atmosphere
- **Steam Breath**: If cold weather, use natural breath vapor

---

## **EDITING & POST-PRODUCTION**

### 16. **Pacing & Rhythm**
- **Scene Duration**: 90-120 seconds total
- **Cut Frequency**: Long holds (5-8 seconds) building to quick cuts (0.5-1 second)
- **Emotional Beats**: Allow pauses for audience absorption
- **Climax Timing**: Save fastest cutting for moment of decision

### 17. **Color Grading**
- **Color Temperature**: Warm highlights, cool shadows
- **Contrast**: High contrast for dramatic effect
- **Saturation**: Slightly desaturated for timeless feel
- **Special Treatment**: Sword blade should gleam with perfect specular highlights

---

## **DIRECTORIAL VISION**

### 18. **Thematic Elements**
- **Honor**: Every gesture must convey samurai code
- **Ritual**: Emphasize ceremonial nature of the moment
- **Tension**: Build unbearable suspense through restraint
- **Humanity**: Show internal conflict despite stoic exteriors

### 19. **Cultural Authenticity**
- **Research**: Study actual samurai execution rituals and ceremonies
- **Consultation**: Work with cultural advisors for accuracy
- **Respect**: Treat subject matter with appropriate gravity
- **Details**: Ensure every element serves the story's deeper meaning

---

## **EXECUTION CHECKLIST**

### 20. **Final Scene Requirements**
- [ ] All actors maintain perfect posture throughout
- [ ] Sword position is exactly vertical and motionless
- [ ] Rope bindings look authentic and properly tied
- [ ] Lighting creates dramatic shadows without losing detail
- [ ] Camera movements are perfectly smooth and motivated
- [ ] Audio captures every subtle sound element
- [ ] Each character's internal state is visible in their expression
- [ ] Scene builds to powerful emotional climax
- [ ] Cultural elements are respectful and accurate
- [ ] Visual composition follows rule of thirds and leading lines

---

## **DIRECTOR'S NOTES**
*"This scene represents the weight of judgment and the burden of honor. Every element‚Äîfrom the inverted sword symbolizing the gravity of decision, to the perfect stillness that precedes action‚Äîmust serve the story's emotional truth. The goal is not just to create a visually stunning moment, but to capture the very essence of what it means to live and die by the way of the samurai."*

---

**Total Scene Impact Goal**: Create a moment so powerful and authentic that it becomes the definitive cinematic representation of samurai honor and the terrible beauty of duty fulfilled.


# ChatGPT

Expand this into a filmography scene builders prompt which provides a detail outlined and numbered instruction set for building a scene and showing the most amazing real movie scene ever with:  Samurai holding a sword upside down.  The sword is about a half foot wide blade two hand hilt and three captured samurai with their hands tied


ChatGPT said:
Here is a filmography scene builder‚Äôs prompt, written as a detailed and numbered instruction set for creating a visually and emotionally stunning cinematic moment. The objective is to design a visceral, stylized, and unforgettable shot worthy of the most iconic movies in film history.

üé¨ Scene Builder Prompt: ‚ÄúThe Upside-Down Blade‚Äù
Core Concept: A master samurai holds an enormous sword upside down, the flat of the half-foot-wide blade resting on his shoulder. Before him kneel three captured samurai, bound by rope, their fate uncertain. The composition must evoke themes of honor, dread, defiance, and reverence.

1. Scene Title
"The Upside-Down Blade" ‚Äì A cinematic tableau of restrained fury and imminent judgment.

2. Location Setup
üìçEnvironment: A fog-drenched mountain clearing at dawn.

üå´Ô∏è Weather & Lighting:

Morning mist curls low across the ground.

Sunlight filters through tall cedar trees at sharp angles.

Use volumetric lighting to cut across the fog and silhouette the samurai.

üèîÔ∏è Set Dressing:

Fallen cherry blossoms mix with ash on the forest floor.

Cracked stone lanterns and ceremonial banners sway in the breeze.

Background: A shrine ruin, partially reclaimed by nature.

3. Character Blocking & Positioning
üßç‚Äç‚ôÇÔ∏è Main Samurai (The Executioner):

Center frame, facing camera three-quarters.

Holds a massive sword upside down, its weight pressing against his shoulder.

Two-handed hilt shows wear; the blade gleams, battle-scarred.

üßé‚Äç‚ôÇÔ∏èüßé‚Äç‚ôÇÔ∏èüßé‚Äç‚ôÇÔ∏è Three Captured Samurai:

Kneeling in a line, slightly offset to camera left.

Hands bound behind backs with coarse rope.

Armor dented, faces bloodied but proud.

One defiant, one serene, one trembling.

4. Camera Work
üé• Opening Shot:

Crane shot descending slowly from treetop level, revealing the tableau in full.

üì∑ Medium Push-In:

Glide into the main samurai‚Äôs face ‚Äì calm, unreadable.

üîÅ Rotating Close-Up:

Slow orbit around the sword‚Äôs upside-down blade, catching reflections: the captives, trees, a flicker of fire.

üì∏ Cutaways:

Tight shots of:

Rope fraying slightly.

A droplet of blood hitting a fallen petal.

The trembling hand of one captive.

üéûÔ∏è Signature Shot:

Focused silhouette of the sword held upside down, framed by the rising sun ‚Äì a halo of light bursts around it.

5. Sound & Score
üîà Ambient:

Soft wind, creaking wood, distant hawk cry.

üéº Score:

Sparse shakuhachi flute, slowly building with taiko percussion as tension mounts.

Sub-bass rumble crescendos with heartbeat rhythm as blade begins to move.

6. Symbolic Elements
üêç Sword Held Upside Down:

Symbol of reversed judgment, delayed execution, or sacred ritual.

üå∏ Falling Petals + Ash:

Life and death intertwined.

‚õ©Ô∏è Shrine Ruin:

Crumbled spiritual order; new code being written in blood.

7. Costume Design
‚öîÔ∏è Main Samurai:

Jet black armor with gold etching of a dragon coiled in descent.

Bare arms wrapped in bloodstained cloth.

Eyes darkened with charcoal war paint.

üõ°Ô∏è Captured Samurai:

Each wears a distinct color: red (rebellion), white (sacrifice), and green (loyalty).

Armor shows signs of different clans.

8. Post-Processing FX
üñºÔ∏è Color Grading:

Muted palette with high contrast.

Highlight metallics and blood reds.

üå´Ô∏è Particle Effects:

Use simulated ash, floating petals, and dust kicked from slight movements.

‚ö° Slow Motion & Ramp Effects:

Key moments (e.g., eye contact, sword twitch) slowed down to emphasize tension.

9. Dialogue (Optional)
üé≠ Main Samurai (softly, as voiceover or diegetic):

‚ÄúYour silence honors you more than your sword ever did.‚Äù

üé≠ Captive #1 (Defiant):

‚ÄúThen let my silence kill you.‚Äù

üé≠ Captive #3 (Trembling):

‚ÄúDo it‚Ä¶ I beg of you‚Ä¶ end it‚Ä¶‚Äù

10. Closing Moment
‚òÄÔ∏è The sun finally crests the mountain as the blade starts to descend in silence.

üì∑ Cut to black at the moment before contact.

üîä Single sound: a bamboo stick cracking.

Would you like this exported as a PDF scene card, or used as a prompt for Midjourney/DALL¬∑E image generation, or even rendered into Three.js cinematic animation?









# MetaAI

Expand this into a filmography scene builders prompt which provides a detail outlined and numbered instruction set for building a scene and showing the most amazing real movie scene ever with: Samurai holding a sword upside down. The sword is about a half foot wide blade two hand hilt and three captured samurai with their hands tied
Here's a filmography scene builders prompt with a detailed, outlined, and numbered instruction set for building the scene you described:
Scene: "The Conqueror's Mercy"
Setting: Feudal Japan, a rural battlefield or a lord's courtyard
Objective: Capture the essence of a powerful samurai leader holding a massive sword upside down, with three defeated samurai as his prisoners.
Scene Builder's Prompt:
Establish the Setting:
Choose a muted color palette with earthy tones (browns, tans, grays) to reflect the ruggedness of the battlefield or the simplicity of the courtyard.
Incorporate subtle Japanese architectural elements, such as stone lanterns, wooden fences, or traditional roofing.
The Samurai Leader:
Cast a tall, imposing actor with a strong presence to play the samurai leader.
Dress him in traditional samurai armor with a distinctive crest or design on his chest plate.
Ensure his facial expression conveys confidence, calmness, and a hint of curiosity.
The Massive Sword:
Design a sword with a blade approximately 0.5 feet (15 cm) wide and a two-handed hilt.
Choose a sword material that looks worn, weathered, and battle-tested (e.g., a mix of dark steel and subtle rust).
Ensure the sword's size and design are proportional to the samurai leader's physique.
The Captured Samurai:
Cast three actors with varying heights, ages, and expressions to create a sense of diversity among the prisoners.
Dress them in worn, damaged, or mismatched samurai armor to reflect their defeated state.
Ensure their hands are tied behind their backs with rope or leather straps, conveying a sense of restraint and vulnerability.
Composition:
Position the samurai leader at the center of the frame, holding the massive sword upside down with both hands.
Place the three captured samurai in a semi-circle around him, seated or kneeling on the ground.
Experiment with different angles and camera positions to emphasize the power dynamic between the samurai leader and his prisoners.
Lighting:
Use natural lighting to create deep shadows and highlights, accentuating the textures of the sword, armor, and surroundings.
Consider adding subtle lens flares or mist effects to enhance the scene's mystique and drama.
Action and Movement:
Have the samurai leader slowly rotate the sword, studying its blade or admiring its craftsmanship.
Allow the captured samurai to display a range of emotions, from despair to defiance, as they gaze up at their captor.
Camera Movement:
Start with a wide shot to establish the scene, then slowly zoom in on the samurai leader's face or the sword as he inspects it.
Consider adding subtle camera shakes or movements to convey the tension and unease emanating from the prisoners.
Color Grading:
Apply a subtle color grade to enhance the earthy tones and muted colors, creating a sense of grittiness and realism.
Ensure the sword's metal and the samurai leader's armor stand out against the duller surroundings.
Final Touches:
Add sound design elements, such as the soft clinking of armor, the rustling of fabric, or the distant calls of birds, to create an immersive atmosphere.
Experiment with different music options, from traditional Japanese instruments to haunting soundscapes, to enhance the scene's emotional impact.
The Most Amazing Real Movie Scene Ever:
To create an unforgettable scene, focus on capturing the intricate details, from the sword's design to the prisoners' expressions. Emphasize the power dynamic, tension, and mystery surrounding the samurai leader and his captives. By combining stunning visuals, captivating performances, and immersive sound design, you'll craft a scene that lingers in the viewer's mind long after the credits roll.
Inspiration:
For reference, consider scenes from classic samurai films like "Seven Samurai" (1954) or "Sanjuro" (1962), both directed by Akira Kurosawa. Study the compositions, lighting, and performances in these films to gain insight into creating a compelling and authentic samurai scene.


# City Sim

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive AI Traffic Simulator</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            font-family: Arial, sans-serif;
            background: #000;
        }
        #ui {
            position: absolute;
            top: 10px;
            left: 10px;
            color: white;
            background-color: rgba(0,0,0,0.9);
            padding: 15px;
            border-radius: 8px;
            z-index: 100;
            font-size: 14px;
            min-width: 200px;
        }
        #controls {
            position: absolute;
            top: 10px;
            right: 10px;
            color: white;
            background-color: rgba(0,0,0,0.9);
            padding: 15px;
            border-radius: 8px;
            z-index: 100;
        }
        #drivingControls {
            position: absolute;
            bottom: 10px;
            left: 50%;
            transform: translateX(-50%);
            color: white;
            background-color: rgba(0,0,0,0.9);
            padding: 15px;
            border-radius: 8px;
            z-index: 100;
            text-align: center;
        }
        #cameraControls {
            position: absolute;
            bottom: 10px;
            right: 10px;
            color: white;
            background-color: rgba(0,0,0,0.9);
            padding: 15px;
            border-radius: 8px;
            z-index: 100;
        }
        button {
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 8px 16px;
            margin: 5px;
            cursor: pointer;
            border-radius: 4px;
            font-size: 12px;
        }
        button:hover {
            background-color: #45a049;
        }
        button.active {
            background-color: #ff6b6b;
        }
        #stats {
            position: absolute;
            bottom: 10px;
            left: 10px;
            color: white;
            background-color: rgba(0,0,0,0.9);
            padding: 15px;
            border-radius: 8px;
            z-index: 100;
            font-size: 12px;
            min-width: 200px;
        }
        #minimap {
            position: absolute;
            top: 10px;
            right: 250px;
            width: 200px;
            height: 200px;
            background-color: rgba(0,0,0,0.8);
            border: 2px solid white;
            border-radius: 8px;
            z-index: 100;
        }
        .highlight { color: #ffcc00; font-weight: bold; }
        .success { color: #00ff00; font-weight: bold; }
        .player { color: #ff00ff; font-weight: bold; }
        .crosshair {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 20px;
            height: 20px;
            border: 2px solid white;
            border-radius: 50%;
            z-index: 200;
            opacity: 0.7;
            display: none;
        }
        #speedometer {
            position: absolute;
            bottom: 100px;
            right: 10px;
            color: white;
            background-color: rgba(0,0,0,0.9);
            padding: 15px;
            border-radius: 8px;
            z-index: 100;
            text-align: center;
            display: none;
        }
        .speed-gauge {
            width: 80px;
            height: 80px;
            border: 3px solid #4CAF50;
            border-radius: 50%;
            position: relative;
            margin: 0 auto;
        }
        .speed-needle {
            position: absolute;
            top: 50%;
            left: 50%;
            width: 2px;
            height: 35px;
            background: #ff6b6b;
            transform-origin: bottom center;
            transform: translate(-50%, -100%) rotate(0deg);
        }
    </style>
</head>
<body>
    <div id="ui">
        <div class="highlight">Interactive AI Traffic Simulator</div>
        <div>Mode: <span id="currentMode">AI Observer</span></div>
        <div>Population: <span id="population">50</span></div>
        <div>Speed: <span id="avgSpeed">0</span> km/h</div>
        <div>Traffic Flow: <span id="trafficFlow">Normal</span></div>
        <div>Active Routes: <span id="activeRoutes">0</span></div>
    </div>

    <div id="controls">
        <button id="pauseBtn">Pause</button>
        <button id="resetBtn">Reset</button>
        <button id="speedBtn">Speed: 1x</button>
        <button id="trafficBtn">Traffic: Normal</button>
        <button id="weatherBtn">Weather: Clear</button>
    </div>

    <div id="drivingControls" style="display: none;">
        <div class="highlight">Driving Controls</div>
        <div>WASD - Drive | Mouse - Look | Space - Brake</div>
        <div>Shift - Boost | Tab - Change Car | Esc - Exit</div>
    </div>

    <div id="cameraControls">
        <div class="highlight">Camera Controls</div>
        <button id="firstPersonBtn">First Person</button>
        <button id="thirdPersonBtn">Third Person</button>
        <button id="overviewBtn">Overview</button>
        <button id="freeCamera">Free Cam</button>
        <button id="nextCarBtn">Next Car</button>
    </div>

    <div id="stats">
        <div><span class="highlight">Current Statistics:</span></div>
        <div>Camera: <span id="cameraMode">Overview</span></div>
        <div>Target: <span id="currentTarget">None</span></div>
        <div>Distance: <span id="targetDistance">0</span>m</div>
        <div>Destination: <span id="currentDestination">None</span></div>
        <div>Flock Size: <span id="flockSize">0</span></div>
    </div>

    <div id="minimap"></div>

    <div id="speedometer">
        <div class="speed-gauge">
            <div class="speed-needle" id="speedNeedle"></div>
        </div>
        <div>Speed: <span id="currentSpeed">0</span> km/h</div>
    </div>

    <div class="crosshair" id="crosshair"></div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script>
        // Global variables
        let scene, camera, renderer, clock;
        let world = {
            roads: [],
            intersections: [],
            buildings: [],
            roadNetwork: new Map(),
            trafficLights: []
        };
        
        // Camera and interaction
        let cameraMode = 'overview'; // firstPerson, thirdPerson, overview, free
        let currentTarget = null;
        let isPlayerDriving = false;
        let mouseControls = { x: 0, y: 0, sensitivity: 0.002 };
        let keys = {};
        
        // Traffic simulation
        let population = [];
        let playerCar = null;
        let populationSize = 50;
        let paused = false;
        let speedMultiplier = 1;
        let trafficDensity = 'normal';
        let weatherCondition = 'clear';
        
        // Enhanced AI parameters
        const NEIGHBOR_RADIUS = 25;
        const ROAD_WIDTH = 8;
        const BUILDING_VISIT_DISTANCE = 15;

        // Simple Neural Network for AI Cars
        class SimpleNeuralNetwork {
            constructor() {
                this.weights = {
                    input: Array(16).fill().map(() => Array(8).fill().map(() => (Math.random() - 0.5) * 2)),
                    hidden: Array(8).fill().map(() => Array(4).fill().map(() => (Math.random() - 0.5) * 2)),
                    output: Array(4).fill().map(() => (Math.random() - 0.5) * 2)
                };
            }
            
            activate(inputs) {
                // Simple forward pass
                let hidden = new Array(8).fill(0);
                for (let i = 0; i < 8; i++) {
                    for (let j = 0; j < inputs.length && j < 16; j++) {
                        hidden[i] += inputs[j] * this.weights.input[j][i];
                    }
                    hidden[i] = Math.tanh(hidden[i]);
                }
                
                let outputs = new Array(4).fill(0);
                for (let i = 0; i < 4; i++) {
                    for (let j = 0; j < hidden.length; j++) {
                        outputs[i] += hidden[j] * this.weights.hidden[j][i];
                    }
                    outputs[i] = this.weights.output[i];
                    outputs[i] = Math.tanh(outputs[i]);
                }
                
                return outputs;
            }
            
            mutate(rate = 0.1) {
                // Simple mutation
                Object.keys(this.weights).forEach(layer => {
                    if (Array.isArray(this.weights[layer][0])) {
                        this.weights[layer].forEach(neuron => {
                            neuron.forEach((weight, i) => {
                                if (Math.random() < rate) {
                                    neuron[i] += (Math.random() - 0.5) * 0.5;
                                }
                            });
                        });
                    } else {
                        this.weights[layer].forEach((weight, i) => {
                            if (Math.random() < rate) {
                                this.weights[layer][i] += (Math.random() - 0.5) * 0.5;
                            }
                        });
                    }
                });
            }
        }

        // Enhanced AI Car with realistic navigation
        class RealisticAICar {
            constructor(x = 0, z = 0, isPlayer = false) {
                this.isPlayer = isPlayer;
                this.brain = isPlayer ? null : new SimpleNeuralNetwork();
                this.mesh = this.createCarMesh();
                this.mesh.position.set(x, 1, z);
                
                // Movement properties
                this.velocity = new THREE.Vector3(0, 0, 0);
                this.acceleration = new THREE.Vector3();
                this.maxSpeed = isPlayer ? 35 : 25;
                this.currentSpeed = 0;
                this.steering = 0;
                
                // Navigation properties
                this.destination = null;
                this.currentPath = [];
                this.pathIndex = 0;
                this.isAtDestination = false;
                this.lastDestinationTime = 0;
                
                // Flocking properties
                this.neighbors = [];
                this.flockingForce = new THREE.Vector3();
                
                // State tracking
                this.sensors = Array(8).fill(0);
                this.onRoad = false;
                this.atIntersection = false;
                this.waitingAtLight = false;
                
                this.initializeDestination();
            }
            
            createCarMesh() {
                const group = new THREE.Group();
                
                // Car body
                const bodyGeometry = new THREE.BoxGeometry(1.8, 1, 4);
                const bodyMaterial = new THREE.MeshLambertMaterial({ 
                    color: this.isPlayer ? 0xff00ff : new THREE.Color().setHSL(Math.random(), 0.8, 0.6) 
                });
                const body = new THREE.Mesh(bodyGeometry, bodyMaterial);
                body.position.y = 0.5;
                body.castShadow = true;
                group.add(body);
                
                // Roof
                const roofGeometry = new THREE.BoxGeometry(1.6, 0.8, 2.5);
                const roof = new THREE.Mesh(roofGeometry, bodyMaterial);
                roof.position.set(0, 1.4, -0.3);
                group.add(roof);
                
                // Wheels
                const wheelGeometry = new THREE.CylinderGeometry(0.4, 0.4, 0.3, 8);
                const wheelMaterial = new THREE.MeshLambertMaterial({ color: 0x333333 });
                
                this.wheels = [];
                const wheelPositions = [
                    [-1, 0, 1.5], [1, 0, 1.5],
                    [-1, 0, -1.5], [1, 0, -1.5]
                ];
                
                wheelPositions.forEach((pos, i) => {
                    const wheel = new THREE.Mesh(wheelGeometry, wheelMaterial);
                    wheel.position.set(...pos);
                    wheel.rotation.z = Math.PI / 2;
                    this.wheels.push(wheel);
                    group.add(wheel);
                });
                
                // Player indicator
                if (this.isPlayer) {
                    const indicatorGeometry = new THREE.ConeGeometry(0.5, 2, 4);
                    const indicator = new THREE.Mesh(indicatorGeometry, 
                        new THREE.MeshLambertMaterial({ color: 0xffff00 }));
                    indicator.position.set(0, 3, 0);
                    group.add(indicator);
                }
                
                return group;
            }
            
            initializeDestination() {
                if (world.buildings.length > 0) {
                    this.setRandomDestination();
                }
            }
            
            setRandomDestination() {
                const availableBuildings = world.buildings.filter(b => 
                    b.mesh.position.distanceTo(this.mesh.position) > 50
                );
                
                if (availableBuildings.length > 0) {
                    this.destination = availableBuildings[Math.floor(Math.random() * availableBuildings.length)];
                    this.calculatePath();
                    this.isAtDestination = false;
                }
            }
            
            calculatePath() {
                if (!this.destination) return;
                
                // Simple pathfinding - find nearest road to destination
                const start = this.mesh.position.clone();
                const end = this.destination.mesh.position.clone();
                
                // For now, create a simple path with waypoints
                this.currentPath = this.generateWaypoints(start, end);
                this.pathIndex = 0;
            }
            
            generateWaypoints(start, end) {
                const waypoints = [];
                const roadSpacing = 80;
                
                // Navigate to road grid
                const startRoadX = Math.round(start.x / roadSpacing) * roadSpacing;
                const startRoadZ = Math.round(start.z / roadSpacing) * roadSpacing;
                const endRoadX = Math.round(end.x / roadSpacing) * roadSpacing;
                const endRoadZ = Math.round(end.z / roadSpacing) * roadSpacing;
                
                waypoints.push(new THREE.Vector3(startRoadX, 1, start.z));
                waypoints.push(new THREE.Vector3(startRoadX, 1, startRoadZ));
                
                // Navigate along roads
                if (startRoadX !== endRoadX) {
                    waypoints.push(new THREE.Vector3(endRoadX, 1, startRoadZ));
                }
                waypoints.push(new THREE.Vector3(endRoadX, 1, endRoadZ));
                waypoints.push(end.clone().add(new THREE.Vector3(0, 1, 0)));
                
                return waypoints;
            }
            
            updateSensors() {
                const maxDistance = 15;
                const raycaster = new THREE.Raycaster();
                
                // 8-direction sensor array
                for (let i = 0; i < 8; i++) {
                    const angle = (i * Math.PI * 2) / 8;
                    const direction = new THREE.Vector3(
                        Math.sin(angle), 0, Math.cos(angle)
                    );
                    direction.applyQuaternion(this.mesh.quaternion);
                    
                    raycaster.set(this.mesh.position, direction);
                    const intersects = raycaster.intersectObjects(this.getObstacles(), true);
                    
                    if (intersects.length > 0 && intersects[0].distance <= maxDistance) {
                        this.sensors[i] = 1 - (intersects[0].distance / maxDistance);
                    } else {
                        this.sensors[i] = 0;
                    }
                }
                
                this.updateRoadStatus();
                this.updateFlocking();
            }
            
            updateRoadStatus() {
                const pos = this.mesh.position;
                const roadSpacing = 80;
                const roadHalfWidth = ROAD_WIDTH / 2;
                
                const nearestHorizontalRoad = Math.round(pos.z / roadSpacing) * roadSpacing;
                const nearestVerticalRoad = Math.round(pos.x / roadSpacing) * roadSpacing;
                
                const distToHorizontalRoad = Math.abs(pos.z - nearestHorizontalRoad);
                const distToVerticalRoad = Math.abs(pos.x - nearestVerticalRoad);
                
                this.onRoad = distToHorizontalRoad <= roadHalfWidth || distToVerticalRoad <= roadHalfWidth;
                
                // Check if at intersection
                this.atIntersection = distToHorizontalRoad <= roadHalfWidth && distToVerticalRoad <= roadHalfWidth;
            }
            
            updateFlocking() {
                this.neighbors = [];
                let separation = new THREE.Vector3();
                let alignment = new THREE.Vector3();
                let cohesion = new THREE.Vector3();
                let neighborCount = 0;
                
                population.forEach(other => {
                    if (other !== this) {
                        const distance = this.mesh.position.distanceTo(other.mesh.position);
                        
                        if (distance < NEIGHBOR_RADIUS && distance > 0) {
                            this.neighbors.push(other);
                            cohesion.add(other.mesh.position);
                            alignment.add(other.velocity);
                            neighborCount++;
                            
                            if (distance < 8) {
                                const diff = this.mesh.position.clone().sub(other.mesh.position);
                                diff.normalize().divideScalar(distance);
                                separation.add(diff);
                            }
                        }
                    }
                });
                
                if (neighborCount > 0) {
                    cohesion.divideScalar(neighborCount).sub(this.mesh.position).normalize();
                    alignment.divideScalar(neighborCount).normalize();
                }
                
                this.flockingForce = separation.multiplyScalar(1.5)
                    .add(alignment.multiplyScalar(1.0))
                    .add(cohesion.multiplyScalar(0.5));
            }
            
            update(deltaTime) {
                this.updateSensors();
                
                if (this.isPlayer) {
                    this.updatePlayerControls(deltaTime);
                } else {
                    this.updateAI(deltaTime);
                }
                
                this.updateMovement(deltaTime);
                this.updateDestination();
                this.keepInBounds();
            }
            
            updatePlayerControls(deltaTime) {
                const forwardForce = keys['KeyW'] ? 1 : 0;
                const backwardForce = keys['KeyS'] ? -0.5 : 0;
                const leftTurn = keys['KeyA'] ? -1 : 0;
                const rightTurn = keys['KeyD'] ? 1 : 0;
                const brake = keys['Space'] ? 1 : 0;
                const boost = keys['ShiftLeft'] ? 1.5 : 1;
                
                this.applyMovement(forwardForce + backwardForce, leftTurn + rightTurn, brake, boost, deltaTime);
            }
            
            updateAI(deltaTime) {
                if (!this.brain) return;
                
                const inputs = [
                    ...this.sensors,
                    this.onRoad ? 1 : 0,
                    this.atIntersection ? 1 : 0,
                    this.currentSpeed / this.maxSpeed,
                    this.getPathDirection(),
                    this.flockingForce.x,
                    this.flockingForce.z,
                    this.neighbors.length / 10,
                    this.getDestinationDirection()
                ];
                
                const outputs = this.brain.activate(inputs);
                const [forward, turn, brake, formation] = outputs;
                
                this.applyMovement(forward, turn, brake, 1, deltaTime);
            }
            
            getPathDirection() {
                if (this.currentPath.length === 0 || this.pathIndex >= this.currentPath.length) {
                    return 0;
                }
                
                const target = this.currentPath[this.pathIndex];
                const direction = target.clone().sub(this.mesh.position).normalize();
                const forward = new THREE.Vector3(0, 0, 1).applyQuaternion(this.mesh.quaternion);
                
                return direction.dot(forward);
            }
            
            getDestinationDirection() {
                if (!this.destination) return 0;
                
                const direction = this.destination.mesh.position.clone().sub(this.mesh.position).normalize();
                const forward = new THREE.Vector3(0, 0, 1).applyQuaternion(this.mesh.quaternion);
                
                return direction.dot(forward);
            }
            
            applyMovement(forwardForce, turnForce, brakeForce, boostMultiplier, deltaTime) {
                // Steering
                this.steering = turnForce * 0.03;
                this.mesh.rotation.y += this.steering * this.currentSpeed * deltaTime;
                
                // Acceleration
                const maxAcceleration = 15 * boostMultiplier;
                if (forwardForce > 0) {
                    this.currentSpeed += maxAcceleration * forwardForce * deltaTime;
                } else if (forwardForce < 0) {
                    this.currentSpeed += maxAcceleration * forwardForce * deltaTime;
                }
                
                // Braking
                if (brakeForce > 0) {
                    this.currentSpeed *= Math.pow(0.1, brakeForce * deltaTime);
                }
                
                // Natural deceleration
                this.currentSpeed *= Math.pow(0.98, deltaTime * 60);
                
                // Speed limits
                this.currentSpeed = Math.max(-this.maxSpeed * 0.5, 
                    Math.min(this.maxSpeed * boostMultiplier, this.currentSpeed));
                
                // Apply velocity
                const forward = new THREE.Vector3(0, 0, 1);
                forward.applyQuaternion(this.mesh.quaternion);
                this.velocity = forward.multiplyScalar(this.currentSpeed);
                
                // Apply flocking forces for AI cars
                if (!this.isPlayer && this.flockingForce.length() > 0) {
                    this.velocity.add(this.flockingForce.multiplyScalar(5 * deltaTime));
                }
                
                // Update position
                this.mesh.position.add(this.velocity.clone().multiplyScalar(deltaTime));
                
                // Wheel rotation
                this.wheels.forEach(wheel => {
                    wheel.rotation.x += this.currentSpeed * deltaTime * 0.2;
                });
            }
            
            updateMovement(deltaTime) {
                // Road following behavior for AI
                if (!this.isPlayer && this.onRoad) {
                    const roadBonus = this.getRoadFollowingForce();
                    this.mesh.position.add(roadBonus.multiplyScalar(deltaTime * 2));
                }
            }
            
            getRoadFollowingForce() {
                const pos = this.mesh.position;
                const roadSpacing = 80;
                const roadHalfWidth = ROAD_WIDTH / 2;
                
                const nearestHorizontalRoad = Math.round(pos.z / roadSpacing) * roadSpacing;
                const nearestVerticalRoad = Math.round(pos.x / roadSpacing) * roadSpacing;
                
                const distToHorizontalRoad = pos.z - nearestHorizontalRoad;
                const distToVerticalRoad = pos.x - nearestVerticalRoad;
                
                const force = new THREE.Vector3();
                
                if (Math.abs(distToHorizontalRoad) <= roadHalfWidth) {
                    force.z = -distToHorizontalRoad * 0.5;
                }
                if (Math.abs(distToVerticalRoad) <= roadHalfWidth) {
                    force.x = -distToVerticalRoad * 0.5;
                }
                
                return force;
            }
            
            updateDestination() {
                if (!this.destination) return;
                
                const distanceToDestination = this.mesh.position.distanceTo(this.destination.mesh.position);
                
                if (distanceToDestination < BUILDING_VISIT_DISTANCE) {
                    if (!this.isAtDestination) {
                        this.isAtDestination = true;
                        this.lastDestinationTime = Date.now();
                    }
                    
                    // Stay at destination for a while, then pick new one
                    if (Date.now() - this.lastDestinationTime > 3000) {
                        this.setRandomDestination();
                    }
                }
                
                // Update path following
                if (this.currentPath.length > 0 && this.pathIndex < this.currentPath.length) {
                    const waypoint = this.currentPath[this.pathIndex];
                    const distanceToWaypoint = this.mesh.position.distanceTo(waypoint);
                    
                    if (distanceToWaypoint < 10) {
                        this.pathIndex++;
                    }
                }
            }
            
            getObstacles() {
                let obstacles = [];
                
                population.forEach(car => {
                    if (car !== this) {
                        obstacles.push(car.mesh);
                    }
                });
                
                world.buildings.forEach(building => {
                    obstacles.push(building.mesh);
                });
                
                return obstacles;
            }
            
            keepInBounds() {
                const bounds = 300;
                if (Math.abs(this.mesh.position.x) > bounds || 
                    Math.abs(this.mesh.position.z) > bounds) {
                    if (Math.abs(this.mesh.position.x) > bounds) {
                        this.mesh.position.x = Math.sign(this.mesh.position.x) * bounds;
                        this.velocity.x *= -0.5;
                    }
                    if (Math.abs(this.mesh.position.z) > bounds) {
                        this.mesh.position.z = Math.sign(this.mesh.position.z) * bounds;
                        this.velocity.z *= -0.5;
                    }
                }
            }
        }

        function init() {
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x87CEEB);
            scene.fog = new THREE.Fog(0x87CEEB, 200, 800);
            
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.set(0, 80, 80);
            
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.shadowMap.enabled = true;
            renderer.shadowMap.type = THREE.PCFSoftShadowMap;
            document.body.appendChild(renderer.domElement);
            
            // Lighting
            const ambientLight = new THREE.AmbientLight(0x404040, 0.6);
            scene.add(ambientLight);
            
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(50, 100, 50);
            directionalLight.castShadow = true;
            directionalLight.shadow.mapSize.width = 2048;
            directionalLight.shadow.mapSize.height = 2048;
            scene.add(directionalLight);
            
            createWorld();
            createPopulation();
            
            clock = new THREE.Clock();
            
            setupEventListeners();
            setupKeyboardControls();
            setupMouseControls();
            
            animate();
        }

        function createWorld() {
            // Ground
            const groundGeometry = new THREE.PlaneGeometry(800, 800);
            const groundMaterial = new THREE.MeshLambertMaterial({ color: 0x228B22 });
            const ground = new THREE.Mesh(groundGeometry, groundMaterial);
            ground.rotation.x = -Math.PI / 2;
            ground.receiveShadow = true;
            scene.add(ground);
            
            createRoadNetwork();
            createBuildings();
            createTrafficLights();
        }

        function createRoadNetwork() {
            const roadMaterial = new THREE.MeshLambertMaterial({ color: 0x444444 });
            const roadSpacing = 80;
            
            // Create road grid
            for (let i = -240; i <= 240; i += roadSpacing) {
                // Horizontal roads
                const hRoadGeometry = new THREE.PlaneGeometry(480, ROAD_WIDTH);
                const hRoad = new THREE.Mesh(hRoadGeometry, roadMaterial);
                hRoad.rotation.x = -Math.PI / 2;
                hRoad.position.set(0, 0.1, i);
                scene.add(hRoad);
                
                // Vertical roads
                const vRoadGeometry = new THREE.PlaneGeometry(ROAD_WIDTH, 480);
                const vRoad = new THREE.Mesh(vRoadGeometry, roadMaterial);
                vRoad.rotation.x = -Math.PI / 2;
                vRoad.position.set(i, 0.1, 0);
                scene.add(vRoad);
                
                // Road markings
                createRoadMarkings(i);
            }
        }

        function createRoadMarkings(position) {
            const markingMaterial = new THREE.MeshLambertMaterial({ color: 0xffffff });
            
            // Center line markings
            for (let j = -200; j <= 200; j += 20) {
                const markingGeometry = new THREE.PlaneGeometry(1, 8);
                const marking = new THREE.Mesh(markingGeometry, markingMaterial);
                marking.rotation.x = -Math.PI / 2;
                marking.position.set(j, 0.11, position);
                scene.add(marking);
                
                const vMarking = new THREE.Mesh(markingGeometry.clone(), markingMaterial);
                vMarking.rotation.x = -Math.PI / 2;
                vMarking.rotation.z = Math.PI / 2;
                vMarking.position.set(position, 0.11, j);
                scene.add(vMarking);
            }
        }

        function createBuildings() {
            world.buildings = [];
            const buildingMaterial = new THREE.MeshLambertMaterial({ color: 0x666666 });
            
            // Create buildings in grid pattern with some randomness
            for (let x = -200; x <= 200; x += 80) {
                for (let z = -200; z <= 200; z += 80) {
                    if (Math.random() > 0.3) { // Don't place building everywhere
                        const offsetX = x + (Math.random() - 0.5) * 40;
                        const offsetZ = z + (Math.random() - 0.5) * 40;
                        
                        const width = 15 + Math.random() * 20;
                        const height = 10 + Math.random() * 30;
                        const depth = 15 + Math.random() * 20;
                        
                        const buildingGeometry = new THREE.BoxGeometry(width, height, depth);
                        const building = new THREE.Mesh(buildingGeometry, buildingMaterial);
                        building.position.set(offsetX, height / 2, offsetZ);
                        building.castShadow = true;
                        scene.add(building);
                        
                        world.buildings.push({ mesh: building });
                    }
                }
            }
        }

        function createTrafficLights() {
            world.trafficLights = [];
            const roadSpacing = 80;
            
            // Place traffic lights at major intersections
            for (let x = -160; x <= 160; x += roadSpacing) {
                for (let z = -160; z <= 160; z += roadSpacing) {
                    if (Math.random() > 0.7) {
                        const light = createTrafficLight(x, z);
                        world.trafficLights.push(light);
                    }
                }
            }
        }

        function createTrafficLight(x, z) {
            const poleGeometry = new THREE.CylinderGeometry(0.2, 0.2, 8);
            const poleMaterial = new THREE.MeshLambertMaterial({ color: 0x333333 });
            const pole = new THREE.Mesh(poleGeometry, poleMaterial);
            pole.position.set(x + 6, 4, z + 6);
            scene.add(pole);
            
            const lightBoxGeometry = new THREE.BoxGeometry(1, 3, 1);
            const lightBoxMaterial = new THREE.MeshLambertMaterial({ color: 0x222222 });
            const lightBox = new THREE.Mesh(lightBoxGeometry, lightBoxMaterial);
            lightBox.position.set(x + 6, 7, z + 6);
            scene.add(lightBox);
            
            // Light states
            const states = ['red', 'yellow', 'green'];
            const currentState = states[Math.floor(Math.random() * states.length)];
            
            return {
                pole: pole,
                lightBox: lightBox,
                position: new THREE.Vector3(x, 0, z),
                state: currentState,
                lastChange: Date.now()
            };
        }

        function createPopulation() {
            population = [];
            
            // Create AI cars
            for (let i = 0; i < populationSize - 1; i++) {
                const angle = (i / populationSize) * Math.PI * 2;
                const radius = 30 + Math.random() * 50;
                const x = Math.cos(angle) * radius;
                const z = Math.sin(angle) * radius;
                
                const car = new RealisticAICar(x, z, false);
                population.push(car);
                scene.add(car.mesh);
            }
            
            // Create player car
            playerCar = new RealisticAICar(0, 0, true);
            population.push(playerCar);
            scene.add(playerCar.mesh);
            currentTarget = playerCar;
        }

        function animate() {
            requestAnimationFrame(animate);
            
            if (!paused) {
                const deltaTime = Math.min(clock.getDelta() * speedMultiplier, 0.1);
                
                updatePopulation(deltaTime);
                updateTrafficLights();
                updateCamera();
                updateUI();
            }
            
            renderer.render(scene, camera);
        }

        function updatePopulation(deltaTime) {
            population.forEach(car => car.update(deltaTime));
        }

        function updateTrafficLights() {
            world.trafficLights.forEach(light => {
                if (Date.now() - light.lastChange > 5000) {
                    const states = ['red', 'yellow', 'green'];
                    const currentIndex = states.indexOf(light.state);
                    light.state = states[(currentIndex + 1) % states.length];
                    light.lastChange = Date.now();
                    
                    // Update light color
                    const colors = { red: 0xff0000, yellow: 0xffff00, green: 0x00ff00 };
                    light.lightBox.material.color.setHex(colors[light.state]);
                }
            });
        }

        function updateCamera() {
            if (!currentTarget) return;
            
            const targetPos = currentTarget.mesh.position;
            const targetRot = currentTarget.mesh.rotation;
            
            switch (cameraMode) {
                case 'firstPerson':
                    // First person view
                    camera.position.copy(targetPos);
                    camera.position.y += 2;
                    camera.position.add(new THREE.Vector3(0, 0, 2).applyQuaternion(currentTarget.mesh.quaternion));
                    
                    const lookDirection = new THREE.Vector3(0, 0, -1).applyQuaternion(currentTarget.mesh.quaternion);
                    lookDirection.add(new THREE.Vector3(mouseControls.x, mouseControls.y, 0));
                    camera.lookAt(targetPos.clone().add(lookDirection.multiplyScalar(10)));
                    break;
                    
                case 'thirdPerson':
                    // Third person view
                    const behindOffset = new THREE.Vector3(0, 8, 15).applyQuaternion(currentTarget.mesh.quaternion);
                    camera.position.lerp(targetPos.clone().sub(behindOffset), 0.1);
                    camera.lookAt(targetPos);
                    break;
                    
                case 'overview':
                    // Overview of the area
                    camera.position.lerp(new THREE.Vector3(0, 150, 150), 0.02);
                    camera.lookAt(targetPos);
                    break;
                    
                case 'free':
                    // Free camera movement
                    updateFreeCamera();
                    break;
            }
        }

        function updateFreeCamera() {
            const moveSpeed = 2;
            
            if (keys['KeyW']) camera.position.add(new THREE.Vector3(0, 0, -moveSpeed));
            if (keys['KeyS']) camera.position.add(new THREE.Vector3(0, 0, moveSpeed));
            if (keys['KeyA']) camera.position.add(new THREE.Vector3(-moveSpeed, 0, 0));
            if (keys['KeyD']) camera.position.add(new THREE.Vector3(moveSpeed, 0, 0));
            if (keys['KeyQ']) camera.position.y += moveSpeed;
            if (keys['KeyE']) camera.position.y -= moveSpeed;
        }

        function updateUI() {
            if (currentTarget) {
                document.getElementById('currentMode').textContent = currentTarget.isPlayer ? 'Player Driving' : 'AI Observer';
                document.getElementById('currentTarget').textContent = currentTarget.isPlayer ? 'Player' : 'AI Car';
                document.getElementById('currentSpeed').textContent = Math.round(Math.abs(currentTarget.currentSpeed * 3.6));
                document.getElementById('flockSize').textContent = currentTarget.neighbors.length;
                
                if (currentTarget.destination) {
                    const distance = currentTarget.mesh.position.distanceTo(currentTarget.destination.mesh.position);
                    document.getElementById('targetDistance').textContent = Math.round(distance);
                    document.getElementById('currentDestination').textContent = 'Building';
                } else {
                    document.getElementById('targetDistance').textContent = '0';
                    document.getElementById('currentDestination').textContent = 'None';
                }
            }
            
            document.getElementById('population').textContent = population.length;
            
            const avgSpeed = population.reduce((sum, car) => sum + Math.abs(car.currentSpeed), 0) / population.length;
            document.getElementById('avgSpeed').textContent = Math.round(avgSpeed * 3.6);
            
            const activeRoutes = population.filter(car => car.currentPath.length > 0).length;
            document.getElementById('activeRoutes').textContent = activeRoutes;
            
            document.getElementById('cameraMode').textContent = cameraMode;
            
            // Update speedometer
            if (currentTarget && currentTarget.isPlayer) {
                const speedPercent = Math.abs(currentTarget.currentSpeed) / currentTarget.maxSpeed;
                const needleRotation = -90 + (speedPercent * 180);
                document.getElementById('speedNeedle').style.transform = 
                    `translate(-50%, -100%) rotate(${needleRotation}deg)`;
            }
        }

        function setupEventListeners() {
            // UI controls
            document.getElementById('pauseBtn').addEventListener('click', togglePause);
            document.getElementById('resetBtn').addEventListener('click', resetSimulation);
            document.getElementById('speedBtn').addEventListener('click', toggleSpeed);
            document.getElementById('trafficBtn').addEventListener('click', toggleTraffic);
            document.getElementById('weatherBtn').addEventListener('click', toggleWeather);
            
            // Camera controls
            document.getElementById('firstPersonBtn').addEventListener('click', () => setCameraMode('firstPerson'));
            document.getElementById('thirdPersonBtn').addEventListener('click', () => setCameraMode('thirdPerson'));
            document.getElementById('overviewBtn').addEventListener('click', () => setCameraMode('overview'));
            document.getElementById('freeCamera').addEventListener('click', () => setCameraMode('free'));
            document.getElementById('nextCarBtn').addEventListener('click', switchToNextCar);
            
            window.addEventListener('resize', onWindowResize);
        }

        function setupKeyboardControls() {
            document.addEventListener('keydown', (event) => {
                keys[event.code] = true;
                
                if (event.code === 'Tab') {
                    event.preventDefault();
                    switchToNextCar();
                }
                if (event.code === 'Escape') {
                    setCameraMode('overview');
                }
            });
            
            document.addEventListener('keyup', (event) => {
                keys[event.code] = false;
            });
        }

        function setupMouseControls() {
            let isMouseLocked = false;
            
            document.addEventListener('click', () => {
                if (cameraMode === 'firstPerson' || cameraMode === 'free') {
                    document.body.requestPointerLock();
                }
            });
            
            document.addEventListener('pointerlockchange', () => {
                isMouseLocked = document.pointerLockElement === document.body;
            });
            
            document.addEventListener('mousemove', (event) => {
                if (isMouseLocked) {
                    mouseControls.x += event.movementX * mouseControls.sensitivity;
                    mouseControls.y -= event.movementY * mouseControls.sensitivity;
                    
                    mouseControls.x = Math.max(-Math.PI/3, Math.min(Math.PI/3, mouseControls.x));
                    mouseControls.y = Math.max(-Math.PI/6, Math.min(Math.PI/6, mouseControls.y));
                }
            });
        }

        function setCameraMode(mode) {
            cameraMode = mode;
            
            // Update UI
            document.querySelectorAll('#cameraControls button').forEach(btn => {
                btn.classList.remove('active');
            });
            
            const buttonMap = {
                'firstPerson': 'firstPersonBtn',
                'thirdPerson': 'thirdPersonBtn',
                'overview': 'overviewBtn',
                'free': 'freeCamera'
            };
            
            if (buttonMap[mode]) {
                document.getElementById(buttonMap[mode]).classList.add('active');
            }
            
            // Show/hide UI elements
            const showDriving = mode === 'firstPerson' && currentTarget && currentTarget.isPlayer;
            document.getElementById('drivingControls').style.display = showDriving ? 'block' : 'none';
            document.getElementById('speedometer').style.display = showDriving ? 'block' : 'none';
            document.getElementById('crosshair').style.display = mode === 'firstPerson' ? 'block' : 'none';
            
            mouseControls.x = 0;
            mouseControls.y = 0;
        }

        function switchToNextCar() {
            if (population.length === 0) return;
            
            const currentIndex = population.indexOf(currentTarget);
            const nextIndex = (currentIndex + 1) % population.length;
            currentTarget = population[nextIndex];
            
            // If switching to player car, enable driving controls
            if (currentTarget.isPlayer && cameraMode !== 'overview') {
                setCameraMode('firstPerson');
            }
        }

        function togglePause() {
            paused = !paused;
            document.getElementById('pauseBtn').textContent = paused ? 'Resume' : 'Pause';
        }

        function resetSimulation() {
            population.forEach(car => {
                if (car.mesh.parent) scene.remove(car.mesh);
            });
            createPopulation();
            currentTarget = playerCar;
        }

        function toggleSpeed() {
            speedMultiplier = speedMultiplier === 1 ? 2 : speedMultiplier === 2 ? 5 : 1;
            document.getElementById('speedBtn').textContent = `Speed: ${speedMultiplier}x`;
        }

        function toggleTraffic() {
            const levels = ['light', 'normal', 'heavy'];
            const currentIndex = levels.indexOf(trafficDensity);
            trafficDensity = levels[(currentIndex + 1) % levels.length];
            document.getElementById('trafficBtn').textContent = `Traffic: ${trafficDensity}`;
            document.getElementById('trafficFlow').textContent = trafficDensity;
        }

        function toggleWeather() {
            const conditions = ['clear', 'rain', 'fog'];
            const currentIndex = conditions.indexOf(weatherCondition);
            weatherCondition = conditions[(currentIndex + 1) % conditions.length];
            document.getElementById('weatherBtn').textContent = `Weather: ${weatherCondition}`;
            
            // Update visual effects
            if (weatherCondition === 'fog') {
                scene.fog.near = 50;
                scene.fog.far = 200;
            } else {
                scene.fog.near = 200;
                scene.fog.far = 800;
            }
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        init();
    </script>
</body>
</html>


# 
