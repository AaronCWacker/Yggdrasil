# Skills Summary - Mixture of ML Experts Research AI Model

![image](https://github.com/user-attachments/assets/bb6e3f66-7d5b-4c78-9640-0276e5500f38)


# This Python script prints a markdown outline of your skills.
# Run this script to see the markdown-formatted skills listing.

markdown_outline = """
## 1. Unique List of Skills

1. **üîß Systems & Low-Level Engineering**  
   1. üîß *Low-level system integrations (compilers, C++)*  
   2. üîß *Linux or embedded systems experience*  
   3. üîß *Hardware acceleration*  
   4. üîß *Accelerating ML training/inference across AI hardware*  
   5. üîß *CUDA kernels*  
   6. üîß *Optimum integration for specialized AI hardware*  

2. **üíª Software Engineering, Cloud & Infrastructure**  
   1. üíª *Python APIs and framework optimizations (tokenizers, datasets)*  
   2. üíª *Python*  
   3. üíª *Rust*  
   4. üíª *PyTorch/Keras*  
   5. üíª *TypeScript, MongoDB, Kubernetes*  
   6. üíª *Building secure, robust developer experiences & APIs*  
   7. üíª *Full-stack development (Node.js, Svelte, MongoDB, AWS)*  
   8. üíª *JavaScript/TypeScript ML: transformers.js, huggingface.js*  
   9. üíª *In-browser inference via WebGPU, WASM, ONNX*  
   10. üíª *Integrating Hugging Face with major cloud platforms*  
   11. üíª *AWS, GCP, Azure, containerizing (Docker), MLOps pipelines*  
   12. üíª *Distributed data processing*  
   13. üíª *Building essential tooling for the Hugging Face ML Hub*  

3. **ü§ñ Machine Learning, Model Development & Optimization**  
   1. ü§ñ *Performance tuning for Transformers (NLP, CV, Speech)*  
   2. ü§ñ *Industrial-level ML with text-generation-inference focus*  
   3. ü§ñ *Optimizing and scaling real-world ML services*  
   4. ü§ñ *Reliability & performance monitoring*  
   5. ü§ñ *Ablation & training small models for data-quality analysis*  
   6. ü§ñ *Reducing model size & complexity (quantization)*  
   7. ü§ñ *Neural sparse models (SPLADE, BM25), semantic/dense retrieval*  
   8. ü§ñ *LLM usage & fine-tuning, chain-of-thought prompting*  
   9. ü§ñ *Energy efficiency & carbon footprint analysis*  
   10. ü§ñ *Post-training for LLMs (RLHF, PPO, DPO, instruction tuning)*  
   11. ü§ñ *Building LLM ‚Äúagents‚Äù with external tool usage*  
   12. ü§ñ *Creating LLM agents that control GUIs via screen recordings*  
   13. ü§ñ *Building web-scale, high-quality LLM training datasets*  
   14. ü§ñ *LLM-based code suggestions in Gradio Playground*  
   15. ü§ñ *Speech-to-text, text-to-speech, speaker diarization*  

4. **üì¢ Community, Open Source & Outreach**  
   1. üì¢ *Technical blogging, demos, community evangelism*  
   2. üì¢ *Speaking at conferences, building & showcasing ML solutions*  
   3. üì¢ *Open‚Äësource libraries (Transformers, Diffusers)*  
   4. üì¢ *Contributing to open‚Äësource projects like Transformers, Datasets, Accelerate*  
   5. üì¢ *Fostering an active ML community*  
   6. üì¢ *Brainstorming unique ML/AI talents*  
   7. üì¢ *Collaborating with researchers in non‚ÄëAI scientific fields*  

---

## 2. Consolidated Similar Skills

1. **üîß Systems & Low-Level Engineering**  
   1. üîß *GPU/TPU/Hardware*  
      - (Hardware acceleration, GPU/TPU/Hardware, Accelerating ML training/inference across AI hardware, Optimum integration for specialized AI hardware)  
   2. üîß *Linux/OS*  
      - (Linux or embedded systems experience)  
   3. üîß *CUDA/Low-level*  
      - (Low‚Äëlevel system integrations, CUDA kernels)  

2. **üíª Software Engineering, Cloud & Infrastructure**  
   1. üíª *Python*  
      - (Python APIs, Python, transformers.js, huggingface.js)  
   2. üíª *Kubernetes/K8s*  
      - (Kubernetes)  
   3. üíª *React/TypeScript/JS*  
      - (React/TypeScript/JS, JavaScript/TypeScript ML)  
   4. üíª *AWS/GCP*  
      - (AWS, GCP, Azure)  
   5. üíª *PyTorch*  
      - (PyTorch/Keras)  
   6. üíª *Distributed Systems*  
      - (Distributed data processing, Distributed training)  
   7. üíª *MLOps*  
      - (MLOps pipelines, ML Ops)  

3. **ü§ñ Machine Learning, Model Development & Optimization**  
   1. ü§ñ *Machine Learning*  
      - (Machine Learning, Industrial‚Äëlevel ML, LLM usage & fine‚Äëtuning, Energy efficiency & carbon footprint analysis)  
   2. ü§ñ *Performance Optimization*  
      - (Performance tuning for Transformers, Reliability & performance monitoring, Optimizing and scaling real‚Äëworld ML services)  
   3. ü§ñ *Model Development*  
      - (Ablation & training small models, Building LLM ‚Äúagents‚Äù, Creating LLM agents)  

4. **üì¢ Community, Open Source & Outreach**  
   1. üì¢ *Open‚Äësource Contributions*  
      - (Open‚Äësource libraries, Contributing to open‚Äësource projects, Fostering an active ML community)  
   2. üì¢ *Community Engagement*  
      - (Technical blogging, demos, community evangelism, Speaking at conferences, building & showcasing ML solutions)  
"""

print(markdown_outline)


```python

For my skills list and my short skills list, sort and classify these by skill type and add appropriate emojis at the beginning of each line for easy reading, and also structure the markdown outline with indented numbered lists in a small number of skill groups that classify the skills.  Make sure no skill is left off and show the numbered outline with suboutlines for both:     

# Unique List of Skills

Low-level system integrations (compilers, C++)
Hardware acceleration
Performance tuning for Transformers (NLP, CV, Speech)
Python APIs and framework optimizations (tokenizers, datasets)
Linux or embedded systems experience
Accelerating ML training/inference across AI hardware
Technical blogging, demos, community evangelism
Speaking at conferences, building & showcasing ML solutions
Open-source libraries (Transformers, Diffusers), ML Ops
Python, Rust, CUDA kernels, PyTorch/Keras
Industrial-level ML with text-generation-inference focus
Optimizing and scaling real-world ML services
Reliability & performance monitoring
Integrating Hugging Face with major cloud platforms
AWS, GCP, Azure, containerizing (Docker), MLOps pipelines
Typescript, Rust, MongoDB, Kubernetes
Building secure, robust developer experiences & APIs
Brainstorming unique ML/AI talents
Contributing to open-source projects like Transformers, Datasets, Accelerate
Fostering an active ML community
Building web-scale, high-quality LLM training datasets
Distributed data processing
Ablation & training small models for data-quality analysis
JavaScript/TypeScript ML: transformers.js, huggingface.js
In-browser inference via WebGPU, WASM, ONNX
Reducing model size & complexity (quantization)
Neural sparse models (SPLADE, BM25), semantic/dense retrieval
LLM usage & fine-tuning, chain-of-thought prompting
Energy efficiency & carbon footprint analysis
Post-training for LLMs (RLHF, PPO, DPO, instruction tuning)
Building LLM ‚Äúagents‚Äù with external tool usage
Creating LLM agents that control GUIs via screen recordings
Optimum integration for specialized AI hardware
Building essential tooling for the Hugging Face ML Hub
Full-stack development (Node.js, Svelte, MongoDB, AWS)
Collaborating with researchers in non-AI scientific fields
LLM-based code suggestions in Gradio Playground
Speech-to-text, text-to-speech, speaker diarization


# Consolidated Similar Skills

Python (Python APIs, Python, transformers.js, huggingface.js)
Kubernetes/K8s (Kubernetes)
GPU/TPU/Hardware (Hardware acceleration, GPU/TPU/Hardware, Accelerating ML training/inference across AI hardware, Optimum integration for specialized AI hardware)
Machine Learning (Machine Learning, Industrial-level ML, LLM usage & fine-tuning, Energy efficiency & carbon footprint analysis)
React/TypeScript/JS (React/TypeScript/JS, JavaScript/TypeScript ML)
AWS/GCP (AWS, GCP, Azure)
PyTorch (PyTorch/Keras)
Distributed Systems (Distributed data processing, Distributed training)
Linux/OS (Linux or embedded systems experience)
CUDA/Low-level (Low-level system integrations, CUDA kernels)
Open-source Contributions (Open-source libraries, Contributing to open-source projects, Fostering an active ML community)
Community Engagement (Technical blogging, demos, community evangelism, Speaking at conferences, building & showcasing ML solutions)
MLOps (MLOps pipelines, ML Ops)
Performance Optimization (Performance tuning for Transformers, Reliability & performance monitoring, Optimizing and scaling real-world ML services)
Model Development (Ablation & training small models, Building LLM ‚Äúagents‚Äù, Creating LLM agents)

```


# Unique List of Skills

Low-level system integrations (compilers, C++)
Hardware acceleration
Performance tuning for Transformers (NLP, CV, Speech)
Python APIs and framework optimizations (tokenizers, datasets)
Linux or embedded systems experience
Accelerating ML training/inference across AI hardware
Technical blogging, demos, community evangelism
Speaking at conferences, building & showcasing ML solutions
Open-source libraries (Transformers, Diffusers), ML Ops
Python, Rust, CUDA kernels, PyTorch/Keras
Industrial-level ML with text-generation-inference focus
Optimizing and scaling real-world ML services
Reliability & performance monitoring
Integrating Hugging Face with major cloud platforms
AWS, GCP, Azure, containerizing (Docker), MLOps pipelines
Typescript, Rust, MongoDB, Kubernetes
Building secure, robust developer experiences & APIs
Brainstorming unique ML/AI talents
Contributing to open-source projects like Transformers, Datasets, Accelerate
Fostering an active ML community
Building web-scale, high-quality LLM training datasets
Distributed data processing
Ablation & training small models for data-quality analysis
JavaScript/TypeScript ML: transformers.js, huggingface.js
In-browser inference via WebGPU, WASM, ONNX
Reducing model size & complexity (quantization)
Neural sparse models (SPLADE, BM25), semantic/dense retrieval
LLM usage & fine-tuning, chain-of-thought prompting
Energy efficiency & carbon footprint analysis
Post-training for LLMs (RLHF, PPO, DPO, instruction tuning)
Building LLM ‚Äúagents‚Äù with external tool usage
Creating LLM agents that control GUIs via screen recordings
Optimum integration for specialized AI hardware
Building essential tooling for the Hugging Face ML Hub
Full-stack development (Node.js, Svelte, MongoDB, AWS)
Collaborating with researchers in non-AI scientific fields
LLM-based code suggestions in Gradio Playground
Speech-to-text, text-to-speech, speaker diarization


# Consolidated Similar Skills

Python (Python APIs, Python, transformers.js, huggingface.js)
Kubernetes/K8s (Kubernetes)
GPU/TPU/Hardware (Hardware acceleration, GPU/TPU/Hardware, Accelerating ML training/inference across AI hardware, Optimum integration for specialized AI hardware)
Machine Learning (Machine Learning, Industrial-level ML, LLM usage & fine-tuning, Energy efficiency & carbon footprint analysis)
React/TypeScript/JS (React/TypeScript/JS, JavaScript/TypeScript ML)
AWS/GCP (AWS, GCP, Azure)
PyTorch (PyTorch/Keras)
Distributed Systems (Distributed data processing, Distributed training)
Linux/OS (Linux or embedded systems experience)
CUDA/Low-level (Low-level system integrations, CUDA kernels)
Open-source Contributions (Open-source libraries, Contributing to open-source projects, Fostering an active ML community)
Community Engagement (Technical blogging, demos, community evangelism, Speaking at conferences, building & showcasing ML solutions)
MLOps (MLOps pipelines, ML Ops)
Performance Optimization (Performance tuning for Transformers, Reliability & performance monitoring, Optimizing and scaling real-world ML services)
Model Development (Ablation & training small models, Building LLM ‚Äúagents‚Äù, Creating LLM agents)

# Percentages

Python: 6 mentions
Kubernetes/K8s: 2 mentions
GPU/TPU/Hardware: 4 mentions
Machine Learning: 4 mentions
React/TypeScript/JS: 2 mentions
AWS/GCP: 3 mentions
PyTorch: 2 mentions
Distributed Systems: 2 mentions
Linux/OS: 2 mentions
CUDA/Low-level: 2 mentions
Open-source Contributions: 3 mentions
Community Engagement: 3 mentions
MLOps: 2 mentions
Performance Optimization: 3 mentions
Model Development: 3 mentions

## Total mentions: 35

## Percentages:

Python: (6/35) * 100 = 17.14%
Kubernetes/K8s: (2/35) * 100 = 5.71%
GPU/TPU/Hardware: (4/35) * 100 = 11.43%
Machine Learning: (4/35) * 100 = 11.43%
React/TypeScript/JS: (2/35) * 100 = 5.71%
AWS/GCP: (3/35) * 100 = 8.57%
PyTorch: (2/35) * 100 = 5.71%
Distributed Systems: (2/35) * 100 = 5.71%
Linux/OS: (2/35) * 100 = 5.71%
CUDA/Low-level: (2/35) * 100 = 5.71%
Open-source Contributions: (3/35) * 100 = 8.57%
Community Engagement: (3/35) * 100 = 8.57%
MLOps: (2/35) * 100 = 5.71%
Performance Optimization: (3/35) * 100 = 8.57%
Model Development: (3/35) * 100 = 8.57%

# Conceptual Pie Chart

1. Python would be the largest segment at 17.14%.
2. GPU/TPU/Hardware and Machine Learning would each take 11.43%.
3. Smaller segments include AWS/GCP, Open-source Contributions, Community Engagement, Performance Optimization, and Model Development each at 8.57%.
4. The smallest segments would be Kubernetes/K8s, React/TypeScript/JS, PyTorch, Distributed Systems, Linux/OS, CUDA/Low-level, and MLOps each at 5.71%.

---

1Ô∏è‚É£ üß†‚öôÔ∏è Machine Learning Engineer in the Optimization team ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Low-level system integrations (compilers, C++), hardware acceleration
‚Ä¢ Performance tuning for Transformers (NLP, CV, Speech)
‚Ä¢ Python APIs and framework optimizations (tokenizers, datasets)
‚Ä¢ Linux or embedded systems experience

2Ô∏è‚É£ ‚ö°üó£Ô∏è Machine Learning Optimization Evangelist ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Accelerating ML training/inference across AI hardware (NVIDIA, AMD, Intel, etc.)
‚Ä¢ Technical blogging, demos, and community evangelism
‚Ä¢ Speaking at conferences, building & showcasing ML solutions
‚Ä¢ Open-source libraries (Transformers, Diffusers), ML Ops

3Ô∏è‚É£ üöÄüß© Machine Learning Engineer, Fast Optimized Inference ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Python, Rust, CUDA kernels, PyTorch/Keras
‚Ä¢ Industrial-level ML with text-generation-inference focus
‚Ä¢ Optimizing and scaling real-world ML services
‚Ä¢ Reliability & performance monitoring

4Ô∏è‚É£ ‚òÅÔ∏èü§ñ Cloud Machine Learning Engineer ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Integrating Hugging Face (Transformers, Diffusers) with major cloud platforms
‚Ä¢ AWS, GCP, Azure, containerizing (Docker), MLOps pipelines
‚Ä¢ Typescript, Rust, MongoDB, Kubernetes are nice-to-have
‚Ä¢ Building secure, robust developer experiences & APIs

5Ô∏è‚É£ ‚ú®üÉè Wild Card ‚Äì (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Open-ended role‚Äîbring your unique ML/AI talents
‚Ä¢ Brainstorm with Hugging Face to create your dream position
‚Ä¢ Potential for any specialized AI, open-source, or engineering focus

6Ô∏è‚É£ üåêüîì Open-Source Machine Learning Engineer ‚Äì International Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Contribute to Transformers, Datasets, Accelerate, etc.
‚Ä¢ Foster an active ML community (GitHub, forums, Slack)
‚Ä¢ Collaboration with researchers & practitioners worldwide
‚Ä¢ Focus on usability, performance, and accessibility in open source

7Ô∏è‚É£ üî¨üìù ML Research Engineer Internship, FineWeb ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Building web-scale, high-quality LLM training datasets
‚Ä¢ Distributed data processing (datatrove)
‚Ä¢ Ablation & training small models for data-quality analysis
‚Ä¢ Open-source mindset, experimentation on HPC clusters

8Ô∏è‚É£ üåêüíª Machine Learning Engineer Internship, WebML ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ JavaScript/TypeScript ML: transformers.js, huggingface.js
‚Ä¢ In-browser inference via WebGPU, WASM, ONNX
‚Ä¢ Building low-latency, interactive, privacy-focused apps
‚Ä¢ Demos & community-building for web-based ML

9Ô∏è‚É£ üíæüîß Machine Learning Engineer Internship, Quantization ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Reducing model size & complexity (int8, bitsandbytes, AutoGPTQ)
‚Ä¢ Integrating quantization into Transformers, Accelerate, PEFT
‚Ä¢ Benchmarking, performance optimization, blogposts
‚Ä¢ Advancing open-source quantization techniques

1Ô∏è‚É£0Ô∏è‚É£ üîçüìñ Machine Learning Engineer Internship, Information Retrieval ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Neural sparse models (SPLADE, BM25), semantic/dense retrieval
‚Ä¢ Extending Sentence Transformers library with new IR trainers
‚Ä¢ Fine-tuning IR models, Python, PyTorch
‚Ä¢ Building user-friendly search & retrieval pipelines

1Ô∏è‚É£1Ô∏è‚É£ üí°ü§ñ Machine Learning Engineer Internship, Generative AI ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ LLM usage & fine-tuning, chain-of-thought prompting
‚Ä¢ Enhancing smaller generative models for higher quality
‚Ä¢ Hardware acceleration, numeric precision, HPC optimization
‚Ä¢ Scalable Python code for LLM APIs & advanced inference

1Ô∏è‚É£2Ô∏è‚É£ ‚ö°üå± Machine Learning Engineer Internship, AI Energy Score ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Energy efficiency & carbon footprint of ML models
‚Ä¢ Hardware/optimization technique analysis
‚Ä¢ Serving stack experiments & measurement
‚Ä¢ Python, performance monitoring, environmental impact research

1Ô∏è‚É£3Ô∏è‚É£ üß†üõ†Ô∏è Machine Learning Engineer Internship, TRL ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Post-training for LLMs (RLHF, PPO, DPO, instruction tuning)
‚Ä¢ Hugging Face Transformers, PEFT, ZeRO
‚Ä¢ Distributed training, scaling from single GPU to large clusters
‚Ä¢ Community support, tutorials, and library maintenance

1Ô∏è‚É£4Ô∏è‚É£ ü§ñ‚öôÔ∏è ML Research Engineer Internship, Agent AI ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Building LLM ‚Äúagents‚Äù with external tool usage
‚Ä¢ Fine-tuning for reasoning & multi-step tasks
‚Ä¢ HPC & H100 cluster training/inference orchestration
‚Ä¢ End-to-end open-source release & advanced LLM planning

1Ô∏è‚É£5Ô∏è‚É£ üñ±Ô∏èüíª ML Research Engineer Internship, GUI Agents ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Creating LLM agents that control GUIs via screen recordings
‚Ä¢ Multi-modal (vision + text) architectures
‚Ä¢ Fine-tuning & large-scale HPC model training
‚Ä¢ Orchestration frameworks, open-source releases

1Ô∏è‚É£6Ô∏è‚É£ ‚öôÔ∏è‚è´ Machine Learning Engineer Internship, Hardware Optimization ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Optimum integration for specialized AI hardware (NVIDIA, Intel, AMD, etc.)
‚Ä¢ Model exporting & conversion, performance benchmarks
‚Ä¢ Tooling for model inference across diverse backends
‚Ä¢ Collaboration & documentation for the developer community

1Ô∏è‚É£7Ô∏è‚É£ üèóÔ∏èüñ•Ô∏è Senior Product Software Engineer, ML Platform ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Building essential tooling for the Hugging Face ML Hub
‚Ä¢ Full-stack: Node.js, Svelte, MongoDB, AWS
‚Ä¢ Developer-first product focus with empathy for user experience
‚Ä¢ High sense of ownership in a fast-paced environment

1Ô∏è‚É£8Ô∏è‚É£ üåéüî¨ Community ML Research Engineer (non-AI scientific fields) ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Collaborating with researchers in biology, physics, quantum, etc.
‚Ä¢ Co-developing ML tools/models for domain-specific use cases
‚Ä¢ Open-source contributions, building partnerships & tutorials
‚Ä¢ Interdisciplinary approach bridging traditional science & ML

1Ô∏è‚É£9Ô∏è‚É£ üåê‚ú® Machine Learning Engineer Internship, Gradio ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ LLM-based code suggestions in Gradio Playground
‚Ä¢ Python & Svelte-based UI building for ML demos
‚Ä¢ Fine-tuning large language models, prompt engineering
‚Ä¢ Developer UX, user onboarding, interactive ML

2Ô∏è‚É£0Ô∏è‚É£ üé∂üîä Machine Learning Engineer for Audio ‚Äì US Remote (Salary: N/A) ‚Üí ??? üí∞
Key Skills & Tech:
‚Ä¢ Speech-to-text, text-to-speech, speaker diarization
‚Ä¢ Transformers-based audio pipelines
‚Ä¢ Python, open-source contributions (Transformers, etc.)
‚Ä¢ Making cutting-edge audio ML accessible to the community




----


Machine Learning Engineer in the Optimization team - US Remote
RemoteCustomer SuccessFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

Transformers in NLP pushed forward the computational requirements and the trend started to expand to other modalities such as Computer Vision and Speech which are actively adopting Transformer architectures to build the latest state-of-the-art models.

About the Role

Hugging Face has become the most popular, community-driven project for training, sharing, and deploying the most advanced machine learning models. Workload efficiency is key to our mission of democratizing state of the art and we are always looking to push the boundaries for faster, and more efficient ways to train and deploy models.

If you like digging into the dark side of low-level system integrations, compiler support, and framework optimizations: we should talk!

We are looking for talented people to join the Hugging Face Special Ops team, focusing on:

Bridging ü§ó transformers models with state-of-the-art AI hardware
Ensuring the above models meet the expected performance
Designing easy to use and proficient Developer Experience for our users
Deploying these models in the most efficient and scalable way.
This is an exciting opportunity to work at the edge of AI on both model architectures and hardware technologies! As additional material, you may want to take a look at  ü§ó.

About You

You‚Äôll enjoy working in this team if you like digging into the dark side of low-level system integrations, compiler support, and framework optimizations. At the intersection of software engineering and machine learning, you would be in charge of integrating the latest features from our hardware partners in Python/C++, designing rich and easy Python APIs in the continuity of what Hugging Face did with transformers, tokenizers, and the datasets library with a strong focus on performances. Linux or embedded devices experience would be a great plus for the job.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity.We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development.You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer parental leave and flexible paid time off.

We support our employees wherever they are. While we have office spaces in NYC and Paris, we‚Äôre very distributed and all remote employees have the opportunity to visit our offices. If needed, we‚Äôll also outfit your workstation to ensure you succeed.

We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.

We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.





Machine Learning Optimization Evangelist - US remote
RemoteCustomer SuccessFull time

New York, New York, United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

Hugging Face has become the most popular, community-driven project for training, sharing, and deploying the most advanced machine learning models. Workload efficiency is key to our mission of democratizing state of the art and we are always looking to push the boundaries for faster, and more efficient ways to train and deploy models.

About the Role

As a Machine Learning Optimization Evangelist, your goal will be to increase the impact of the Hugging Face ML Optimization team by educating the community of ML practitioners on how they can benefit by accelerating their training and inference workloads.

The Hugging Face ML Optimization team is working through strategic collaborations with the most used AI Accelerators (incl. NVIDIA, AMD, Intel, Gaudi, Inferentia, TPU), Clouds (AWS, GCP, Azure, Cloudflare) and Systems (Dell, Nutanix), to make it easy for the community to use Hugging Face models and libraries on these compute platforms.

These partnerships are core to Hugging Face product strategy as an open platform (no lock-in of customers), and monetization strategy to drive usage and revenue for our partners through commercial collaborations and product extensions.

This is not a marketing role, or a business development role. Your impact will be driving visibility and usage of integrations with strategic partners, through activities including:

Publishing technical blog posts
Contributing documentation and code examples
Speaking to business and technical audiences at partner conferences,
Participating in, or producing webinars
Building and evangelizing demos
Leading GTM conversations with strategic partners.
You will be at the forefront of Generative AI (and how to build practical stuff with open source). You will work hand in hand with the most important companies in AI. You will enjoy a lot of autonomy and full creative control, with the goal to have 10x more impact than a similar role at a big tech corporation.

About You

You are passionate about ML Engineering, building practical AI applications, putting them in production, and accelerating them to the best of the hardware ability. You love learning new challenging engineering concepts and technologies, and discussing them with engineers. You appreciate a good Developer Experience, and take pride in your code being easy to understand.

You are a great communicator and educator, comfortable (as much as one can be!) with public speaking to technical audiences.

You love engaging with the ML community in a positive and helpful way. Existing engagement in social platforms (GitHub, LinkedIn, Twitter, Reddit, etc) or other communication/education channels is expected. Having experience in Open Source development will be helpful..

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity.We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development.You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer parental leave and flexible paid time off.

We support our employees wherever they are. While we have office spaces in NYC and Paris, we‚Äôre very distributed and all remote employees have the opportunity to visit our offices. If needed, we‚Äôll also outfit your workstation to ensure you succeed.

We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.

We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.






Machine Learning Engineer, Fast Optimized Inference - US Remote
RemoteProductFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the role:

As a Machine learning Engineer, you work mainly on creating great libraries highly focused on real world ML use cases. We're building on top of our open-source to create more specialized code with a focus on industrial level of usage.

We are searching for someone who brings fresh ideas, demonstrates a unique and informed viewpoint, and enjoys collaborating with a progressive, nimble and decentralized approach to develop real-world solutions and positive user experiences at every interaction.

Objectives of this role:

Develop specialized software for specific machine learning (ML) use cases that have broad applications, similar to [text-generation-inference]().
Utilize existing library frameworks to create scalable software solutions for industrial purposes.
Enhance the reliability, quality, and time-to-market of our software suite. Measure and optimize system performance to stay ahead of customer needs and drive innovation.
Manage the production environment by monitoring availability and ensuring overall system health. We run our own tools
About you:

If you are a passionate Machine Learning Engineer with a keen interest in AI and proficient with Python, Rust and specialized Cuda kernels Frameworks (transformers of course + Keras or PyTorch), we would love to hear from you. Join our team and contribute to the advancement of AI technologies while working alongside talented professionals in a collaborative and stimulating environment.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also flexible parental leave and paid time off.

We support our employees wherever they are. While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.

We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.







Cloud Machine Learning Engineer - US remote
RemoteCustomer SuccessFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

Hugging Face has become the most popular, community-driven project for training, sharing, and deploying the most advanced machine learning models. Workload efficiency is key to our mission of democratizing state of the art and we are always looking to push the boundaries for faster, and more efficient ways to train and deploy models.

About the Role

We are looking for a Cloud Machine Learning engineer responsible to help build machine learning solutions used by millions leveraging cloud technologies. You will work on integrating Hugging Face's open-source libraries like Transformers and Diffusers, with major cloud platforms or managed SaaS solutions.

You may want to take a look at these announcements to get a better sense of what this role might mean in practice ü§ó:




Responsibilities

We are looking for talented people with deep experience and passion for both Machine Learning (at the framework level) and Cloud Services:

Bridging and integrating ü§ó transformers/diffusers models with a different Cloud provider.
Ensuring the above models meet the expected performance
Designing & Developing easy-to-use, secure, and robust Developer Experiences & APIs for our users.
Write technical documentation, examples and notebooks to demonstrate new features
Sharing & Advocating your work and the results with the community.
About You

You'll enjoy working on this team if you have experience with and interest in deploying machine learning systems to production and build great developer experiences. The ideal candidate will have skills including:

Deep experience building with Hugging Face Technologies, including Transformers, Diffusers, Accelerate, PEFT, Datasets
Expertise in Deep Learning Framework, preferably PyTorch, optionally XLA understanding
Strong knowledge of cloud platforms like AWS and services like Amazon SageMaker, EC2, S3, CloudWatch and/or Azure and GCP equivalents.
Experience in building MLOps pipelines for containerizing models and solutions with Docker
Familiarity with Typescript, Rust, and MongoDB, Kubernetes are helpful
Ability to write clear documentation, examples and definition and work across the full product development lifecycle
Bonus: Experience with Svelte & TailwindCSS
More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity.We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development.You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer parental leave and flexible paid time off.

We support our employees wherever they are. While we have office spaces in NYC and Paris, we‚Äôre very distributed and all remote employees have the opportunity to visit our offices. If needed, we‚Äôll also outfit your workstation to ensure you succeed.

We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.

We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.




Wild Card
RemoteWild CardFull time

United States
Overview
Application
Description
If you don't see the perfect job position, just apply to this one - we'll brainstorm with you to put you in position to do the best work of your life at Hugging Face!

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer parental leave and flexible paid time off.

We support our employees wherever they are. While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.

We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.




Open-Source Machine Learning Engineer - International Remote
RemoteOpen SourceFull time

New York, New York, United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

As an open-source Machine Learning Engineer, you will work to improve the open-source machine learning ecosystem. You will mainly work with existing open-source libraries, such as Transformers, Datasets, or Accelerate, and you will interact with users and contributors of the broad open-source machine learning ecosystem. We'll brainstorm with you to put you in a position to do the work that interests you and that is impactful.

You'll get to foster one of the most active machine learning communities, helping users contribute to and use the tools that you build. You'll interact with Researchers, ML practitioners and data scientists on a daily basis through GitHub, our forums, or slack.

About you

If you love open-source, are passionate about making complex technology more accessible, and want to contribute to one of the fastest-growing ML ecosystems, then we can't wait to see your application!

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and background complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer parental leave and flexible paid time off.

We support our employees wherever they are. While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.

We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.

Requirements
Please provide a cover letter mentioning why you would like to work in open-source at Hugging Face. We encourage you to mention your skills, potential expertise, and topics on which you would like to work.




ML Research Engineer Internship, FineWeb - US Remote
RemoteInternshipsFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

High-quality datasets are the foundation of strong LLMs, yet, most labs releasing state-of-the-art models are vague when it comes to the pretraining data. At Hugging Face we want to enable all the community to build the best models by building and open-sourcing the finest datasets. FineWeb and FineWeb-Edu are examples of very strong, web-scale datasets we released this year while also open-sourcing the distributed processing library datatrove.

During this internship you will work alongside the FineWeb team and build the next generation of high-quality web data, by running distributed data processing and ablating the data quality by training small models. Checkout hf.co/science for more information about the science team at Hugging Face and the  and  blog posts for the work of this team specifically.

About You

If you love open-source but also have an eye for art and creativity, are passionate about making complex technology more accessible to engineers and artists, and want to contribute to one of the fastest-growing ML ecosystems, then we can't wait to see your application!

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and background complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.

Requirements
Please provide a cover letter mentioning why you would like to work in open-source at Hugging Face. We encourage you to mention your skills, potential expertise, and topics on which you would like to work.




Machine Learning Engineer Internship, WebML - US Remote
RemoteInternshipsFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

Hugging Face maintains a large collection of open source machine learning libraries, including transformers, diffusers, and datasets, just to name a few. However, these are all implemented in Python, meaning they aren‚Äôt as easily accessible to JavaScript/TypeScript developers. So, in order to grow the Hugging Face ecosystem, we decided to build projects like transformers.js and huggingface.js with the primary goal of bridging the gap between web development and machine learning.

WebML (Web Machine Learning) unlocks a range of new possibilities for building web applications by enabling models to run locally in the browser. Combining on-device machine learning with the plethora of APIs that browsers provide, empowers developers to create low-latency, interactive, and privacy-focused applications that can scale and reach users without them needing to install anything!

This internship operates at the intersection of software engineering, machine learning, and open-source community building. The focus will be to expand the Hugging Face ecosystem to web developers through the creation and maintenance of easy-to-use JS/TS machine learning libraries.

By the end of the internship, the candidate will have touched on many aspects of web machine learning, including: converting and optimizing models for in-browser inference (ONNX, quantization), enabling models to run in-browser at near-native speeds (WebGPU, WebNN, WASM), building demo applications to showcase new features, and fostering a collaborative open-source community.

About You

If you love open-source but also have an eye for art and creativity, are passionate about making complex technology more accessible to engineers and artists, and want to contribute to one of the fastest-growing ML ecosystems, then we can't wait to see your application!

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and background complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.




Machine Learning Engineer Internship, Quantization - US Remote
RemoteInternshipsFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

Quantization is a technique to reduce the computational and memory costs of running inference by representing the weights and activations with low-precision data types like 8-bit integer (int8) instead of the usual 32-bit floating point (float32). It is a very promising technique as it allows to run and fine-tune on consumer-grade hardware LLMs with minimal performance degradation.

This internship works at the intersections of software engineering, machine learning engineering, and education. The focus will be to integrate new quantization methods in Hugging Face ecosystem (transformers, accelerate, peft, diffusers), maintain existing integration (bitsandbytes, awq, autogptq) as well as making sure that the community is aware of these tools through benchmarks and blogposts. The ultimate goal of this internship is to drive forward quantization in the open source ecosystem.

About You

If you love open-source but also have an eye for art and creativity, are passionate about making complex technology more accessible to engineers and artists, and want to contribute to one of the fastest-growing ML ecosystems, then we can't wait to see your application!

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and background complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.





Machine Learning Engineer Internship, Information Retrieval - US Remote
RemoteInternshipsFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

In Information Retrieval, modern search solutions combine both semantic search (e.g. similar meaning) and lexical search (e.g. exact keyword). The former is often implemented via a dense bi-encoder (a.k.a. Sentence Transformer) model, whereas the latter usually involves a sparse (e.g. SPLADE, BM25) model or algorithm.

Currently, there is no accessible, de-facto solution for training or fine-tuning neural sparse models. To address this, this internship aims to implement an existing neural sparse model architecture and a matching trainer into the Sentence Transformers library, prioritizing ease of use.

About You

If you love open-source but also have an eye for art and creativity, are passionate about making complex technology more accessible to engineers and artists, and want to contribute to one of the fastest-growing ML ecosystems, then we can't wait to see your application!

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and background complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.



Machine Learning Engineer Internship, Generative AI - US Remote
RemoteInternshipsFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

ChatGPT took the world by storm due to its surprising capabilities. By the time it was launched it was a massive model, requiring many GPUs to run. Fast forward to 2024, and we have 1B LLMs that fit in a smartphone and have similar quality levels. The community has also realized that small models using techniques like chain of thought can outperform much larger models. The focus of this internship is on model usage: how can we extract a higher-quality output from existing small-sized pre-trained models?

This internship works at the intersection of software engineering and machine learning engineering, bringing state-of-the-art generative breakthroughs to transformers in a user-friendly fashion. By the end of this internship, the candidate will have touched all facets that power LLM APIs, including hardware acceleration, numerical precision problems, common machine learning caveats, and the importance of writing scalable software.

About You

If you love open-source but also have an eye for art and creativity, are passionate about making complex technology more accessible to engineers and artists, and want to contribute to one of the fastest-growing ML ecosystems, then we can't wait to see your application!

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and background complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.


Machine Learning Engineer Internship, AI Energy Score - US Remote
RemoteInternshipsFull time

New York, New York, United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

The energy requirements of machine learning models have been rising in recent years, raising concerns regarding the impacts of this on energy grids and the environment.

Building upon the  this internship will continue experimentation and analysis to get a better understanding of the energy efficiency of different models and deployment contexts (hardware, optimization techniques, serving stacks).

About You

If you love open-source but also have an eye for art and creativity, are passionate about making complex technology more accessible to engineers and artists, and want to contribute to one of the fastest-growing ML ecosystems, then we can't wait to see your application!

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and background complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.




Machine Learning Engineer Internship, TRL - US Remote
RemoteInternshipsFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

In the past year the focus of building LLMs has gradually shifted from pretraining to post-training. This means spending more and more time on figuring out how to get models follow instructions reliably, use tools and generally align with certain values. With over 10k Github stars and close to 1M monthly installs the  has become one of the go-to libraries for post-training. It scales flexibly from a single GPU to large clusters of GPUs using PEFT and ZeRO and offers a wide range of trainers for the latest post training techniques such as PPO or DPO and many more. In addition it includes a user friendly CLI that allows training models with a single command.

During this internship, you will collaborate with the research team to integrate cutting-edge methods into the library, maintain a clean and scalable codebase, and ensure its usability through thoughtful documentation. You‚Äôll actively engage with the TRL community by responding to issues, gathering feedback, and fostering collaboration through thoughtful discussions and support, ensuring the library continues to meet developers' needs. Your contributions will directly influence thousands of developers globally, advancing the adoption of state-of-the-art post-training techniques and laying the groundwork for the next generation of customizable, instruction-following LLMs.

About You

We are looking for someone with knowledge and experience in some of the following areas:

Machine Learning: Fine-tuning large language models (LLMs) or vision-language models (VLMs), and optimisation techniques.
Software Development: Proficiency in Python, PyTorch, and frameworks like Hugging Face Transformers, with experience in distributed training and GPU acceleration.
Open-Source: Familiarity with Git/GitHub workflows, community engagement, documentation, and collaborative development.
Research and Experimentation: Exposure to cutting-edge ML research, benchmarking, and testing fine-tuning methods.
Tooling and Maintenance: Building tools to streamline workflows, ensuring software stability, backward compatibility, versioning, and delivering reliable releases.
Communication and Outreach: Writing blog posts, tutorials, and sharing updates on platforms like LinkedIn to engage with the community and make complex concepts accessible to a wider audience.
You‚Äôre passionate about open-source innovation and making advanced ML tools accessible globally. You value continuity in software development, ensuring users have a dependable and evolving library to rely on.

Even if you don‚Äôt check every box, we encourage you to apply‚Äîwe value diverse skills, perspectives, and experiences that complement our mission.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.

Requirements
Please provide a cover letter mentioning why you would like to work in open-source at Hugging Face. We encourage you to mention your skills, potential expertise, and topics on which you would like to work.




ML Research Engineer Internship, Agent AI - US Remote
RemoteInternshipsFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

LLM Agents are an exciting new field giving LLMs more autonomy and tools to solve more complex and longer tasks. Building capable agents is both exciting and challenging as it lies at the intersection of post-training, inference, orchestration as well as UX design.

During this internship you will work specifically on agents that can reason over data using code. This work will include the whole agent stack from preparing fine-tuning datasets, training recipes and inference orchestration. You will leverage our compute CPU and H100 clusters for large scale processing and model training. Finally we‚Äôll release the full recipe as well as the model serving as a foundation for the community to build on.

Checkout  for more information about the science team at Hugging Face.

About You

If you love open-source but also have an eye for art and creativity, are passionate about making complex technology more accessible to engineers and artists, and want to contribute to one of the fastest-growing ML ecosystems, then we can't wait to see your application!

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and background complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.

Requirements
Please provide a cover letter mentioning why you would like to work in open-source at Hugging Face. We encourage you to mention your skills, potential expertise, and topics on which you would like to work.




ML Research Engineer Internship, GUI Agents - US Remote
RemoteInternshipsFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

2025 will be the year of Agents.

LLM agents, what are these? In short, agentic systems are a way to connect an LLM to the outside world, to let it perform actions and observations. The promises of such a setup are immense : it enables an LLM to get external knowledge to ground its reasoning, use reliable tools for specific tasks, and even self-correct errors through additional iterations.

An agentic system requires a powerful enough LLM to reason and plan actions. Now with the progress of LLMs in general and specifically open models overtaking closed ones, we have all weapons to build great agents. So Hugging Face is launching a moonshot in that direction.

Building agents is both exciting and challenging as it lies at the intersection of post-training, inference, orchestration as well as UX design.

During this internship you will work specifically on agents that take screen recordings from any GUI, and act through a mouse/keyboard setup. You may have seen such models from other companies: we‚Äôll make them better and open.

This work will include the whole agent stack, from improving the framework, to preparing fine-tuning datasets, training recipes, and inference orchestration. You will leverage our compute CPU and H100 clusters for large scale processing and model training. Finally we‚Äôll release any code we built, as well as the model serving as a foundation for the community to build on.

Checkout  for more information about the science team at Hugging Face.

About You

If you love open-source but also have an eye for art and creativity, are passionate about making complex technology more accessible to engineers and artists, and want to contribute to one of the fastest-growing ML ecosystems, then we can't wait to see your application!

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and background complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.

Requirements
Please provide a cover letter mentioning why you would like to work in open-source at Hugging Face. We encourage you to mention your skills, potential expertise, and topics on which you would like to work.




Machine Learning Engineer Internship, Hardware Optimization - US Remote
RemoteInternshipsFull time

United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

At Hugging Face, we‚Äôre leading the AI revolution with a mission to democratize machine learning. Through our open-source libraries, state-of-the-art models, and curated datasets, we empower developers and researchers to build cutting-edge AI solutions. Besides, to ensure our models run seamlessly across a diverse range of hardware platforms, our ML Optimization team partners with some of the world‚Äôs top hardware innovators, including AWS Inferentia and Trainium, AMD CPUs and Instinct GPUs, Nvidia GPUs, Google TPUs, Intel CPUs, and Habana accelerators.

At the heart of these collaborations is Optimum, our open-source library that bridges the Hugging Face ecosystem with specific hardware. Optimum and its sub-packages are pivotal in optimizing performance and accessibility, helping developers maximize efficiency and scalability.

As an intern on the ML Optimization team, you‚Äôll play a key role in shaping the future of AI. Your contributions will involve developing and refining cutting-edge solutions for widely-used and emerging hardware platforms, sharing these advancements with the Hugging Face community, and enabling researchers and developers worldwide to access the best tools and technologies. This is your opportunity to make a tangible impact on the AI landscape while working alongside world-class experts and forward-thinking hardware providers.

Key Responsibilities

1. Develop an online exporter tool: Create a user-friendly online tool to convert Hugging Face models for specific hardware platforms leveraging Optimum.

2. Bake the recipes: Author comprehensive guides to help users deploy Hugging Face models on various hardware platforms, including detailed instructions and best practices.

3. Design User Flow: Develop a seamless flow to guide users from traditional Hugging Face libraries (like Transformers and Diffusers) to alternative hardware backends. This includes integrating these solutions into the Hugging Face Hub and our partners' platforms.

4. Optimize Hardware Selection: Conduct inference experiments across different hardware backends to identify the strengths and weaknesses of each platform under various scenarios. Provide clear guidelines to help users select the best hardware for their specific tasks.

5. Advocate and Communicate Insights: Collaborate with the Hugging Face Advocacy team to share your findings and insights through various channels, including blog posts, tweets, leaderboards, Spaces, and YouTube videos. You will educate and inspire the community about the importance of hardware in AI.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.

Requirements
Please provide a cover letter mentioning why you would like to work in open-source at Hugging Face. We encourage you to mention your skills, potential expertise, and topics on which you would like to work.





Senior Product Software Engineer, ML Platform - US Remote
HybridProductFull time

New York, New York, United States
Overview
Application
Description
Here at Hugging Face, we‚Äôre on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.

We have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 1 Million+ models and 320K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Grammarly and NASA.

About the Role

To fulfill our mission of building the Github of Machine Learning, our team is now looking for a Product Engineer with experience working in a fast-paced environment. In this unique position, you will play a key role by building the essential tooling required to interact with our Machine Learning Hub, which is rapidly becoming a go-to destination for companies and individuals to host and run their models.

You'll work with a supportive team of talented engineers while enjoying a lot of autonomy to build and own features end-to-end. This is a great opportunity to be an early contributor to the biggest platform shift of the decade.

About You

You'll enjoy working here if you are:

Enthusiastic about working on technical challenges for ML-focused products.
Are a generalist and polyglot engineer with an ability to pick up new frameworks quickly and willing to work across the stack from backend to frontend (Typescript, Node.js, Svelte, MongoDB, AWS).
Comfortable working in a fast-paced and ambiguous environment, aka shifting sands of startup land.
Excited to be a builder for builders! Empathy for developers across the stack and an enthusiasm for developer-first products.
A great product sense and experience building products that our users rely on.
Enjoy understanding technical domains deeply and are willing to really get into the weeds.
A high sense of technical and product ownership and a desire to please the customer.
You know what it takes to build cross-platform tools, and you have experience working collaboratively across the stack.

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and backgrounds complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias toward impact and is always challenging ourselves to grow continuously. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer flexible parental leave and paid time off.

We support our employees wherever they are. While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.

We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.





Community ML Research Engineer, non-AI scientific fields - US Remote
RemoteScienceFull time

New York, New York, United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github. We focus on developing open-source tools and models that push the boundaries of AI while remaining efficient and user-friendly.

About the Role

As a Community Machine Learning Research Engineer, you will be collaborating with science communities while doing impactful machine learning research. 

You‚Äôll be responsible for : 

Build and facilitate non-consortium-based research collaborations with researchers in non-AI scientific fields (e.g., biology, physics, chemistry, quantum, fluid dynamics) to explore innovative applications of ML tools.
Co-build ML tools and models for scientific use cases, co-developing solutions and publishing pre-trained models or datasets tailored to these domains.
Educate and engage with the scientific community through tutorials, workshops, and open-source contributions to bridge the gap between ML and traditional sciences.
Foster strategic partnerships and community research initiatives with academic institutions and organizations to advance interdisciplinary innovation and adoption.
The work will likely be pretty varied: in some cases, you might work with industry or academic partners early in the research process. In other cases, you might set up these collaborations at a high level and guide them to the final release. We‚Äôre interested in folks who are willing to experiment with different models and figure out how to have the most impact while working with the amazing science machine learning community.

About You

You have done cutting-edge machine learning research and/or engaged and collaborated with the research community, such as Jean-Zay, Alan Turing Institute, PRACE, Lawrence Berkeley National Laboratory, Institute for Quantum Computing ‚Ä¶

You'll enjoy working here if you:

Have a generalist Research Engineer with an ability to experiment with different models and figure out how to have the most impact while working with the amazing science machine learning community.
Are comfortable working in a fast-paced and ambiguous environment, aka shifting sands of startup land. This includes communicating with other teams to efficiently join forces, in Hugging Face‚Äôs very decentralized/anarchic organization.
Enjoy understanding technical domains deeply and are willing to really get into the weeds.
If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and backgrounds complement one another. We're happy to consider where you might be able to make the biggest impact.

Checkout for more information about the science team at Hugging Face.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias toward impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer flexible parental leave and paid time off.

We support our employees wherever they are. While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed. However, this job offer is quite special as it's best if you are in-person in our new Paris office. We provide relocation packages if necessary.

We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.

We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.



Machine Learning Engineer Internship, Gradio - US Remote
RemoteInternshipsFull time

New York, New York, United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

Gradio is the most widely used library to build and share machine learning demos, with more than 6m monthly downloads on PYPI. It is maintained by the Gradio team within Hugging Face. 

We are currently working on a suite of AI tools to help users quickly understand and write Gradio code.The first is the Playground: a code editor on our website which can generate or update complete Gradio demos based on a user‚Äôs query. 

The main objective for a Machine Learning Engineering intern will be to expand this effort. We can leverage ~500k Gradio spaces and thousands of existing prompts from users to build a sophisticated model pipeline with the proper context of how Gradio works. 

More and more developers are relying on LLMs for assistance in writing code, but these LLMs often do not have proper context on how Gradio works. Gradio has evolved from a library to an ecosystem for machine learning developers, with custom components contributed from our community, Python and JS clients, and Gradio Lite. To advance these efforts and as Gradio's usage and developer community grows, it's important to invest in tools that can help users learn, build and contribute to Gradio.

About You

You‚Äôre passionate about open source and making advanced ML tools accessible. You are someone who stays up to date with the latest machine learning trends and models. You love experimenting and have a high bias for action and results. 

Some of our requirements for this role :

Experience using modern deep learning libraries and LLM APIs and understanding tradeoffs between different models and APIs.
Knowledge of how to fine-tune LLMs, create retrieval-augmented generation pipelines, and use re-rankers for two-stage retrieval
You‚Äôre comfortable exploring and contributing to a codebase consisting of Python and Svelte-flavored JavaScript
You have a ‚Äúproduct mindset‚Äù -- like experimenting with different user interfaces to build products that are useful to to hundreds of thousands of users 
If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and backgrounds complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We support our employees wherever they are. While we have office spaces around the world, especially in the US, Canada, and Europe, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We support the community. We believe significant scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.

Requirements
Please provide a cover letter mentioning why you would like to work in open-source at Hugging Face. We encourage you to mention your skills, potential expertise, and topics on which you would like to work.







Machine Learning Engineer for Audio - US Remote
RemoteOpen SourceFull time

New York, New York, United States
Overview
Application
Description
At Hugging Face, we‚Äôre on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users & 100k organizations who collectively shared over 1M models, 300k datasets & 300k apps. Our open-source libraries have more than 400k+ stars on Github.

About the Role

For this position, you will be making cutting edge speech-to-text and text-to-speech technologies more accessible to the open-source community.

You will work in existing open-source libraries, such as Transformers, boosting the support for robust speech-to-text, speaker diarization, text-to-speech and lead the creation of novel open-source libraries for ML in audio.

You'll get to foster one of the most active machine learning communities, helping users contribute to and use the tools that you build. You'll interact with Researchers, ML practitioners and data scientists on a daily basis through GitHub, Discord, our forums, or Slack.

About you

If you love open-source, are passionate about new technologies in text-to-speech and speech-to-text, then we can't wait to see your application!

Industry experience in speech recognition, speaker diarization, dialogue systems or text-to-speech is a plus.

If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and backgrounds complement one another. We're happy to consider where you might be able to make the biggest impact.

More about Hugging Face

We are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to grow continuously. We provide all employees with reimbursement for relevant conferences, training, and education.

We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer parental leave and flexible paid time off.

We support our employees wherever they are. While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.

We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.

We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.








```python

Variation 1:

Da, da, da, da, da
Riding the cosmic tide, yeah (Feel that vibe!)
Da, da, da, da, da
Whirlpool deep to Atlantis, high tide (Uh, let‚Äôs ride!)

From the stars we dive, waves spin like a dream,
Cosmic vortex pulling us into a futuristic scheme.
Symbols light the corners where time twists and bends,
Mixing myth with high-tech‚Äîwhere chaos and order blend.

King of beats in space, planets align in our sight,
Rollin‚Äô deep with cosmic flair, igniting the night.
Every turn‚Äôs a portal where destiny gets unfurled,
Atlantis calls us home‚Äîwelcome to a brand-new world!

Chorus:
Whirlpool of dreams, let the rhythm flow free,
From cosmic streets to ocean beats, we rewrite destiny.
Ride that vortex, feel the pulse of the night,
Atlantis and the stars, where legends ignite!

Variation 2:

Da, da, da, da, da
Space ace on deck, yeah (Aaron‚Äôs in the mix!)
Da, da, da, da, da
Diving through the whirlpool, where fate clicks (Let‚Äôs go!)

Blast off from Earth into a nebula so deep,
Where the whirlpool‚Äôs pull makes the galaxies weep.
Atlantis emerges‚Äîa city of myth and gleam,
Tech fused with ancient lore, like a visionary dream.

I‚Äôm the top dog of space, remixing time and rhyme,
Interstellar beats break the bounds of space and time.
Symbols on the tide, runes glowing in the spray,
Cosmic crossroads of the past and future, here to stay.

Chorus:
Ride that cosmic swirl, let your soul be free,
From the nebula to Atlantis, unlock your destiny.
With the rhythm of the universe, we groove and we soar,
In the vortex of legend, we‚Äôre forever hardcore!

Variation 3:

Da, da, da, da, da
Spin it in the void, yeah (Cosmic Wacker!)
Da, da, da, da, da
On a whirlpool ride where legends regroup (Feel the swoop!)

We blast off, then dive into that swirling astral sea,
A vortex of innovation where the old meets destiny.
Atlantis shimmers in the depths with a radiant golden gleam,
An epic fusion of organic tech‚Äîlike living in a dream.

Rollin‚Äô deep with A.C.W. and a sprinkle of mystic lore,
Every symbol, every beat, tells tales of cosmic yore.
From the urban streets to a future where myths revive,
We ride the whirlpool of time‚Äîwhere the real and surreal collide.

Chorus:
Let the tide of the cosmos carry you through the night,
Atlantis, stars, and beats blend in a symphony of light.
Keep groovin‚Äô, keep ridin‚Äô as the universe unfolds,
In this endless cosmic journey, our legend forever holds!

```


